{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "pytorch version =  1.10.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "# visualization \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "device = torch.device(\"cpu\"); gpu_id = -1 # select CPU\n",
    "\n",
    "gpu_id = '0' # select a single GPU  \n",
    "#gpu_id = '2,3' # select multiple GPUs  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)  \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('GPU name: {:s}, gpu_id: {:s}'.format(torch.cuda.get_device_name(0),gpu_id))   \n",
    "    \n",
    "print(device)\n",
    "print('pytorch version = ',torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from listofpathpoint import input_handler\n",
    "import cnc_input\n",
    "import copy\n",
    "temp = input_handler('10&15data/25_chips/25_1.json')\n",
    "temp.original_map_present()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "107\n",
      "here\n",
      "h0 : torch.Size([128])\n",
      "c0 : torch.Size([128])\n",
      "alpha : torch.Size([1])\n",
      "start_placeholder : torch.Size([128])\n",
      "TransPointer.v : torch.Size([128])\n",
      "TransPointer.Wref.weight : torch.Size([128, 128])\n",
      "TransPointer.Wref.bias : torch.Size([128])\n",
      "TransPointer.Wq.weight : torch.Size([128, 128])\n",
      "TransPointer.Wq.bias : torch.Size([128])\n",
      "encoder.Wxi.weight : torch.Size([128, 128])\n",
      "encoder.Wxi.bias : torch.Size([128])\n",
      "encoder.Whi.weight : torch.Size([128, 128])\n",
      "encoder.Whi.bias : torch.Size([128])\n",
      "encoder.wci.weight : torch.Size([128, 128])\n",
      "encoder.wci.bias : torch.Size([128])\n",
      "encoder.Wxf.weight : torch.Size([128, 128])\n",
      "encoder.Wxf.bias : torch.Size([128])\n",
      "encoder.Whf.weight : torch.Size([128, 128])\n",
      "encoder.Whf.bias : torch.Size([128])\n",
      "encoder.wcf.weight : torch.Size([128, 128])\n",
      "encoder.wcf.bias : torch.Size([128])\n",
      "encoder.Wxc.weight : torch.Size([128, 128])\n",
      "encoder.Wxc.bias : torch.Size([128])\n",
      "encoder.Whc.weight : torch.Size([128, 128])\n",
      "encoder.Whc.bias : torch.Size([128])\n",
      "encoder.Wxo.weight : torch.Size([128, 128])\n",
      "encoder.Wxo.bias : torch.Size([128])\n",
      "encoder.Who.weight : torch.Size([128, 128])\n",
      "encoder.Who.bias : torch.Size([128])\n",
      "encoder.wco.weight : torch.Size([128, 128])\n",
      "encoder.wco.bias : torch.Size([128])\n",
      "embedding_x.weight : torch.Size([128, 2])\n",
      "embedding_x.bias : torch.Size([128])\n",
      "embedding_all.weight : torch.Size([128, 2])\n",
      "embedding_all.bias : torch.Size([128])\n",
      "Transembedding_all.MHA_layers.0.in_proj_weight : torch.Size([384, 128])\n",
      "Transembedding_all.MHA_layers.0.in_proj_bias : torch.Size([384])\n",
      "Transembedding_all.MHA_layers.0.out_proj.weight : torch.Size([128, 128])\n",
      "Transembedding_all.MHA_layers.0.out_proj.bias : torch.Size([128])\n",
      "Transembedding_all.MHA_layers.1.in_proj_weight : torch.Size([384, 128])\n",
      "Transembedding_all.MHA_layers.1.in_proj_bias : torch.Size([384])\n",
      "Transembedding_all.MHA_layers.1.out_proj.weight : torch.Size([128, 128])\n",
      "Transembedding_all.MHA_layers.1.out_proj.bias : torch.Size([128])\n",
      "Transembedding_all.MHA_layers.2.in_proj_weight : torch.Size([384, 128])\n",
      "Transembedding_all.MHA_layers.2.in_proj_bias : torch.Size([384])\n",
      "Transembedding_all.MHA_layers.2.out_proj.weight : torch.Size([128, 128])\n",
      "Transembedding_all.MHA_layers.2.out_proj.bias : torch.Size([128])\n",
      "Transembedding_all.MHA_layers.3.in_proj_weight : torch.Size([384, 128])\n",
      "Transembedding_all.MHA_layers.3.in_proj_bias : torch.Size([384])\n",
      "Transembedding_all.MHA_layers.3.out_proj.weight : torch.Size([128, 128])\n",
      "Transembedding_all.MHA_layers.3.out_proj.bias : torch.Size([128])\n",
      "Transembedding_all.MHA_layers.4.in_proj_weight : torch.Size([384, 128])\n",
      "Transembedding_all.MHA_layers.4.in_proj_bias : torch.Size([384])\n",
      "Transembedding_all.MHA_layers.4.out_proj.weight : torch.Size([128, 128])\n",
      "Transembedding_all.MHA_layers.4.out_proj.bias : torch.Size([128])\n",
      "Transembedding_all.MHA_layers.5.in_proj_weight : torch.Size([384, 128])\n",
      "Transembedding_all.MHA_layers.5.in_proj_bias : torch.Size([384])\n",
      "Transembedding_all.MHA_layers.5.out_proj.weight : torch.Size([128, 128])\n",
      "Transembedding_all.MHA_layers.5.out_proj.bias : torch.Size([128])\n",
      "Transembedding_all.linear1_layers.0.weight : torch.Size([512, 128])\n",
      "Transembedding_all.linear1_layers.0.bias : torch.Size([512])\n",
      "Transembedding_all.linear1_layers.1.weight : torch.Size([512, 128])\n",
      "Transembedding_all.linear1_layers.1.bias : torch.Size([512])\n",
      "Transembedding_all.linear1_layers.2.weight : torch.Size([512, 128])\n",
      "Transembedding_all.linear1_layers.2.bias : torch.Size([512])\n",
      "Transembedding_all.linear1_layers.3.weight : torch.Size([512, 128])\n",
      "Transembedding_all.linear1_layers.3.bias : torch.Size([512])\n",
      "Transembedding_all.linear1_layers.4.weight : torch.Size([512, 128])\n",
      "Transembedding_all.linear1_layers.4.bias : torch.Size([512])\n",
      "Transembedding_all.linear1_layers.5.weight : torch.Size([512, 128])\n",
      "Transembedding_all.linear1_layers.5.bias : torch.Size([512])\n",
      "Transembedding_all.linear2_layers.0.weight : torch.Size([128, 512])\n",
      "Transembedding_all.linear2_layers.0.bias : torch.Size([128])\n",
      "Transembedding_all.linear2_layers.1.weight : torch.Size([128, 512])\n",
      "Transembedding_all.linear2_layers.1.bias : torch.Size([128])\n",
      "Transembedding_all.linear2_layers.2.weight : torch.Size([128, 512])\n",
      "Transembedding_all.linear2_layers.2.bias : torch.Size([128])\n",
      "Transembedding_all.linear2_layers.3.weight : torch.Size([128, 512])\n",
      "Transembedding_all.linear2_layers.3.bias : torch.Size([128])\n",
      "Transembedding_all.linear2_layers.4.weight : torch.Size([128, 512])\n",
      "Transembedding_all.linear2_layers.4.bias : torch.Size([128])\n",
      "Transembedding_all.linear2_layers.5.weight : torch.Size([128, 512])\n",
      "Transembedding_all.linear2_layers.5.bias : torch.Size([128])\n",
      "Transembedding_all.norm1_layers.0.weight : torch.Size([128])\n",
      "Transembedding_all.norm1_layers.0.bias : torch.Size([128])\n",
      "Transembedding_all.norm1_layers.1.weight : torch.Size([128])\n",
      "Transembedding_all.norm1_layers.1.bias : torch.Size([128])\n",
      "Transembedding_all.norm1_layers.2.weight : torch.Size([128])\n",
      "Transembedding_all.norm1_layers.2.bias : torch.Size([128])\n",
      "Transembedding_all.norm1_layers.3.weight : torch.Size([128])\n",
      "Transembedding_all.norm1_layers.3.bias : torch.Size([128])\n",
      "Transembedding_all.norm1_layers.4.weight : torch.Size([128])\n",
      "Transembedding_all.norm1_layers.4.bias : torch.Size([128])\n",
      "Transembedding_all.norm1_layers.5.weight : torch.Size([128])\n",
      "Transembedding_all.norm1_layers.5.bias : torch.Size([128])\n",
      "Transembedding_all.norm2_layers.0.weight : torch.Size([128])\n",
      "Transembedding_all.norm2_layers.0.bias : torch.Size([128])\n",
      "Transembedding_all.norm2_layers.1.weight : torch.Size([128])\n",
      "Transembedding_all.norm2_layers.1.bias : torch.Size([128])\n",
      "Transembedding_all.norm2_layers.2.weight : torch.Size([128])\n",
      "Transembedding_all.norm2_layers.2.bias : torch.Size([128])\n",
      "Transembedding_all.norm2_layers.3.weight : torch.Size([128])\n",
      "Transembedding_all.norm2_layers.3.bias : torch.Size([128])\n",
      "Transembedding_all.norm2_layers.4.weight : torch.Size([128])\n",
      "Transembedding_all.norm2_layers.4.bias : torch.Size([128])\n",
      "Transembedding_all.norm2_layers.5.weight : torch.Size([128])\n",
      "Transembedding_all.norm2_layers.5.bias : torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "class TransEncoderNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder network based on self-attention transformer\n",
    "    Inputs :  \n",
    "      h of size      (bsz, nb_nodes, dim_emb)    batch of input cities\n",
    "    Outputs :  \n",
    "      h of size      (bsz, nb_nodes, dim_emb)    batch of encoded cities\n",
    "      score of size  (bsz, nb_nodes, nb_nodes+1) batch of attention scores\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, nb_layers, dim_emb, nb_heads, dim_ff, batchnorm):\n",
    "        super(TransEncoderNet, self).__init__()\n",
    "        assert dim_emb == nb_heads* (dim_emb//nb_heads) # check if dim_emb is divisible by nb_heads\n",
    "        self.MHA_layers = nn.ModuleList( [nn.MultiheadAttention(dim_emb, nb_heads) for _ in range(nb_layers)] )\n",
    "        self.linear1_layers = nn.ModuleList( [nn.Linear(dim_emb, dim_ff) for _ in range(nb_layers)] )\n",
    "        self.linear2_layers = nn.ModuleList( [nn.Linear(dim_ff, dim_emb) for _ in range(nb_layers)] )   \n",
    "        if batchnorm:\n",
    "            self.norm1_layers = nn.ModuleList( [nn.BatchNorm1d(dim_emb) for _ in range(nb_layers)] )\n",
    "            self.norm2_layers = nn.ModuleList( [nn.BatchNorm1d(dim_emb) for _ in range(nb_layers)] )\n",
    "        else:\n",
    "            self.norm1_layers = nn.ModuleList( [nn.LayerNorm(dim_emb) for _ in range(nb_layers)] )\n",
    "            self.norm2_layers = nn.ModuleList( [nn.LayerNorm(dim_emb) for _ in range(nb_layers)] )\n",
    "        self.nb_layers = nb_layers\n",
    "        self.nb_heads = nb_heads\n",
    "        self.batchnorm = batchnorm\n",
    "        \n",
    "    def forward(self, h):      \n",
    "        # PyTorch nn.MultiheadAttention requires input size (seq_len, bsz, dim_emb) \n",
    "        h = h.transpose(0,1) # size(h)=(nb_nodes, bsz, dim_emb)  \n",
    "        # L layers\n",
    "        for i in range(self.nb_layers):\n",
    "            h_rc = h # residual connection, size(h_rc)=(nb_nodes, bsz, dim_emb)\n",
    "            h, score = self.MHA_layers[i](h, h, h) # size(h)=(nb_nodes, bsz, dim_emb), size(score)=(bsz, nb_nodes, nb_nodes)\n",
    "            # add residual connection\n",
    "            \n",
    "            h = h_rc + h # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            if self.batchnorm:\n",
    "                # Pytorch nn.BatchNorm1d requires input size (bsz, dim, seq_len)\n",
    "                h = h.permute(1,2,0).contiguous() # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                h = self.norm1_layers[i](h)       # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                h = h.permute(2,0,1).contiguous() # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            else:\n",
    "                h = self.norm1_layers[i](h)       # size(h)=(nb_nodes, bsz, dim_emb) \n",
    "            # feedforward\n",
    "            h_rc = h # residual connection\n",
    "            h = self.linear2_layers[i](torch.relu(self.linear1_layers[i](h)))\n",
    "            h = h_rc + h # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            if self.batchnorm:\n",
    "                h = h.permute(1,2,0).contiguous() # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                h = self.norm2_layers[i](h)       # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                h = h.permute(2,0,1).contiguous() # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            else:\n",
    "                h = self.norm2_layers[i](h) # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "        # Transpose h\n",
    "        h = h.transpose(0,1) # size(h)=(bsz, nb_nodes, dim_emb)\n",
    "        return h, score\n",
    "    \n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, n_hidden):\n",
    "        super(Attention, self).__init__()\n",
    "        self.size = 0\n",
    "        self.batch_size = 0\n",
    "        self.dim = n_hidden\n",
    "        \n",
    "        v  = torch.FloatTensor(n_hidden)\n",
    "        self.v  = nn.Parameter(v)\n",
    "        self.v.data.uniform_(-1/math.sqrt(n_hidden), 1/math.sqrt(n_hidden))\n",
    "        \n",
    "        # parameters for pointer attention\n",
    "        self.Wref = nn.Linear(n_hidden, n_hidden)\n",
    "        self.Wq = nn.Linear(n_hidden, n_hidden)\n",
    "    \n",
    "    \n",
    "    def forward(self, q, ref):       # query and reference\n",
    "        self.batch_size = q.size(0)\n",
    "        self.size = int(ref.size(0) / self.batch_size)\n",
    "        q = self.Wq(q)     # (B, dim)\n",
    "        ref = self.Wref(ref)\n",
    "        ref = ref.view(self.batch_size, self.size, self.dim)  # (B, size, dim)\n",
    "        \n",
    "        q_ex = q.unsqueeze(1).repeat(1, self.size, 1) # (B, size, dim)\n",
    "        # v_view: (B, dim, 1)\n",
    "        v_view = self.v.unsqueeze(0).expand(self.batch_size, self.dim).unsqueeze(2)\n",
    "        \n",
    "        # (B, size, dim) * (B, dim, 1)\n",
    "        u = torch.bmm(torch.tanh(q_ex + ref), v_view).squeeze(2)\n",
    "        \n",
    "        return u, ref\n",
    "    \n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, n_hidden):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        # parameters for input gate\n",
    "        self.Wxi = nn.Linear(n_hidden, n_hidden)    # W(xt)\n",
    "        self.Whi = nn.Linear(n_hidden, n_hidden)    # W(ht)\n",
    "        self.wci = nn.Linear(n_hidden, n_hidden)    # w(ct)\n",
    "        \n",
    "        # parameters for forget gate\n",
    "        self.Wxf = nn.Linear(n_hidden, n_hidden)    # W(xt)\n",
    "        self.Whf = nn.Linear(n_hidden, n_hidden)    # W(ht)\n",
    "        self.wcf = nn.Linear(n_hidden, n_hidden)    # w(ct)\n",
    "        \n",
    "        # parameters for cell gate\n",
    "        self.Wxc = nn.Linear(n_hidden, n_hidden)    # W(xt)\n",
    "        self.Whc = nn.Linear(n_hidden, n_hidden)    # W(ht)\n",
    "        \n",
    "        # parameters for forget gate\n",
    "        self.Wxo = nn.Linear(n_hidden, n_hidden)    # W(xt)\n",
    "        self.Who = nn.Linear(n_hidden, n_hidden)    # W(ht)\n",
    "        self.wco = nn.Linear(n_hidden, n_hidden)    # w(ct)\n",
    "    \n",
    "    \n",
    "    def forward(self, x, h, c):       # query and reference\n",
    "        \n",
    "        # input gate\n",
    "        i = torch.sigmoid(self.Wxi(x) + self.Whi(h) + self.wci(c))\n",
    "        # forget gate\n",
    "        f = torch.sigmoid(self.Wxf(x) + self.Whf(h) + self.wcf(c))\n",
    "        # cell gate\n",
    "        c = f * c + i * torch.tanh(self.Wxc(x) + self.Whc(h))\n",
    "        # output gate\n",
    "        o = torch.sigmoid(self.Wxo(x) + self.Who(h) + self.wco(c))\n",
    "        \n",
    "        h = o * torch.tanh(c)\n",
    "        \n",
    "        return h, c\n",
    "\n",
    "class HPN(nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden):\n",
    "\n",
    "        super(HPN, self).__init__()\n",
    "        self.city_size = 0\n",
    "        self.batch_size = 0\n",
    "        self.dim = n_hidden\n",
    "        \n",
    "        # lstm for first turn\n",
    "        #self.lstm0 = nn.LSTM(n_hidden, n_hidden)main_training - Jupyter Notebook\n",
    "        \n",
    "        # pointer layer\n",
    "        #self.pointer = Attention(n_hidden)\n",
    "        self.TransPointer = Attention(n_hidden)\n",
    "        \n",
    "        # lstm encoder\n",
    "        self.encoder = LSTM(n_hidden)\n",
    "        \n",
    "        # trainable first hidden input\n",
    "        h0 = torch.FloatTensor(n_hidden)\n",
    "        c0 = torch.FloatTensor(n_hidden)\n",
    "        # trainable latent variable coefficient\n",
    "        print('here') \n",
    "        alpha = torch.ones(1)\n",
    "        self.h0 = nn.Parameter(h0)\n",
    "        self.c0 = nn.Parameter(c0)\n",
    "        \n",
    "        self.alpha = nn.Parameter(alpha)\n",
    "        self.h0.data.uniform_(-1/math.sqrt(n_hidden), 1/math.sqrt(n_hidden))\n",
    "        self.c0.data.uniform_(-1/math.sqrt(n_hidden), 1/math.sqrt(n_hidden))\n",
    "        \n",
    "#        r1 = torch.ones(1)\n",
    "#        r2 = torch.ones(1)\n",
    "#        r3 = torch.ones(1)\n",
    "#        self.r1 = nn.Parameter(r1)\n",
    "#        self.r2 = nn.Parameter(r2)\n",
    "#        self.r3 = nn.Parameter(r3)\n",
    "        \n",
    "        # embedding\n",
    "        self.embedding_x = nn.Linear(n_feature, n_hidden)\n",
    "        self.embedding_all = nn.Linear(n_feature, n_hidden)\n",
    "        self.Transembedding_all = TransEncoderNet(6, 128, 8, 512, batchnorm=True)#6,128,8,512\n",
    "        \n",
    "        # vector to start decoding \n",
    "        self.start_placeholder = nn.Parameter(torch.randn(n_hidden))\n",
    "        \n",
    "        # weights for GNN\n",
    "#         self.W1 = nn.Linear(n_hidden, n_hidden)\n",
    "#         self.W2 = nn.Linear(n_hidden, n_hidden)\n",
    "#         self.W3 = nn.Linear(n_hidden, n_hidden)\n",
    "        \n",
    "        # aggregation function for GNN\n",
    "#         self.agg_1 = nn.Linear(n_hidden, n_hidden)\n",
    "#         self.agg_2 = nn.Linear(n_hidden, n_hidden)\n",
    "#         self.agg_3 = nn.Linear(n_hidden, n_hidden)\n",
    "    \n",
    "    \n",
    "    def forward(self,context,Transcontext, x, X_all, mask_final, h=None, c=None, latent=None):\n",
    "        '''\n",
    "        Inputs (B: batch size, size: city size, dim: hidden dimension)\n",
    "        \n",
    "        x: current city coordinate (B, 2)\n",
    "        X_all: all cities' cooridnates (B, size, 2)\n",
    "        mask: mask visited cities\n",
    "        h: hidden variable (B, dim)\n",
    "        c: cell gate (B, dim)\n",
    "        latent: latent pointer vector from previous layer (B, size, dim)\n",
    "        \n",
    "        Outputs\n",
    "        \n",
    "        softmax: probability distribution of next city (B, size)\n",
    "        h: hidden variable (B, dim)\n",
    "        c: cell gate (B, dim)\n",
    "        latent_u: latent pointer vector for next layer\n",
    "        '''\n",
    "        \n",
    "        self.batch_size = X_all.size(0)\n",
    "        self.city_size = X_all.size(1)\n",
    "        # Check if this the first iteration loop\n",
    "        if h is None or c is None:\n",
    "            x          = self.start_placeholder  \n",
    "            context = self.embedding_all(X_all)\n",
    "            Transcontext,_ = self.Transembedding_all(context)\n",
    "            \n",
    "            # =============================\n",
    "            # graph neural network encoder\n",
    "            # =============================\n",
    "\n",
    "            # (B, size, dim)\n",
    "            #context = context.reshape(-1, self.dim)\n",
    "            Transcontext = Transcontext.reshape(-1, self.dim)\n",
    "\n",
    "#             context = self.r1 * self.W1(context)\\\n",
    "#                 + (1-self.r1) * F.relu(self.agg_1(context/(self.city_size-1)))\n",
    "\n",
    "#             context = self.r2 * self.W2(context)\\\n",
    "#                 + (1-self.r2) * F.relu(self.agg_2(context/(self.city_size-1)))\n",
    "\n",
    "#             context = self.r3 * self.W3(context)\\\n",
    "#                 + (1-self.r3) * F.relu(self.agg_3(context/(self.city_size-1)))\n",
    "            h0 = self.h0.unsqueeze(0).expand(self.batch_size, self.dim)\n",
    "            c0 = self.c0.unsqueeze(0).expand(self.batch_size, self.dim)\n",
    "\n",
    "            h0 = h0.unsqueeze(0).contiguous()\n",
    "            c0 = c0.unsqueeze(0).contiguous()\n",
    "            \n",
    "            # let h0, c0 be the hidden variable of first turn\n",
    "            h = h0.squeeze(0)\n",
    "            c = c0.squeeze(0)\n",
    "        else:\n",
    "            x          = self.embedding_x(x)\n",
    "        # LSTM encoder1900/2500\n",
    "        h, c = self.encoder(x, h, c)\n",
    "        # query vector\n",
    "        q = h\n",
    "        # pointer\n",
    "        #u1, _ = self.pointer(q, context)\n",
    "        u2 ,_ = self.TransPointer(q, Transcontext)\n",
    "        # Avg Agg between the two attention vector\n",
    "        u = u2\n",
    "        latent_u = u.clone()\n",
    "                \n",
    "        u = 10 * torch.tanh(u)\n",
    "        u = u + mask_final\n",
    "        return context, Transcontext,F.softmax(u, dim=1), h, c, latent_u\n",
    "params= list(HPN(n_feature = 2, n_hidden = 128).parameters())\n",
    "print(len(params))\n",
    "for name,parameters in HPN(n_feature = 2, n_hidden = 128).named_parameters():\n",
    "    print(name,':',parameters.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "HPN(\n",
      "  (TransPointer): Attention(\n",
      "    (Wref): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (encoder): LSTM(\n",
      "    (Wxi): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (Whi): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (wci): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (Wxf): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (Whf): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (wcf): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (Wxc): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (Whc): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (Wxo): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (Who): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (wco): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (embedding_x): Linear(in_features=2, out_features=128, bias=True)\n",
      "  (embedding_all): Linear(in_features=2, out_features=128, bias=True)\n",
      "  (Transembedding_all): TransEncoderNet(\n",
      "    (MHA_layers): ModuleList(\n",
      "      (0): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (1): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (2): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (3): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (4): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (5): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (linear1_layers): ModuleList(\n",
      "      (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "      (1): Linear(in_features=128, out_features=512, bias=True)\n",
      "      (2): Linear(in_features=128, out_features=512, bias=True)\n",
      "      (3): Linear(in_features=128, out_features=512, bias=True)\n",
      "      (4): Linear(in_features=128, out_features=512, bias=True)\n",
      "      (5): Linear(in_features=128, out_features=512, bias=True)\n",
      "    )\n",
      "    (linear2_layers): ModuleList(\n",
      "      (0): Linear(in_features=512, out_features=128, bias=True)\n",
      "      (1): Linear(in_features=512, out_features=128, bias=True)\n",
      "      (2): Linear(in_features=512, out_features=128, bias=True)\n",
      "      (3): Linear(in_features=512, out_features=128, bias=True)\n",
      "      (4): Linear(in_features=512, out_features=128, bias=True)\n",
      "      (5): Linear(in_features=512, out_features=128, bias=True)\n",
      "    )\n",
      "    (norm1_layers): ModuleList(\n",
      "      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (norm2_layers): ModuleList(\n",
      "      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Number of parameters: 1405569\n"
     ]
    }
   ],
   "source": [
    "#test network \n",
    "Actor = HPN(n_feature = 2, n_hidden = 128)\n",
    "print(Actor)\n",
    "nb_param = 0\n",
    "for param in Actor.parameters():\n",
    "    nb_param += np.prod(list(param.data.size()))\n",
    "print('Number of parameters:', nb_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# daniel rectangle feature handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This part I designed the rectangle-characterized TSP, that means for every step the agent walk through a corner,\n",
    "then he travel through the whole rectangle using zig-zag, finally he ends up at one of the rest corners of \n",
    "the rextangle, so, it equals the agent walk through three points at one step, in practice, I add three points into \n",
    "mask to make them unselectable.\n",
    "'''\n",
    "def rectangle_process(temp,idx,idx_final,Y,Y_final,Y0,mask,k,B,Not_choosen_ones,Not_last_time,mask_list_num):\n",
    "    Y1 = Y[zero_to_bsz, idx.data].clone()\n",
    "    rectangle_inf = idx/4\n",
    "    feature_table,mapping_tool = temp.outcorner_getout(rectangle_inf,B,mask_list_num)\n",
    "    if torch.cuda.is_available():\n",
    "        mapping_tool_matrix = torch.tensor(mapping_tool).cuda()\n",
    "    else:\n",
    "        mapping_tool_matrix = torch.tensor(mapping_tool)\n",
    "    mapping_tool_matrix = mapping_tool_matrix.repeat(B,1)\n",
    "    feature_table = torch.Tensor(feature_table).type(torch.long)\n",
    "    if torch.cuda.is_available():\n",
    "        feature_table = feature_table.cuda()\n",
    "    Y_corner = Y[zero_to_bsz, feature_table[:,0].data].clone()\n",
    "    Y_Yfinal = feature_table[:,0].data/4\n",
    "    Y_Yfinal_int = Y_Yfinal.type(torch.int)\n",
    "    Y_Yfinal_int = Y_Yfinal_int.type(torch.long)\n",
    "    Y_Yfinal_ROI = mapping_tool_matrix[zero_to_bsz,Y_Yfinal_int]\n",
    "    Y_Yfinal_corner = feature_table[:,0].data - Y_Yfinal_int*4\n",
    "    Y_corner_final = Y_Yfinal_ROI*4 + Y_Yfinal_corner\n",
    "    x = Y_final[zero_to_bsz, Y_corner_final].clone()\n",
    "    if k ==0:\n",
    "        if torch.cuda.is_available():\n",
    "            reward = torch.zeros(B).cuda()\n",
    "        else:\n",
    "            reward = torch.zeros(B)\n",
    "    if k > 0:\n",
    "        reward = torch.sum((Y1[:,(0,1)] - Y0[:,(0,1)])**2 , dim=1 )**0.5\n",
    "        reward += torch.sum((Y_corner[:,(0,1)] - Y1[:,(0,1)])**2 , dim=1 )**0.5\n",
    "        #dis = (Y1 - Y0)**2\n",
    "        #dis_1 = (Y_corner - Y1)**2\n",
    "        #reward = torch.maximum(dis[:,0],dis[:,1])**0.5\n",
    "        #reward += torch.maximum(dis_1[:,0],dis_1[:,1])**0.5 \n",
    "    if torch.cuda.is_available():\n",
    "        reward = reward.cuda()\n",
    "    mask[zero_to_bsz, idx.data] += -np.inf\n",
    "    #這邊是全都是四邊形時的配置\n",
    "    mask[zero_to_bsz, feature_table[:,0].data] += -np.inf\n",
    "    mask[zero_to_bsz, feature_table[:,1].data] += -np.inf    \n",
    "    mask[zero_to_bsz, feature_table[:,2].data] += -np.inf \n",
    "    if_frozen = Not_last_time[zero_to_bsz, idx.data]\n",
    "    Not_choosen_ones[zero_to_bsz,if_frozen * (idx.data +4)] = 0\n",
    "    if_frozen = Not_last_time[zero_to_bsz, feature_table[:,0].data]\n",
    "    Not_choosen_ones[zero_to_bsz,if_frozen * (feature_table[:,0] +4)] = 0\n",
    "    if_frozen = Not_last_time[zero_to_bsz, feature_table[:,1].data]\n",
    "    Not_choosen_ones[zero_to_bsz,if_frozen * (feature_table[:,1] +4)] = 0  \n",
    "    if_frozen = Not_last_time[zero_to_bsz, feature_table[:,2].data]\n",
    "    Not_choosen_ones[zero_to_bsz,if_frozen * (feature_table[:,2] +4)] = 0\n",
    "    Not_choosen_ones[zero_to_bsz,0] = 1\n",
    "    return reward, Y_corner, x\n",
    "def rectangle_process_actor(temp,idx,idx_final,Y,Y_final,Y0,mask,k,B,i,path_gazebo,Not_choosen_ones,Not_last_time,mask_list_num):\n",
    "    Y1 = Y[zero_to_bsz, idx.data].clone()\n",
    "    rectangle_inf = idx/4\n",
    "    feature_table,mapping_tool = temp.outcorner_getout(rectangle_inf,B,mask_list_num)\n",
    "    if torch.cuda.is_available():\n",
    "        mapping_tool_matrix = torch.tensor(mapping_tool).cuda()\n",
    "    else:\n",
    "        mapping_tool_matrix = torch.tensor(mapping_tool)\n",
    "    mapping_tool_matrix = mapping_tool_matrix.repeat(B,1)\n",
    "    feature_table = torch.Tensor(feature_table).type(torch.long)\n",
    "    if torch.cuda.is_available():\n",
    "        feature_table = feature_table.cuda()\n",
    "    Y_corner = Y[zero_to_bsz, feature_table[:,0].data].clone()\n",
    "    Y_Yfinal = feature_table[:,0].data/4\n",
    "    Y_Yfinal_int = Y_Yfinal.type(torch.int)\n",
    "    Y_Yfinal_int = Y_Yfinal_int.type(torch.long)\n",
    "    Y_Yfinal_ROI = mapping_tool_matrix[zero_to_bsz,Y_Yfinal_int]\n",
    "    Y_Yfinal_corner = feature_table[:,0].data - Y_Yfinal_int*4\n",
    "    Y_corner_final = Y_Yfinal_ROI*4 + Y_Yfinal_corner\n",
    "    x = Y_final[zero_to_bsz, Y_corner_final].clone()\n",
    "    if i % 100 == 0:\n",
    "        path_gazebo.append([idx.data[0].tolist(),feature_table[:,0].data[0].tolist()])\n",
    "    if k ==0:\n",
    "        if torch.cuda.is_available():\n",
    "            reward = torch.zeros(B).cuda()\n",
    "        else:\n",
    "            reward = torch.zeros(B)\n",
    "    if k > 0:\n",
    "        reward = torch.sum((Y1[:,(0,1)] - Y0[:,(0,1)])**2 , dim=1 )**0.5\n",
    "        reward += torch.sum((Y_corner[:,(0,1)] - Y1[:,(0,1)])**2 , dim=1 )**0.5\n",
    "        #dis = (Y1 - Y0)**2\n",
    "        #dis_1 = (Y_corner - Y1)**2\n",
    "        #reward = torch.maximum(dis[:,0],dis[:,1])**0.5\n",
    "        #reward += torch.maximum(dis_1[:,0],dis_1[:,1])**0.5 \n",
    "    if torch.cuda.is_available():\n",
    "        reward = reward.cuda()\n",
    "    mask[zero_to_bsz, idx.data] += -np.inf\n",
    "    mask[zero_to_bsz, feature_table[:,0].data] += -np.inf\n",
    "    mask[zero_to_bsz, feature_table[:,1].data ] += -np.inf    \n",
    "    mask[zero_to_bsz, feature_table[:,2].data ] += -np.inf\n",
    "    if_frozen = Not_last_time[zero_to_bsz, idx.data]\n",
    "    next_time_visited = if_frozen * (idx.data +4)\n",
    "    Not_choosen_ones[zero_to_bsz,next_time_visited] = 0\n",
    "    if_frozen = Not_last_time[zero_to_bsz, feature_table[:,0].data]\n",
    "    next_time_visited = if_frozen * (feature_table[:,0].data+4)\n",
    "    Not_choosen_ones[zero_to_bsz,next_time_visited] = 0\n",
    "    if_frozen = Not_last_time[zero_to_bsz, feature_table[:,1].data]\n",
    "    next_time_visited = if_frozen * (feature_table[:,1].data+4)\n",
    "    Not_choosen_ones[zero_to_bsz,next_time_visited] = 0  \n",
    "    if_frozen = Not_last_time[zero_to_bsz, feature_table[:,2].data]\n",
    "    next_time_visited = if_frozen * (feature_table[:,2].data+4)\n",
    "    Not_choosen_ones[zero_to_bsz,next_time_visited] = 0\n",
    "    Not_choosen_ones[zero_to_bsz,0] = 1\n",
    "    return reward, Y_corner, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_map_matrix(size, size_final, mask_list_num):\n",
    "    if torch.cuda.is_available():\n",
    "        map_matrix = torch.zeros(size, size_final).cuda()\n",
    "    else:\n",
    "        map_matrix = torch.zeros(size, size_final)\n",
    "    for i in range(len(mask_list_num)):\n",
    "        if i !=0 :\n",
    "            for j in range(mask_list_num[i-1],mask_list_num[i]):\n",
    "                #complete a ROI for once visit time\n",
    "                map_matrix[4*j][4*(i-1)]=1\n",
    "                map_matrix[4*j+1][4*(i-1)+1]=1\n",
    "                map_matrix[4*j+2][4*(i-1)+2]=1\n",
    "                map_matrix[4*j+3][4*(i-1)+3]=1\n",
    "                \n",
    "    return map_matrix\n",
    "def unmask_checker(R,B, waiting_time_list, mask_temp):\n",
    "    R_reshape = R.view(B,1)\n",
    "    if_dried = waiting_time_list - R_reshape\n",
    "    if_dried = if_dried<0\n",
    "    # if a ROI is ready for re-opened, it would be True in if_dried matrix\n",
    "    mask_temp[if_dried] = 0\n",
    "    return mask_temp\n",
    "def logical_mask_filter(mask_final_temp, mask_final, map_matrix):\n",
    "    if_open = mask_final_temp==0\n",
    "    if_open = if_open.type(torch.LongTensor)\n",
    "    map_matrix = map_matrix.type(torch.LongTensor)\n",
    "    mask_final = torch.mm(if_open,map_matrix)\n",
    "    mask_final = mask_final==0\n",
    "    # true = masked, false = unmasked\n",
    "    mask_final = mask_final.type(torch.float)\n",
    "    mask_final *= -np.inf\n",
    "    mask_final[mask_final != mask_final] = 0 \n",
    "    return mask_final\n",
    "def idx_transfer(counter_visit, mask_list_num, idx,B):\n",
    "    idx_float = idx.data/4\n",
    "    idx_int = idx_float.type(torch.int)\n",
    "    idx_int = idx_int.type(torch.LongTensor)\n",
    "    if torch.cuda.is_available():\n",
    "        idx_int = idx_int.cuda()\n",
    "    idx_temp = idx_int*4\n",
    "    idx_corner = idx.data - idx_temp\n",
    "    if torch.cuda.is_available():\n",
    "        mask_list_matrix = torch.tensor(mask_list_num[:-1]).cuda()\n",
    "    else:\n",
    "        mask_list_matrix = torch.tensor(mask_list_num[:-1])\n",
    "    mask_list_matrix = mask_list_matrix.repeat(B,1)\n",
    "    which_ROI_baseline = mask_list_matrix[zero_to_bsz,idx_int]+counter_visit[zero_to_bsz,idx_int]\n",
    "    if torch.cuda.is_available():\n",
    "        which_ROI_baseline = which_ROI_baseline.cuda()\n",
    "    idx_baseline = which_ROI_baseline*4 + idx_corner\n",
    "    idx_baseline = idx_baseline.type(torch.int)\n",
    "    idx_baseline = idx_baseline.type(torch.LongTensor)\n",
    "    if torch.cuda.is_available():\n",
    "        idx_baseline = idx_baseline.cuda()\n",
    "    counter_visit[zero_to_bsz, idx_int] += 1\n",
    "    return idx_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "prepare to train\n",
      "======================\n",
      "Hyper parameters:\n",
      "learning rate 0.0001\n",
      "batch size 128\n",
      "steps 2500\n",
      "epoch 100\n",
      "======================\n",
      "here\n",
      "here\n",
      "[[533, 152, 5, 1], [633, 152, 5, 1], [633, 166, 5, 1], [533, 166, 5, 1], [198, 80, 5, 2], [236, 80, 5, 2], [236, 105, 5, 2], [198, 105, 5, 2], [171, 280, 5, 1], [213, 280, 5, 1], [213, 311, 5, 1], [171, 311, 5, 1], [410, 122, 5, 3], [436, 122, 5, 3], [436, 134, 5, 3], [410, 134, 5, 3], [367, 71, 5, 3], [384, 71, 5, 3], [384, 83, 5, 3], [367, 83, 5, 3], [592, 450, 5, 3], [687, 450, 5, 3], [687, 462, 5, 3], [592, 462, 5, 3], [747, 131, 5, 3], [777, 131, 5, 3], [777, 148, 5, 3], [747, 148, 5, 3], [332, 413, 5, 1], [377, 413, 5, 1], [377, 443, 5, 1], [332, 443, 5, 1], [513, 231, 5, 1], [542, 231, 5, 1], [542, 260, 5, 1], [513, 260, 5, 1], [158, 120, 5, 3], [188, 120, 5, 3], [188, 234, 5, 3], [158, 234, 5, 3], [299, 138, 5, 2], [332, 138, 5, 2], [332, 251, 5, 2], [299, 251, 5, 2], [357, 287, 5, 2], [396, 287, 5, 2], [396, 318, 5, 2], [357, 318, 5, 2], [277, 480, 5, 3], [294, 480, 5, 3], [294, 491, 5, 3], [277, 491, 5, 3], [698, 202, 5, 3], [754, 202, 5, 3], [754, 223, 5, 3], [698, 223, 5, 3], [612, 224, 5, 1], [658, 224, 5, 1], [658, 258, 5, 1], [612, 258, 5, 1], [421, 241, 5, 1], [475, 241, 5, 1], [475, 261, 5, 1], [421, 261, 5, 1], [442, 70, 5, 2], [461, 70, 5, 2], [461, 83, 5, 2], [442, 83, 5, 2], [436, 444, 5, 2], [490, 444, 5, 2], [490, 455, 5, 2], [436, 455, 5, 2], [244, 378, 5, 3], [264, 378, 5, 3], [264, 389, 5, 3], [244, 389, 5, 3], [284, 78, 5, 2], [326, 78, 5, 2], [326, 109, 5, 2], [284, 109, 5, 2], [724, 86, 5, 3], [743, 86, 5, 3], [743, 99, 5, 3], [724, 99, 5, 3], [469, 190, 5, 2], [569, 190, 5, 2], [569, 204, 5, 2], [469, 204, 5, 2], [479, 373, 5, 2], [518, 373, 5, 2], [518, 405, 5, 2], [479, 405, 5, 2], [631, 338, 5, 3], [677, 338, 5, 3], [677, 372, 5, 3], [631, 372, 5, 3], [244, 225, 5, 3], [277, 225, 5, 3], [277, 338, 5, 3], [244, 338, 5, 3]]\n",
      "55\n",
      "initial_all tensor([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 150., 150., 150., 150.,\n",
      "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 150., 150., 150., 150.,\n",
      "        150., 150., 150., 150.,   0.,   0.,   0.,   0., 150., 150., 150., 150.,\n",
      "        150., 150., 150., 150.,   0.,   0.,   0.,   0., 150., 150., 150., 150.,\n",
      "        150., 150., 150., 150.,   0.,   0.,   0.,   0., 150., 150., 150., 150.,\n",
      "        150., 150., 150., 150.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "          0.,   0.,   0.,   0., 150., 150., 150., 150., 150., 150., 150., 150.,\n",
      "          0.,   0.,   0.,   0., 150., 150., 150., 150.,   0.,   0.,   0.,   0.,\n",
      "        150., 150., 150., 150.,   0.,   0.,   0.,   0., 150., 150., 150., 150.,\n",
      "        150., 150., 150., 150.,   0.,   0.,   0.,   0., 150., 150., 150., 150.,\n",
      "        150., 150., 150., 150.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "          0.,   0.,   0.,   0., 150., 150., 150., 150.,   0.,   0.,   0.,   0.,\n",
      "        150., 150., 150., 150.,   0.,   0.,   0.,   0., 150., 150., 150., 150.,\n",
      "        150., 150., 150., 150.,   0.,   0.,   0.,   0., 150., 150., 150., 150.,\n",
      "          0.,   0.,   0.,   0., 150., 150., 150., 150., 150., 150., 150., 150.,\n",
      "          0.,   0.,   0.,   0., 150., 150., 150., 150.,   0.,   0.,   0.,   0.,\n",
      "        150., 150., 150., 150.,   0.,   0.,   0.,   0., 150., 150., 150., 150.,\n",
      "        150., 150., 150., 150.,   0.,   0.,   0.,   0., 150., 150., 150., 150.,\n",
      "        150., 150., 150., 150.])\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from torch.distributions.categorical import Categorical\n",
    "# visualization\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from tqdm import tqdm_notebook\n",
    "import torch.nn.functional as F\n",
    "####### my own import file ##########\n",
    "from listofpathpoint import input_handler\n",
    "import cnc_input\n",
    "import copy\n",
    "#from hybrid_models import HPN\n",
    "####### my own import file ##########\n",
    "'''\n",
    "so, the models we have are TransEncoderNet,\n",
    "                            Attention\n",
    "                            LSTM\n",
    "                            HPN\n",
    "each one have initial parameters and the forward part, \n",
    "once we have the forward part, the back propagation will \n",
    "finished automatically by pytorch  \n",
    "'''\n",
    "TOL = 1e-3\n",
    "TINY = 1e-15\n",
    "learning_rate = 1e-4   #learning rate\n",
    "B = 128            #batch size\n",
    "B_valLoop = 20\n",
    "steps = 2500\n",
    "n_epoch = 100       # epochs\n",
    "map_number = 0\n",
    "record_actor = []\n",
    "record_critic = []\n",
    "dimension = 4\n",
    "speed_of_nozzle = 30\n",
    "range_of_wait = 10\n",
    "visit_time_range = 4\n",
    "scale_of_the_map = (800,500,speed_of_nozzle*range_of_wait)\n",
    "\n",
    "print('======================')\n",
    "print('prepare to train')\n",
    "print('======================')\n",
    "print('Hyper parameters:')\n",
    "print('learning rate', learning_rate)\n",
    "print('batch size', B)\n",
    "print('steps', steps)\n",
    "print('epoch', n_epoch)\n",
    "print('======================')\n",
    "\n",
    "'''\n",
    "instantiate a training network and a baseline network\n",
    "'''\n",
    "\n",
    "\n",
    "try:\n",
    "    del Actor  # remove existing model\n",
    "    del Critic # remove existing model\n",
    "except:\n",
    "    pass\n",
    "Actor = HPN(n_feature = dimension, n_hidden = 128)\n",
    "Critic = HPN(n_feature = dimension, n_hidden = 128)\n",
    "optimizer = optim.Adam(Actor.parameters(), lr=learning_rate)\n",
    "\n",
    "# Putting Critic model on the eval mode\n",
    "Actor = Actor.to(device)\n",
    "Critic = Critic.to(device)\n",
    "Critic.eval()\n",
    "\n",
    "epoch_ckpt = 0\n",
    "tot_time_ckpt = 0\n",
    "\n",
    "val_mean = []\n",
    "val_std = []\n",
    "maplist = ['10&15data/25_chips/25_1.json'\n",
    "          ,'10&15data/25_chips/25_1.json','10&15data/25_chips/25_1.json'\\\n",
    "          ,'10&15data/25_chips/25_1.json','10&15data/25_chips/25_1.json'\\\n",
    "          ,'10&15data/25_chips/25_1.json'\n",
    "          ]\n",
    "          \n",
    "plot_performance_train = []\n",
    "plot_performance_baseline = []\n",
    "# recording the result of the resent epoch makes it available for future\n",
    "#*********************# Uncomment these lines to load the previous check point\n",
    "\"\"\"\n",
    "checkpoint_file = \"checkpoint/mutimap_20.pkl\"\n",
    "checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "epoch_ckpt = checkpoint['epoch'] + 1\n",
    "tot_time_ckpt = checkpoint['tot_time']\n",
    "plot_performance_train = checkpoint['plot_performance_train']\n",
    "plot_performance_baseline = checkpoint['plot_performance_baseline']\n",
    "Critic.load_state_dict(checkpoint['model_baseline'])\n",
    "Actor.load_state_dict(checkpoint['model_train'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "print('Re-start training with saved checkpoint file={:s}\\n  Checkpoint at epoch= {:d} and time={:.3f}min\\n'.format(checkpoint_file,epoch_ckpt-1,tot_time_ckpt/60))\n",
    "\"\"\"\n",
    "\n",
    "#***********************# Uncomment these lines to load the previous check point\n",
    "\n",
    "# Main training loop\n",
    "# The core training concept mainly upon Sampling from the actor\n",
    "# then taking the greedy action from the critic\n",
    "\n",
    "start_training_time = time.time()\n",
    "time_stamp = datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\") # Load the time stamp\n",
    "\n",
    "C = 0       # baseline => the object which the actor can compare\n",
    "R = 0       # reward\n",
    "\n",
    "temp = input_handler(maplist[map_number])\n",
    "X_temp, mask_list_num, waiting_time_list_initial = temp.final_ver_points()\n",
    "print(X_temp)\n",
    "X_baseline_temp, mask_list_num, waiting_time_list_initial = temp.baseline_points()\n",
    "#change the waiting time to the distance that we can measure\n",
    "mask_list_num_with_lastone = mask_list_num.copy()\n",
    "size = mask_list_num.pop()*4\n",
    "size_final = len(X_temp)\n",
    "if torch.cuda.is_available():\n",
    "    Not_last_time = torch.ones(B,size, dtype=torch.bool).cuda()\n",
    "else:\n",
    "    Not_last_time = torch.ones(B,size, dtype=torch.bool)\n",
    "zero_to_bsz = torch.arange(B, device = device) # a list contains 0 to (batch size -1)\n",
    "zero_to_size = torch.arange(size_final, device = device)\n",
    "for last_one in mask_list_num:\n",
    "    Not_last_time[zero_to_bsz,(last_one-1)*4] = False\n",
    "    Not_last_time[zero_to_bsz,(last_one-1)*4+1] = False\n",
    "    Not_last_time[zero_to_bsz,(last_one-1)*4+2] = False\n",
    "    Not_last_time[zero_to_bsz,(last_one-1)*4+3] = False\n",
    "\n",
    "for corner in X_temp:\n",
    "    corner[dimension -2] *= speed_of_nozzle\n",
    "size_rec = int(size/4)\n",
    "print(size_rec)\n",
    "\n",
    "X_temp = torch.FloatTensor(X_temp)\n",
    "X_baseline_temp = torch.FloatTensor(X_baseline_temp)\n",
    "waiting_time_list_initial = torch.FloatTensor(waiting_time_list_initial)\n",
    "X = X_temp.repeat(B,1,1)\n",
    "X_baseline = X_baseline_temp.repeat(B,1,1)\n",
    "waiting_time_list_initial *= speed_of_nozzle\n",
    "waiting_time_list = waiting_time_list_initial.repeat(B,1)\n",
    "if torch.cuda.is_available():\n",
    "    waiting_time_list = waiting_time_list.cuda()\n",
    "map_matrix = make_map_matrix(size, size_final, mask_list_num_with_lastone)\n",
    "\n",
    "print('initial_all',waiting_time_list_initial)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    X = X.cuda()\n",
    "\n",
    "for epoch in range(0, n_epoch):\n",
    "    # re-start training with saved checkpoint\n",
    "    epoch += epoch_ckpt # adding the number of the former epochs\n",
    "    # Train the model for one epoch\n",
    "    start = time.time() # record the starting time\n",
    "    Actor.train() \n",
    "    path_gazebo = []\n",
    "    for i in range(1, steps+1): # 1 ~ 2500 steps\n",
    "        # mask some points that are not the first visited points\n",
    "        if torch.cuda.is_available():\n",
    "            R = torch.zeros(B).cuda()\n",
    "            punishment_of_wait = torch.zeros(B).cuda()\n",
    "            logprobs = 0\n",
    "            reward = torch.zeros(B).cuda()\n",
    "            mask_final = torch.zeros(B,size_final).cuda()\n",
    "            mask = torch.zeros(B,size).cuda() # use mask to make some points impossible to choose\n",
    "            mask_temp = torch.zeros(B,size).cuda() # mask_temp for temp-masked points(wait for drying)\n",
    "        else:\n",
    "            R = torch.zeros(B)\n",
    "            punishment_of_wait = torch.zeros(B)\n",
    "            logprobs = 0\n",
    "            reward = torch.zeros(B)\n",
    "            mask_final = torch.zeros(B,size_final)\n",
    "            mask = torch.zeros(B,size) # use mask to make some points impossible to choose\n",
    "            mask_temp = torch.zeros(B,size) # mask_temp for temp-masked points(wait for drying)\n",
    "        mask_temp += -np.inf\n",
    "        for initial_area_idx in mask_list_num:\n",
    "            mask_temp[zero_to_bsz,initial_area_idx*4] = 0\n",
    "            mask_temp[zero_to_bsz,initial_area_idx*4 +1] = 0\n",
    "            mask_temp[zero_to_bsz,initial_area_idx*4 +2] = 0\n",
    "            mask_temp[zero_to_bsz,initial_area_idx*4 +3] = 0\n",
    "        if torch.cuda.is_available():\n",
    "            Not_choosen_ones = torch.ones(B,size).cuda()\n",
    "        else:\n",
    "            Not_choosen_ones = torch.ones(B,size)\n",
    "        x = torch.zeros(B,dimension)# Y[:,0,:] #set the first point to x\n",
    "        h = None\n",
    "        c = None\n",
    "        context = None        # set Y_ini to the out corner\n",
    "        Transcontext = None\n",
    "        Y0 = None\n",
    "        waiting_time_list = waiting_time_list_initial.repeat(B,1)\n",
    "        if torch.cuda.is_available():\n",
    "            waiting_time_list = waiting_time_list.cuda()\n",
    "        # need a counter_visit here to map the baseline_idx to final_version_idx\n",
    "        counter_visit = torch.zeros(B,int(size_final/4))\n",
    "        if torch.cuda.is_available():\n",
    "            counter_visit = counter_visit.cuda()\n",
    "        # Actor Sampling phase\n",
    "        for k in range(size_rec):\n",
    "            #add the time passed to the time axis of nessesary points\n",
    "            reward_reshape = reward.view(B,1)\n",
    "            waiting_time_list[zero_to_bsz] += Not_choosen_ones[zero_to_bsz] * reward_reshape\n",
    "            R_reshape = R.view(B,1)\n",
    "            temp_remain_wait = waiting_time_list - R_reshape\n",
    "            Y = X_baseline.view(B,size,dimension-1)\n",
    "            Y_final = X.view(B,size_final,dimension)\n",
    "            #refresh the mask list, fits the present situation\n",
    "            mask_temp = unmask_checker(R,B, waiting_time_list, mask_temp)\n",
    "            #check if all the points to be masked,if so, raise the total reward R, and check again\n",
    "            if torch.cuda.is_available():\n",
    "                test_mask_tool = torch.zeros(B,size).cuda()\n",
    "            else:\n",
    "                test_mask_tool = torch.zeros(B,size)\n",
    "            test_mask_tool += mask\n",
    "            test_mask_tool += mask_temp\n",
    "            test_output = F.softmax(test_mask_tool, dim=1)\n",
    "            test_anyone_open = torch.sum(test_output,1)\n",
    "            test_anyone_open = test_anyone_open>0\n",
    "            test_no_one_open = torch.logical_not(test_anyone_open)\n",
    "            if torch.sum(test_no_one_open.type(torch.uint8)) >0:\n",
    "                punishment_of_wait += test_no_one_open*range_of_wait*speed_of_nozzle\n",
    "                temp_waiting = range_of_wait*speed_of_nozzle\n",
    "                mask_temp = unmask_checker(R+temp_waiting,B, waiting_time_list, mask_temp)\n",
    "            # now we need to convert the mask+mask_temp to mask_final and use it \n",
    "            mask_final_temp = mask + mask_temp\n",
    "            # using a function 'logical mask filter'    \n",
    "            mask_final = logical_mask_filter(mask_final_temp, mask_final, map_matrix)\n",
    "            if torch.cuda.is_available():\n",
    "                mask_final = mask_final.cuda()\n",
    "            context, Transcontext, output, h, c, _ = Actor(context,Transcontext,x=x, X_all=X,h=h,\n",
    "                                                           c=c, mask_final=mask_final)\n",
    "            sampler = torch.distributions.Categorical(output)\n",
    "            idx = sampler.sample() #[batch_size, 1]\n",
    "            # this idx here is the final point version, need to transfer to baseline version\n",
    "            \n",
    "            # make a function to map the idx to idx_baseline using counter_visit and mask_list_num_with_lastone\n",
    "            idx_baseline = idx_transfer(counter_visit, mask_list_num_with_lastone, idx,B)\n",
    "            #prepare for the back propagation of pytorch\n",
    "            reward, Y0,x = rectangle_process_actor(temp, idx_baseline,idx,Y,Y_final,Y0,mask,k,B,i,path_gazebo,\n",
    "                                                Not_choosen_ones,Not_last_time,mask_list_num_with_lastone)\n",
    "            \n",
    "            R += reward\n",
    "            logprobs += torch.log(output[zero_to_bsz, idx.data] + TINY)\n",
    "            \n",
    "# critic baseline phase, use the baseline to compute the actual reward of agent at that time\n",
    "        if torch.cuda.is_available():\n",
    "            mask = torch.zeros(B,size).cuda() # use mask to make some points impossible to choose\n",
    "            C = torch.zeros(B).cuda()\n",
    "            punishment_of_wait_critic = torch.zeros(B).cuda()\n",
    "            baseline = torch.zeros(B).cuda()\n",
    "            mask_temp = torch.zeros(B,size).cuda() # mask_temp for temp-masked points(wait for drying)\n",
    "        else:\n",
    "            mask = torch.zeros(B,size) # use mask to make some points impossible to choose\n",
    "            C = torch.zeros(B)\n",
    "            punishment_of_wait_critic = torch.zeros(B)\n",
    "            baseline = torch.zeros(B)\n",
    "            mask_temp = torch.zeros(B,size) # mask_temp for temp-masked points(wait for drying)\n",
    "        mask_temp += -np.inf\n",
    "        for initial_area_idx in mask_list_num:\n",
    "            mask_temp[zero_to_bsz,initial_area_idx*4] = 0\n",
    "            mask_temp[zero_to_bsz,initial_area_idx*4 +1] = 0\n",
    "            mask_temp[zero_to_bsz,initial_area_idx*4 +2] = 0\n",
    "            mask_temp[zero_to_bsz,initial_area_idx*4 +3] = 0\n",
    "        if torch.cuda.is_available():\n",
    "            Not_choosen_ones = torch.ones(B,size).cuda()\n",
    "        else:\n",
    "            Not_choosen_ones = torch.ones(B,size)\n",
    "        x = torch.zeros(B,dimension)#Y[:,0,:] #set the first point to x\n",
    "        h = None\n",
    "        c = None\n",
    "        context = None\n",
    "        Transcontext = None\n",
    "        C0 = None\n",
    "        waiting_time_list = waiting_time_list_initial.repeat(B,1)\n",
    "        if torch.cuda.is_available():\n",
    "            waiting_time_list = waiting_time_list.cuda()\n",
    "        # compute tours for baseline without grad \"Cause we want to fix the weights for the critic\"\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # need a counter_visit here to map the baseline_idx to final_version_idx\n",
    "            counter_visit = torch.zeros(B,int(size_final/4))\n",
    "            if torch.cuda.is_available():\n",
    "                counter_visit = counter_visit.cuda()\n",
    "            for k in range(size_rec):     \n",
    "                baseline_reshape = baseline.view(B,1)\n",
    "                waiting_time_list[zero_to_bsz] += Not_choosen_ones[zero_to_bsz] * baseline_reshape\n",
    "                Y = X_baseline.view(B,size,dimension-1)\n",
    "                Y_final = X.view(B,size_final,dimension)\n",
    "                mask_temp = unmask_checker(C,B, waiting_time_list, mask_temp)\n",
    "                #check if all the points to be masked,if so, raise the total reward R, and check again\n",
    "                if torch.cuda.is_available():\n",
    "                    test_mask_tool = torch.zeros(B,size).cuda()\n",
    "                else:\n",
    "                    test_mask_tool = torch.zeros(B,size)\n",
    "                test_mask_tool += mask\n",
    "                test_mask_tool += mask_temp\n",
    "                test_output = F.softmax(test_mask_tool, dim=1)\n",
    "                test_anyone_open = torch.sum(test_output,1)\n",
    "                test_anyone_open = test_anyone_open>0\n",
    "                test_no_one_open = torch.logical_not(test_anyone_open)\n",
    "                if torch.sum(test_no_one_open.type(torch.uint8)) >0:\n",
    "                    punishment_of_wait_critic += test_no_one_open*range_of_wait*speed_of_nozzle\n",
    "                    temp_waiting = range_of_wait*speed_of_nozzle\n",
    "                    mask_temp = unmask_checker(C+temp_waiting,B, waiting_time_list, mask_temp)\n",
    "                # now we need to convert the mask+mask_temp to mask_final and use it \n",
    "                mask_final_temp = mask + mask_temp\n",
    "                # using a function 'logical mask filter'    \n",
    "                mask_final = logical_mask_filter(mask_final_temp, mask_final, map_matrix)\n",
    "                if torch.cuda.is_available():\n",
    "                    mask_final = mask_final.cuda()\n",
    "                context, Transcontext, output, h, c, _ = Critic(context,Transcontext,x=x, X_all=X,h=h,\n",
    "                                                                c=c, mask_final=mask_final)\n",
    "                idx = torch.argmax(output, dim=1) # ----> greedy baseline critic\n",
    "                # this idx here is the final point version, need to transfer to baseline version\n",
    "                # make a function to map the idx to idx_baseline using counter_visit and mask_list_num_with_lastone\n",
    "                idx_baseline = idx_transfer(counter_visit, mask_list_num_with_lastone, idx,B)\n",
    "                baseline, C0,x = rectangle_process(temp,idx_baseline,idx,Y,Y_final,C0, mask,k,B,\n",
    "                                                   Not_choosen_ones,Not_last_time,mask_list_num_with_lastone)\n",
    "                C += baseline\n",
    "        ###################\n",
    "        # Loss and backprop handling \n",
    "        ###################\n",
    "        C+= punishment_of_wait_critic\n",
    "        R+= punishment_of_wait\n",
    "        loss = torch.mean((R - C) * logprobs)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print(\"epoch:{}, batch:{}/{}, reward:{}\".format(epoch, i, steps,R.mean().item()))\n",
    "            record_actor.append(R.mean().tolist())\n",
    "            record_critic.append(C.tolist())\n",
    "            plt.plot(record_actor,'r:')\n",
    "            plt.plot(record_critic,'b:')\n",
    "            plt.show()\n",
    "        if i % 100 == 0:\n",
    "            print(\"record the last path to gazebo for showing up\")\n",
    "            #starting to show the path on simulated enviroment of cnc_machine \n",
    "            the_resent_path = temp.zig_zag_path(path_gazebo,mask_list_num_with_lastone)\n",
    "            data = {'path':the_resent_path}\n",
    "            data_1 = {'corners':path_gazebo}\n",
    "            pathpoints_dir = os.path.join(\"pathpoints\")\n",
    "            if not os.path.exists(pathpoints_dir):\n",
    "                os.makedirs(pathpoints_dir)\n",
    "            name = 'pathpoints/path_points '+str(i)+'.yaml'\n",
    "            with open(name, 'w') as file:\n",
    "                documents = yaml.dump(data,file)\n",
    "                documents = yaml.dump(data_1,file)\n",
    "            path_gazebo = []\n",
    "    time_one_epoch = time.time() - start #recording the work time of one epoch\n",
    "    time_tot = time.time() - start_training_time + tot_time_ckpt\n",
    "    ###################\n",
    "    # Evaluate train model and baseline \n",
    "    # in this phase we just solve random instances with the actor and the critic\n",
    "    # compare this soluation if we get any improvment we'll transfer the actor's\n",
    "    # weights into the critic\n",
    "    ###################\n",
    "    # putting the actor in the eval mode\n",
    "    Actor.eval()\n",
    "    \n",
    "    mean_tour_length_actor = 0\n",
    "    mean_tour_length_critic = 0\n",
    "\n",
    "    for step in range(0,B_valLoop):\n",
    "        \n",
    "        # compute tour for model and baseline\n",
    "        # mask some points that are not the first visited points\n",
    "        if torch.cuda.is_available():\n",
    "            R = torch.zeros(B).cuda()\n",
    "            punishment_of_wait = torch.zeros(B).cuda()\n",
    "            logprobs = 0\n",
    "            reward = torch.zeros(B).cuda()\n",
    "            mask = torch.zeros(B,size).cuda() # use mask to make some points impossible to choose\n",
    "            mask_temp = torch.zeros(B,size).cuda() # mask_temp for temp-masked points(wait for drying)\n",
    "        else:\n",
    "            R = torch.zeros(B)\n",
    "            punishment_of_wait = torch.zeros(B)\n",
    "            logprobs = 0\n",
    "            reward = torch.zeros(B)\n",
    "            mask = torch.zeros(B,size) # use mask to make some points impossible to choose\n",
    "            mask_temp = torch.zeros(B,size) # mask_temp for temp-masked points(wait for drying)\n",
    "        mask_temp += -np.inf\n",
    "        for initial_area_idx in mask_list_num:\n",
    "            mask_temp[zero_to_bsz,initial_area_idx*4] = 0\n",
    "            mask_temp[zero_to_bsz,initial_area_idx*4 +1] = 0\n",
    "            mask_temp[zero_to_bsz,initial_area_idx*4 +2] = 0\n",
    "            mask_temp[zero_to_bsz,initial_area_idx*4 +3] = 0\n",
    "        if torch.cuda.is_available():\n",
    "            Not_choosen_ones = torch.ones(B,size).cuda()\n",
    "        else:\n",
    "            Not_choosen_ones = torch.ones(B,size)\n",
    "        x = torch.zeros(B,dimension)# Y[:,0,:] #set the first point to x\n",
    "        h = None\n",
    "        c = None\n",
    "        context = None        # set Y_ini to the out corner\n",
    "        Transcontext = None\n",
    "        Y0 = None\n",
    "        waiting_time_list = waiting_time_list_initial.repeat(B,1)\n",
    "        if torch.cuda.is_available():\n",
    "            waiting_time_list = waiting_time_list.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # need a counter_visit here to map the baseline_idx to final_version_idx\n",
    "            counter_visit = torch.zeros(B,int(size_final/4))\n",
    "            if torch.cuda.is_available():\n",
    "                counter_visit = counter_visit.cuda()\n",
    "            for k in range(size_rec):\n",
    "                #add the time passed to the time axis of nessesary points\n",
    "                reward_reshape = reward.view(B,1)\n",
    "                waiting_time_list[zero_to_bsz] += Not_choosen_ones[zero_to_bsz] * reward_reshape\n",
    "                Y = X_baseline.view(B,size,dimension-1)\n",
    "                Y_final = X.view(B,size_final,dimension)\n",
    "                #refresh the mask list, fits the present situation\n",
    "                mask_temp = unmask_checker(R,B, waiting_time_list, mask_temp)\n",
    "                #check if all the points to be masked,if so, raise the total reward R, and check again\n",
    "                if torch.cuda.is_available():\n",
    "                    test_mask_tool = torch.zeros(B,size).cuda()\n",
    "                else:\n",
    "                    test_mask_tool = torch.zeros(B,size)\n",
    "                test_mask_tool += mask\n",
    "                test_mask_tool += mask_temp\n",
    "                test_output = F.softmax(test_mask_tool, dim=1)\n",
    "                test_anyone_open = torch.sum(test_output,1)\n",
    "                test_anyone_open = test_anyone_open>0\n",
    "                test_no_one_open = torch.logical_not(test_anyone_open)\n",
    "                if torch.sum(test_no_one_open.type(torch.uint8)) >0:\n",
    "                    punishment_of_wait += test_no_one_open*range_of_wait*speed_of_nozzle\n",
    "                    temp_waiting = range_of_wait*speed_of_nozzle\n",
    "                    mask_temp = unmask_checker(R+temp_waiting,B, waiting_time_list, mask_temp)\n",
    "                # now we need to convert the mask+mask_temp to mask_final and use it \n",
    "                mask_final_temp = mask + mask_temp\n",
    "                # using a function 'logical mask filter'    \n",
    "                mask_final = logical_mask_filter(mask_final_temp, mask_final, map_matrix)\n",
    "                if torch.cuda.is_available():\n",
    "                    mask_final = mask_final.cuda()\n",
    "                #same as the above part\n",
    "                context, Transcontext, output, h, c, _ = Actor(context,Transcontext,x=x, \n",
    "                                                               X_all=X,h=h, c=c, mask_final=mask_final)\n",
    "                idx = torch.argmax(output, dim=1)\n",
    "                # this idx here is the final point version, need to transfer to baseline version\n",
    "                # make a function to map the idx to idx_baseline using counter_visit and mask_list_num_with_lastone\n",
    "                idx_baseline = idx_transfer(counter_visit, mask_list_num_with_lastone, idx,B)\n",
    "                reward, Y0,x = rectangle_process(temp, idx_baseline, idx, Y,Y_final,Y0, mask,k,B,\n",
    "                                                 Not_choosen_ones,Not_last_time,mask_list_num_with_lastone)\n",
    "                R += reward\n",
    "        # critic baseline\n",
    "        if torch.cuda.is_available():\n",
    "            mask = torch.zeros(B,size).cuda() # use mask to make some points impossible to choose\n",
    "            C = torch.zeros(B).cuda()\n",
    "            punishment_of_wait_critic = torch.zeros(B).cuda()\n",
    "            baseline = torch.zeros(B).cuda()\n",
    "            mask_temp = torch.zeros(B,size).cuda() # mask_temp for temp-masked points(wait for drying)\n",
    "        else:\n",
    "            mask = torch.zeros(B,size) # use mask to make some points impossible to choose\n",
    "            C = torch.zeros(B)\n",
    "            punishment_of_wait_critic = torch.zeros(B)\n",
    "            baseline = torch.zeros(B)\n",
    "            mask_temp = torch.zeros(B,size) # mask_temp for temp-masked points(wait for drying)\n",
    "        mask_temp += -np.inf\n",
    "        for initial_area_idx in mask_list_num:\n",
    "            mask_temp[zero_to_bsz,initial_area_idx*4] = 0\n",
    "            mask_temp[zero_to_bsz,initial_area_idx*4 +1] = 0\n",
    "            mask_temp[zero_to_bsz,initial_area_idx*4 +2] = 0\n",
    "            mask_temp[zero_to_bsz,initial_area_idx*4 +3] = 0\n",
    "        if torch.cuda.is_available():\n",
    "            Not_choosen_ones = torch.ones(B,size).cuda()\n",
    "        else:\n",
    "            Not_choosen_ones = torch.ones(B,size)\n",
    "        x = torch.zeros(B,dimension)#Y[:,0,:] #set the first point to x\n",
    "        h = None\n",
    "        c = None\n",
    "        context = None\n",
    "        Transcontext = None\n",
    "        C0 = None\n",
    "        waiting_time_list = waiting_time_list_initial.repeat(B,1)\n",
    "        if torch.cuda.is_available():\n",
    "            waiting_time_list = waiting_time_list.cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # need a counter_visit here to map the baseline_idx to final_version_idx\n",
    "            counter_visit = torch.zeros(B,int(size_final/4))\n",
    "            if torch.cuda.is_available():\n",
    "                counter_visit = counter_visit.cuda()\n",
    "            for k in range(size_rec):\n",
    "                #same as the above part\n",
    "                baseline_reshape = baseline.view(B,1)\n",
    "                waiting_time_list[zero_to_bsz] += Not_choosen_ones[zero_to_bsz] * baseline_reshape\n",
    "                Y = X_baseline.view(B,size,dimension-1)\n",
    "                Y_final = X.view(B,size_final,dimension)\n",
    "                mask_temp = unmask_checker(C,B, waiting_time_list, mask_temp)\n",
    "                #check if all the points to be masked,if so, raise the total reward R, and check again\n",
    "                if torch.cuda.is_available():\n",
    "                    test_mask_tool = torch.zeros(B,size).cuda()\n",
    "                else:\n",
    "                    test_mask_tool = torch.zeros(B,size)\n",
    "                test_mask_tool += mask\n",
    "                test_mask_tool += mask_temp\n",
    "                test_output = F.softmax(test_mask_tool, dim=1)\n",
    "                test_anyone_open = torch.sum(test_output,1)\n",
    "                test_anyone_open = test_anyone_open>0\n",
    "                test_no_one_open = torch.logical_not(test_anyone_open)\n",
    "                if torch.sum(test_no_one_open.type(torch.uint8)) >0:\n",
    "                    punishment_of_wait_critic += test_no_one_open*range_of_wait*speed_of_nozzle\n",
    "                    temp_waiting = range_of_wait*speed_of_nozzle\n",
    "                    mask_temp = unmask_checker(C+temp_waiting,B, waiting_time_list, mask_temp)\n",
    "                # now we need to convert the mask+mask_temp to mask_final and use it \n",
    "                mask_final_temp = mask + mask_temp\n",
    "                # using a function 'logical mask filter'    \n",
    "                mask_final = logical_mask_filter(mask_final_temp, mask_final, map_matrix)\n",
    "                if torch.cuda.is_available():\n",
    "                    mask_final = mask_final.cuda()\n",
    "                context, Transcontext, output, h, c, _ = Critic(context,Transcontext,x=x, X_all=X,h=h,\n",
    "                                                                c=c, mask_final=mask_final)\n",
    "                idx = torch.argmax(output, dim=1)  \n",
    "                # this idx here is the final point version, need to transfer to baseline version\n",
    "                # make a function to map the idx to idx_baseline using counter_visit and mask_list_num_with_lastone\n",
    "                idx_baseline = idx_transfer(counter_visit, mask_list_num_with_lastone, idx,B)\n",
    "                baseline, C0,x = rectangle_process(temp,idx_baseline, idx ,Y,Y_final,C0, mask,k,B,\n",
    "                                                   Not_choosen_ones,Not_last_time,mask_list_num_with_lastone)\n",
    "                C += baseline\n",
    "        C+= punishment_of_wait_critic\n",
    "        #R+= punishment_of_wait\n",
    "        mean_tour_length_actor  += R.mean().item()\n",
    "        mean_tour_length_critic += C.mean().item()\n",
    "\n",
    "    mean_tour_length_actor  =  mean_tour_length_actor  / B_valLoop\n",
    "    mean_tour_length_critic =  mean_tour_length_critic / B_valLoop\n",
    "    # evaluate train model and baseline and update if train model is better\n",
    "\n",
    "    update_baseline = mean_tour_length_actor + TOL < mean_tour_length_critic\n",
    "\n",
    "    print('Avg Actor {} --- Avg Critic {}'.format(mean_tour_length_actor,mean_tour_length_critic))\n",
    "\n",
    "    if update_baseline:\n",
    "        Critic.load_state_dict(Actor.state_dict())\n",
    "        print('My actor is going on the right road Hallelujah :) Updated')\n",
    "    ###################\n",
    "    # Valdiation train model and baseline on 1k random TSP instances\n",
    "    ###################\n",
    "    # erased by daniel due to the 1K tsp is not the scale I want to train  \n",
    "\n",
    "    # For checkpoint\n",
    "    plot_performance_train.append([(epoch+1), mean_tour_length_actor])\n",
    "    plot_performance_baseline.append([(epoch+1), mean_tour_length_critic])\n",
    "    # compute the optimally gap ==> this is interesting because there is no LKH or other optimal algorithms \n",
    "    # for the problem like this rectangle characterized map\n",
    "    mystring_min = 'Epoch: {:d}, epoch time: {:.3f}min, tot time: {:.3f}day, L_actor: {:.3f}, L_critic: {:.3f}, update: {}'.format(\n",
    "        epoch, time_one_epoch/60, time_tot/86400, mean_tour_length_actor, mean_tour_length_critic, update_baseline)\n",
    "\n",
    "    print(mystring_min)\n",
    "    print('Save Checkpoints')\n",
    "\n",
    "    # Saving checkpoint\n",
    "    checkpoint_dir = os.path.join(\"checkpoint\")\n",
    "\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "    \n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'time': time_one_epoch,\n",
    "        'tot_time': time_tot,\n",
    "        'loss': loss.item(),\n",
    "        'plot_performance_train': plot_performance_train,\n",
    "        'plot_performance_baseline': plot_performance_baseline,\n",
    "        'model_baseline': Critic.state_dict(),\n",
    "        'model_train': Actor.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        },'{}.pkl'.format(checkpoint_dir + \"/checkpoint_\" + time_stamp + \"-n{}\".format(size) + \"-gpu{}\".format(gpu_id)))\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "            \n",
    "                \n",
    "        \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "index = int(9.34)\n",
    "table = [[1,2],[3,4]]\n",
    "table_1 = [[3,44],[5,6]]\n",
    "table = torch.as_tensor(table)\n",
    "table_1 = torch.as_tensor(table_1)\n",
    "result = torch.maximum(table_1[:,0],table_1[:,1])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.zeros(10)\n",
    "a[3] = 10\n",
    "a = a.type(torch.bool)\n",
    "b = a*10\n",
    "print(b)\n",
    "print(0+np.inf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
