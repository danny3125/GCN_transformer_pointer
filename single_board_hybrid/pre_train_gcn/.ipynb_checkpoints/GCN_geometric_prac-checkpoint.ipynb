{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ec2f0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU name: NVIDIA GeForce RTX 2080 Ti, gpu_id: 0\n",
      "cuda\n",
      "pytorch version =  1.10.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "# visualization \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "device = torch.device(\"cpu\"); gpu_id = -1 # select CPU\n",
    "\n",
    "gpu_id = '0' # select a single GPU  \n",
    "#gpu_id = '2,3' # select multiple GPUs  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)  \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('GPU name: {:s}, gpu_id: {:s}'.format(torch.cuda.get_device_name(0),gpu_id))   \n",
    "    \n",
    "print(device)\n",
    "print('pytorch version = ',torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a6b05d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.dense.linear import Linear\n",
    "from torch_geometric.typing import OptTensor, PairOptTensor, PairTensor\n",
    "from torch_geometric.utils import remove_self_loops\n",
    "try:\n",
    "    from torch_cluster import knn\n",
    "except ImportError:\n",
    "    knn = None\n",
    "import math\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "class GravNetConv(MessagePassing):\n",
    "    \n",
    "    def __init__(self, in_channels: int, out_channels: int,\n",
    "                 space_dimensions: int, propagate_dimensions: int, k: int,\n",
    "                 num_workers: Optional[int] = None, **kwargs):\n",
    "        super().__init__(aggr='mean', flow='source_to_target',\n",
    "                         **kwargs)\n",
    "\n",
    "        if knn is None:\n",
    "            raise ImportError('`GravNetConv` requires `torch-cluster`.')\n",
    "\n",
    "        if num_workers is not None:\n",
    "            warnings.warn(\n",
    "                \"'num_workers' attribute in '{self.__class__.__name__}' is \"\n",
    "                \"deprecated and will be removed in a future release\")\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.k = k\n",
    "\n",
    "        self.lin_s = Linear(in_channels, space_dimensions)\n",
    "        self.lin_h = Linear(in_channels, propagate_dimensions)\n",
    "\n",
    "        self.lin_out1 = Linear(in_channels, out_channels, bias=False)\n",
    "        self.lin_out2 = Linear(propagate_dimensions, out_channels)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin_s.reset_parameters()\n",
    "        self.lin_h.reset_parameters()\n",
    "        self.lin_out1.reset_parameters()\n",
    "        self.lin_out2.reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(\n",
    "            self, x: Union[Tensor, PairTensor],\n",
    "            batch: Union[OptTensor, Optional[PairTensor]] = None) -> Tensor:\n",
    "        # type: (Tensor, OptTensor) -> Tensor  # noqa\n",
    "        # type: (PairTensor, Optional[PairTensor]) -> Tensor  # noqa\n",
    "        \"\"\"\"\"\"\n",
    "\n",
    "        is_bipartite: bool = True\n",
    "        if isinstance(x, Tensor):\n",
    "            x: PairTensor = (x, x)\n",
    "            is_bipartite = False\n",
    "\n",
    "        if x[0].dim() != 2:\n",
    "            raise ValueError(\"Static graphs not supported in 'GravNetConv'\")\n",
    "\n",
    "        b: PairOptTensor = (None, None)\n",
    "        if isinstance(batch, Tensor):\n",
    "            b = (batch, batch)\n",
    "        elif isinstance(batch, tuple):\n",
    "            assert batch is not None\n",
    "            b = (batch[0], batch[1])\n",
    "\n",
    "        h_l: Tensor = self.lin_h(x[0])\n",
    "        s_l: Tensor = self.lin_s(x[0])\n",
    "        s_r: Tensor = s_l\n",
    "# x[0] = x[1], s_l = s_r \n",
    "        edge_index = knn(s_l, s_r, self.k, b[0], b[1]).flip([0])\n",
    "        edge_weight = (s_l[edge_index[0]] - s_r[edge_index[1]]).pow(2).sum(-1)\n",
    "        edge_weight = torch.exp(-150. * edge_weight)  # 10 gives a better spread\n",
    "        # propagate_type: (x: OptPairTensor, edge_weight: OptTensor)\n",
    "        out = self.propagate(edge_index, x=(h_l, None),\n",
    "                             edge_weight=edge_weight,\n",
    "                             size=(s_l.size(0), s_r.size(0)))\n",
    "\n",
    "        return self.lin_out1(x[1]) + self.lin_out2(out)\n",
    "\n",
    "\n",
    "    def message(self, x_j: Tensor, edge_weight: Tensor) -> Tensor:\n",
    "        return x_j * edge_weight.unsqueeze(1)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.out_channels}, k={self.k})')\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, n_hidden):\n",
    "        super(Attention, self).__init__()\n",
    "        self.size = 0\n",
    "        self.batch_size = 0\n",
    "        self.dim = n_hidden\n",
    "        \n",
    "        v  = torch.FloatTensor(n_hidden)\n",
    "        self.v  = nn.Parameter(v)\n",
    "        self.v.data.uniform_(-1/math.sqrt(n_hidden), 1/math.sqrt(n_hidden))\n",
    "        \n",
    "        # parameters for pointer attention\n",
    "        self.Wref = nn.Linear(n_hidden, n_hidden)\n",
    "        self.Wq = nn.Linear(n_hidden, n_hidden)\n",
    "    \n",
    "    \n",
    "    def forward(self, q, ref):       # query and reference\n",
    "        self.batch_size = q.size(0)\n",
    "        self.size = int(ref.size(0) / self.batch_size)\n",
    "        q = self.Wq(q)     # (B, dim)\n",
    "        ref = self.Wref(ref)\n",
    "        ref = ref.view(self.batch_size, self.size, self.dim)  # (B, size, dim)\n",
    "        \n",
    "        q_ex = q.unsqueeze(1).repeat(1, self.size, 1) # (B, size, dim)\n",
    "        # v_view: (B, dim, 1)\n",
    "        v_view = self.v.unsqueeze(0).expand(self.batch_size, self.dim).unsqueeze(2)\n",
    "        \n",
    "        # (B, size, dim) * (B, dim, 1)\n",
    "        u = torch.bmm(torch.tanh(q_ex + ref), v_view).squeeze(2)\n",
    "        \n",
    "        return u, ref\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, n_hidden):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        # parameters for input gate\n",
    "        self.Wxi = nn.Linear(n_hidden, n_hidden)    # W(xt)\n",
    "        self.Whi = nn.Linear(n_hidden, n_hidden)    # W(ht)\n",
    "        self.wci = nn.Linear(n_hidden, n_hidden)    # w(ct)\n",
    "        \n",
    "        # parameters for forget gate\n",
    "        self.Wxf = nn.Linear(n_hidden, n_hidden)    # W(xt)\n",
    "        self.Whf = nn.Linear(n_hidden, n_hidden)    # W(ht)\n",
    "        self.wcf = nn.Linear(n_hidden, n_hidden)    # w(ct)\n",
    "        \n",
    "        # parameters for cell gate\n",
    "        self.Wxc = nn.Linear(n_hidden, n_hidden)    # W(xt)\n",
    "        self.Whc = nn.Linear(n_hidden, n_hidden)    # W(ht)\n",
    "        \n",
    "        # parameters for forget gate\n",
    "        self.Wxo = nn.Linear(n_hidden, n_hidden)    # W(xt)\n",
    "        self.Who = nn.Linear(n_hidden, n_hidden)    # W(ht)\n",
    "        self.wco = nn.Linear(n_hidden, n_hidden)    # w(ct)\n",
    "    \n",
    "    \n",
    "    def forward(self, x, h, c):       # query and reference\n",
    "        \n",
    "        # input gate\n",
    "        i = torch.sigmoid(self.Wxi(x) + self.Whi(h) + self.wci(c))\n",
    "        # forget gate\n",
    "        f = torch.sigmoid(self.Wxf(x) + self.Whf(h) + self.wcf(c))\n",
    "        # cell gate\n",
    "        c = f * c + i * torch.tanh(self.Wxc(x) + self.Whc(h))\n",
    "        # output gate\n",
    "        o = torch.sigmoid(self.Wxo(x) + self.Who(h) + self.wco(c))\n",
    "        \n",
    "        h = o * torch.tanh(c)\n",
    "        \n",
    "        return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "409c1fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MLP, DynamicEdgeConv, global_max_pool\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, space_dimensions=10, propagate_dimensions=22 ,k=20, aggr='max'):\n",
    "        super().__init__()\n",
    "        self.conv1 = GravNetConv(n_feature, n_hidden, space_dimensions, propagate_dimensions, k, aggr)\n",
    "        self.embedding_x = nn.Linear(n_feature, n_hidden)\n",
    "        self.start_placeholder = nn.Parameter(torch.randn(n_hidden))\n",
    "        self.encoder = LSTM(n_hidden)\n",
    "        self.Pointer = Attention(n_hidden)\n",
    "        self.batch_size = 0\n",
    "        self.dim = n_hidden\n",
    "        \n",
    "        # trainable first hidden input\n",
    "        h0 = torch.FloatTensor(n_hidden)\n",
    "        c0 = torch.FloatTensor(n_hidden)\n",
    "        self.h0 = nn.Parameter(h0)\n",
    "        self.c0 = nn.Parameter(c0)\n",
    "        self.h0.data.uniform_(-1/math.sqrt(n_hidden), 1/math.sqrt(n_hidden))\n",
    "        self.c0.data.uniform_(-1/math.sqrt(n_hidden), 1/math.sqrt(n_hidden))\n",
    "    def forward(self, data, x, h=None, c=None):\n",
    "        pos, batch, mask, B = data.pos, data.batch, data.mask, data.B\n",
    "        self.batch_size = B\n",
    "        if h is None or c is None:\n",
    "            x          = self.start_placeholder\n",
    "            h0 = self.h0.unsqueeze(0).expand(self.batch_size, self.dim)\n",
    "            c0 = self.c0.unsqueeze(0).expand(self.batch_size, self.dim)\n",
    "            h0 = h0.unsqueeze(0).contiguous()\n",
    "            c0 = c0.unsqueeze(0).contiguous()\n",
    "            # let h0, c0 be the hidden variable of first turn\n",
    "            h = h0.squeeze(0)\n",
    "            c = c0.squeeze(0)\n",
    "        else:\n",
    "            x          = self.embedding_x(x)\n",
    "        h, c = self.encoder(x, h, c)\n",
    "        q = h\n",
    "        GCNcontext = self.conv1(pos, batch)\n",
    "        # GCNcontext.shape = (B*size, n_hidden)\n",
    "        u1 ,_ = self.Pointer(q, GCNcontext)\n",
    "        latent_u = u1.clone()\n",
    "        # n_nidden as output dimension \n",
    "        \n",
    "        out = 10 * torch.tanh(u1)\n",
    "        out = out + mask\n",
    "        return F.softmax(out, dim=1), h, c, latent_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63658724",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This part I designed the rectangle-characterized TSP, that means for every step the agent walk through a corner,\n",
    "then he travel through the whole rectangle using zig-zag, finally he ends up at one of the rest corners of \n",
    "the rextangle, so, it equals the agent walk through three points at one step, in practice, I add three points into \n",
    "mask to make them unselectable.\n",
    "'''\n",
    "def rectangle_process(temp,idx,Y,Y0,mask,k,B,i_step,path_gazebo, visit_count, visit_time_count, X_gcn_original, if_actor):\n",
    "    Y1 = Y[zero_to_bsz, idx.data].clone()\n",
    "    rectangle_inf = idx/4\n",
    "    feature_table = temp.outcorner_getout(rectangle_inf,B)\n",
    "    feature_table = torch.Tensor(feature_table).type(torch.long)\n",
    "    if torch.cuda.is_available():\n",
    "        feature_table = feature_table.cuda()\n",
    "    Y_corner = Y[zero_to_bsz, feature_table[:,0].data].clone()\n",
    "    add_time = visit_time_count[zero_to_bsz, feature_table[:,0].data]*((range_of_wait/2)*speed_of_nozzle)\n",
    "    if torch.cuda.is_available():\n",
    "        add_time = add_time.cuda()\n",
    "    Y_corner[:,dimension-2] = add_time\n",
    "    X_gcn_transfer = X_gcn_original.clone()\n",
    "    for i in range(B):\n",
    "        X_gcn_transfer[i][idx.data[i]][dimension-2] = (add_time[i]/scale_of_the_map[0])\n",
    "        X_gcn_transfer[i][feature_table[:,0].data[i]][dimension-2] = (add_time[i]/scale_of_the_map[0])\n",
    "        X_gcn_transfer[i][feature_table[:,1].data[i]][dimension-2] = (add_time[i]/scale_of_the_map[0])\n",
    "        X_gcn_transfer[i][feature_table[:,2].data[i]][dimension-2] = (add_time[i]/scale_of_the_map[0])\n",
    "    if (i_step % 100 == 0)and(if_actor):\n",
    "        path_gazebo.append([idx.data[0].tolist(),feature_table[:,0].data[0].tolist()])\n",
    "    if k ==0:\n",
    "        if torch.cuda.is_available():\n",
    "            reward = torch.zeros(B).cuda()\n",
    "        else:\n",
    "            reward = torch.zeros(B)\n",
    "    if k > 0:\n",
    "        reward = torch.sum((Y1[:,(0,1)] - Y0[:,(0,1)])**2 , dim=1 )**0.5\n",
    "        reward += torch.sum((Y_corner[:,(0,1)] - Y1[:,(0,1)])**2 , dim=1 )**0.5\n",
    "        #dis = (Y1 - Y0)**2\n",
    "        #dis_1 = (Y_corner - Y1)**2\n",
    "        #reward = torch.maximum(dis[:,0],dis[:,1])**0.5\n",
    "        #reward += torch.maximum(dis_1[:,0],dis_1[:,1])**0.5  \n",
    "    visit_count[zero_to_bsz, idx.data] -= 1\n",
    "    visit_count[zero_to_bsz, feature_table[:,0].data] -= 1\n",
    "    visit_count[zero_to_bsz, feature_table[:,1].data] -= 1\n",
    "    visit_count[zero_to_bsz, feature_table[:,2].data] -= 1\n",
    "    visit_time_count[zero_to_bsz, idx.data] += 1\n",
    "    visit_time_count[zero_to_bsz, feature_table[:,0].data] += 1\n",
    "    visit_time_count[zero_to_bsz, feature_table[:,1].data] += 1\n",
    "    visit_time_count[zero_to_bsz, feature_table[:,2].data] += 1\n",
    "    if_revisited = visit_count[zero_to_bsz, idx.data]<=0\n",
    "    if_revisited = -np.inf*if_revisited\n",
    "    if_revisited[if_revisited!=if_revisited] = 0\n",
    "    mask[zero_to_bsz, idx.data] += if_revisited\n",
    "    mask[zero_to_bsz, feature_table[:,0].data] += if_revisited\n",
    "    mask[zero_to_bsz, feature_table[:,1].data] += if_revisited  \n",
    "    mask[zero_to_bsz, feature_table[:,2].data] += if_revisited\n",
    "    \n",
    "    \n",
    "    \n",
    "    return Y, reward, Y_corner, Y_corner,feature_table[:,0], X_gcn_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e13731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "prepare to train\n",
      "======================\n",
      "Hyper parameters:\n",
      "learning rate 0.005\n",
      "batch size 128\n",
      "steps 500\n",
      "epoch 100\n",
      "======================\n",
      "tensor([[0.6662, 0.1900, 0.0000, 0.0012],\n",
      "        [0.7912, 0.1900, 0.0000, 0.0012],\n",
      "        [0.7912, 0.2075, 0.0000, 0.0012],\n",
      "        [0.6662, 0.2075, 0.0000, 0.0012],\n",
      "        [0.2475, 0.1000, 0.0000, 0.0025],\n",
      "        [0.2950, 0.1000, 0.0000, 0.0025],\n",
      "        [0.2950, 0.1312, 0.0000, 0.0025],\n",
      "        [0.2475, 0.1312, 0.0000, 0.0025],\n",
      "        [0.2138, 0.3500, 0.0000, 0.0012],\n",
      "        [0.2663, 0.3500, 0.0000, 0.0012],\n",
      "        [0.2663, 0.3887, 0.0000, 0.0012],\n",
      "        [0.2138, 0.3887, 0.0000, 0.0012],\n",
      "        [0.5125, 0.1525, 0.0000, 0.0037],\n",
      "        [0.5450, 0.1525, 0.0000, 0.0037],\n",
      "        [0.5450, 0.1675, 0.0000, 0.0037],\n",
      "        [0.5125, 0.1675, 0.0000, 0.0037],\n",
      "        [0.4588, 0.0887, 0.0000, 0.0037],\n",
      "        [0.4800, 0.0887, 0.0000, 0.0037],\n",
      "        [0.4800, 0.1037, 0.0000, 0.0037],\n",
      "        [0.4588, 0.1037, 0.0000, 0.0037],\n",
      "        [0.7400, 0.5625, 0.0000, 0.0037],\n",
      "        [0.8587, 0.5625, 0.0000, 0.0037],\n",
      "        [0.8587, 0.5775, 0.0000, 0.0037],\n",
      "        [0.7400, 0.5775, 0.0000, 0.0037],\n",
      "        [0.9337, 0.1637, 0.0000, 0.0037],\n",
      "        [0.9712, 0.1637, 0.0000, 0.0037],\n",
      "        [0.9712, 0.1850, 0.0000, 0.0037],\n",
      "        [0.9337, 0.1850, 0.0000, 0.0037],\n",
      "        [0.4150, 0.5163, 0.0000, 0.0012],\n",
      "        [0.4712, 0.5163, 0.0000, 0.0012],\n",
      "        [0.4712, 0.5537, 0.0000, 0.0012],\n",
      "        [0.4150, 0.5537, 0.0000, 0.0012],\n",
      "        [0.6413, 0.2887, 0.0000, 0.0012],\n",
      "        [0.6775, 0.2887, 0.0000, 0.0012],\n",
      "        [0.6775, 0.3250, 0.0000, 0.0012],\n",
      "        [0.6413, 0.3250, 0.0000, 0.0012],\n",
      "        [0.1975, 0.1500, 0.0000, 0.0037],\n",
      "        [0.2350, 0.1500, 0.0000, 0.0037],\n",
      "        [0.2350, 0.2925, 0.0000, 0.0037],\n",
      "        [0.1975, 0.2925, 0.0000, 0.0037],\n",
      "        [0.3738, 0.1725, 0.0000, 0.0025],\n",
      "        [0.4150, 0.1725, 0.0000, 0.0025],\n",
      "        [0.4150, 0.3137, 0.0000, 0.0025],\n",
      "        [0.3738, 0.3137, 0.0000, 0.0025],\n",
      "        [0.4462, 0.3587, 0.0000, 0.0025],\n",
      "        [0.4950, 0.3587, 0.0000, 0.0025],\n",
      "        [0.4950, 0.3975, 0.0000, 0.0025],\n",
      "        [0.4462, 0.3975, 0.0000, 0.0025],\n",
      "        [0.3462, 0.6000, 0.0000, 0.0037],\n",
      "        [0.3675, 0.6000, 0.0000, 0.0037],\n",
      "        [0.3675, 0.6137, 0.0000, 0.0037],\n",
      "        [0.3462, 0.6137, 0.0000, 0.0037],\n",
      "        [0.8725, 0.2525, 0.0000, 0.0037],\n",
      "        [0.9425, 0.2525, 0.0000, 0.0037],\n",
      "        [0.9425, 0.2788, 0.0000, 0.0037],\n",
      "        [0.8725, 0.2788, 0.0000, 0.0037],\n",
      "        [0.7650, 0.2800, 0.0000, 0.0012],\n",
      "        [0.8225, 0.2800, 0.0000, 0.0012],\n",
      "        [0.8225, 0.3225, 0.0000, 0.0012],\n",
      "        [0.7650, 0.3225, 0.0000, 0.0012],\n",
      "        [0.5263, 0.3013, 0.0000, 0.0012],\n",
      "        [0.5938, 0.3013, 0.0000, 0.0012],\n",
      "        [0.5938, 0.3262, 0.0000, 0.0012],\n",
      "        [0.5263, 0.3262, 0.0000, 0.0012],\n",
      "        [0.5525, 0.0875, 0.0000, 0.0025],\n",
      "        [0.5763, 0.0875, 0.0000, 0.0025],\n",
      "        [0.5763, 0.1037, 0.0000, 0.0025],\n",
      "        [0.5525, 0.1037, 0.0000, 0.0025],\n",
      "        [0.5450, 0.5550, 0.0000, 0.0025],\n",
      "        [0.6125, 0.5550, 0.0000, 0.0025],\n",
      "        [0.6125, 0.5688, 0.0000, 0.0025],\n",
      "        [0.5450, 0.5688, 0.0000, 0.0025],\n",
      "        [0.3050, 0.4725, 0.0000, 0.0037],\n",
      "        [0.3300, 0.4725, 0.0000, 0.0037],\n",
      "        [0.3300, 0.4863, 0.0000, 0.0037],\n",
      "        [0.3050, 0.4863, 0.0000, 0.0037],\n",
      "        [0.3550, 0.0975, 0.0000, 0.0025],\n",
      "        [0.4075, 0.0975, 0.0000, 0.0025],\n",
      "        [0.4075, 0.1363, 0.0000, 0.0025],\n",
      "        [0.3550, 0.1363, 0.0000, 0.0025],\n",
      "        [0.9050, 0.1075, 0.0000, 0.0037],\n",
      "        [0.9287, 0.1075, 0.0000, 0.0037],\n",
      "        [0.9287, 0.1238, 0.0000, 0.0037],\n",
      "        [0.9050, 0.1238, 0.0000, 0.0037],\n",
      "        [0.5863, 0.2375, 0.0000, 0.0025],\n",
      "        [0.7113, 0.2375, 0.0000, 0.0025],\n",
      "        [0.7113, 0.2550, 0.0000, 0.0025],\n",
      "        [0.5863, 0.2550, 0.0000, 0.0025],\n",
      "        [0.5987, 0.4663, 0.0000, 0.0025],\n",
      "        [0.6475, 0.4663, 0.0000, 0.0025],\n",
      "        [0.6475, 0.5063, 0.0000, 0.0025],\n",
      "        [0.5987, 0.5063, 0.0000, 0.0025],\n",
      "        [0.7887, 0.4225, 0.0000, 0.0037],\n",
      "        [0.8462, 0.4225, 0.0000, 0.0037],\n",
      "        [0.8462, 0.4650, 0.0000, 0.0037],\n",
      "        [0.7887, 0.4650, 0.0000, 0.0037],\n",
      "        [0.3050, 0.2812, 0.0000, 0.0037],\n",
      "        [0.3462, 0.2812, 0.0000, 0.0037],\n",
      "        [0.3462, 0.4225, 0.0000, 0.0037],\n",
      "        [0.3050, 0.4225, 0.0000, 0.0037]])\n",
      "[[533, 152, 0, 1], [633, 152, 0, 1], [633, 166, 0, 1], [533, 166, 0, 1], [198, 80, 0, 2], [236, 80, 0, 2], [236, 105, 0, 2], [198, 105, 0, 2], [171, 280, 0, 1], [213, 280, 0, 1], [213, 311, 0, 1], [171, 311, 0, 1], [410, 122, 0, 3], [436, 122, 0, 3], [436, 134, 0, 3], [410, 134, 0, 3], [367, 71, 0, 3], [384, 71, 0, 3], [384, 83, 0, 3], [367, 83, 0, 3], [592, 450, 0, 3], [687, 450, 0, 3], [687, 462, 0, 3], [592, 462, 0, 3], [747, 131, 0, 3], [777, 131, 0, 3], [777, 148, 0, 3], [747, 148, 0, 3], [332, 413, 0, 1], [377, 413, 0, 1], [377, 443, 0, 1], [332, 443, 0, 1], [513, 231, 0, 1], [542, 231, 0, 1], [542, 260, 0, 1], [513, 260, 0, 1], [158, 120, 0, 3], [188, 120, 0, 3], [188, 234, 0, 3], [158, 234, 0, 3], [299, 138, 0, 2], [332, 138, 0, 2], [332, 251, 0, 2], [299, 251, 0, 2], [357, 287, 0, 2], [396, 287, 0, 2], [396, 318, 0, 2], [357, 318, 0, 2], [277, 480, 0, 3], [294, 480, 0, 3], [294, 491, 0, 3], [277, 491, 0, 3], [698, 202, 0, 3], [754, 202, 0, 3], [754, 223, 0, 3], [698, 223, 0, 3], [612, 224, 0, 1], [658, 224, 0, 1], [658, 258, 0, 1], [612, 258, 0, 1], [421, 241, 0, 1], [475, 241, 0, 1], [475, 261, 0, 1], [421, 261, 0, 1], [442, 70, 0, 2], [461, 70, 0, 2], [461, 83, 0, 2], [442, 83, 0, 2], [436, 444, 0, 2], [490, 444, 0, 2], [490, 455, 0, 2], [436, 455, 0, 2], [244, 378, 0, 3], [264, 378, 0, 3], [264, 389, 0, 3], [244, 389, 0, 3], [284, 78, 0, 2], [326, 78, 0, 2], [326, 109, 0, 2], [284, 109, 0, 2], [724, 86, 0, 3], [743, 86, 0, 3], [743, 99, 0, 3], [724, 99, 0, 3], [469, 190, 0, 2], [569, 190, 0, 2], [569, 204, 0, 2], [469, 204, 0, 2], [479, 373, 0, 2], [518, 373, 0, 2], [518, 405, 0, 2], [479, 405, 0, 2], [631, 338, 0, 3], [677, 338, 0, 3], [677, 372, 0, 3], [631, 372, 0, 3], [244, 225, 0, 3], [277, 225, 0, 3], [277, 338, 0, 3], [244, 338, 0, 3]]\n",
      "[0, 1, 3, 4, 7, 10, 13, 16, 17, 18, 21, 23, 25, 28, 31, 32, 33, 35, 37, 40, 42, 45, 47, 49, 52, 55]\n",
      "55\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "tensor([ 1., 18.,  9.,  9., 12.,  2., 18., 12., 10.,  9., 18., 12., 24., 24.,\n",
      "        19.,  1., 10., 24.,  4., 19.,  3.,  3., 11.,  7., 11.,  4.,  3., 21.,\n",
      "         4., 15., 21., 16., 17., 17., 16., 22.,  8., 22.,  5.,  0.,  5., 13.,\n",
      "        13., 23., 14., 23.,  5., 23., 13.,  6., 20., 20.,  6., 20.,  6.],\n",
      "       device='cuda:0')\n",
      "torch.Size([12800, 48])\n",
      "epoch:0, batch:100/500, reward:13216.044921875\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAASD0lEQVR4nO3dfYxc1X3G8e/TOOGtBRp7acBrahJcpNAgikfUf6QqDYVaNAEqqIqayki15ICKlCqlFGQFGiGkOlR1RJtSWYFgEyBUpBGIl4S2VEWKHKdrwBgS0pgU8AZSm4CAtGoSwq9/zFkYNrPe9eyudxe+H+lq75yXmXM00j5z7r0zN1WFJEk/N9cDkCTNDwaCJAkwECRJjYEgSQIMBElSs2iuBzCoJUuW1PLly+d6GJK0oGzfvv35qhrqVzdpICS5EfgwsKeqfnVc3aXAtcBQVT2f5Azgr4B3AT8G/ryqHmhtVwI3AYcA9wIfr6pKchCwBVgJ/AD4g6p6arJxLV++nJGRkcmaSZJ6JHl6orqpHDK6CVjd50mXAWcAz/QUPw98pKo+AFwI3NxTdz2wDljRtrHnXAu8WFXHAxuBDVMYkyRphk0aCFX1IPBCn6qNwGVA9bR9uKqebQ8fBw5OclCSo4HDq2prdb8JtwU4t7U7B9jc9u8ATk+SQSYjSRrcQCeVk5wNfK+qduyj2XnAw1X1I2ApMNpTN9rKaH93A1TVq8BLwOIJXnddkpEkI3v37h1k6JKkCez3SeUkhwLrgTP30eZEuod+xtr0+8RfU6h7c2HVJmATQKfT8Tc3JGkGDbJCeB9wHLAjyVPAMPBQkvcAJBkGvgysqaonW5/R1m7MMPBsT92y1ncRcAT9D1FJkmbRfgdCVe2sqqOqanlVLaf7D/2Uqvp+kiOBe4ArquprPX2eA15JsqqdH1gD3Nmq76J7AhrgfOCB8hf3JOmAmzQQktwGbAVOSDKaZO0+ml8CHA98MskjbTuq1V0MfA7YBTwJ3NfKbwAWJ9kFfAK4fLCpSJKmIwv1w3in0ym/hyBJ+yfJ9qrq9KvzpyskSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTEQJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxkCQJAEGgiSpMRAkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKkxECRJwBQCIcmNSfYkeaxP3aVJKsmSnrIrkuxK8u0kv9NTvjLJzlZ3XZK08oOS3N7KtyVZPkNzkyTth6msEG4CVo8vTLIMOAN4pqfs/cAFwImtz98neUervh5YB6xo29hzrgVerKrjgY3AhkEmIkmankkDoaoeBF7oU7URuAyonrJzgC9W1Y+q6r+AXcCpSY4GDq+qrVVVwBbg3J4+m9v+HcDpY6sHSdKBM9A5hCRnA9+rqh3jqpYCu3sej7aypW1/fPmb+lTVq8BLwOIJXnddkpEkI3v37h1k6JKkCex3ICQ5FFgPXNmvuk9Z7aN8X31+trBqU1V1qqozNDQ0leFKkqZokBXC+4DjgB1JngKGgYeSvIfuJ/9lPW2HgWdb+XCfcnr7JFkEHEH/Q1SSpFm034FQVTur6qiqWl5Vy+n+Qz+lqr4P3AVc0K4cOo7uyeNvVNVzwCtJVrXzA2uAO9tT3gVc2PbPBx5o5xkkSQfQVC47vQ3YCpyQZDTJ2onaVtXjwD8C3wS+AvxJVf20VV8MfI7uieYngfta+Q3A4iS7gE8Alw84F0nSNGShfhjvdDo1MjIy18OQpAUlyfaq6vSr85vKkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUTBoISW5MsifJYz1lVyd5NMkjSe5Pckwrf2eSzUl2JvlWkit6+qxs5buSXJckrfygJLe38m1Jls/CPCVJk5jKCuEmYPW4smur6qSqOhm4G7iylf8+cFBVfQBYCXys5x/89cA6YEXbxp5zLfBiVR0PbAQ2DDQTSdK0TBoIVfUg8MK4spd7Hh4G1FgVcFiSRcAhwI+Bl5McDRxeVVurqoAtwLmtzznA5rZ/B3D62OpBknTgDHwOIck1SXYDH+WNFcIdwP8AzwHPAH9dVS8AS4HRnu6jrYz2dzdAVb0KvAQsnuA11yUZSTKyd+/eQYcuSepj4ECoqvVVtQy4BbikFZ8K/BQ4BjgO+LMk7wX6feIfW1Xsq278a26qqk5VdYaGhgYduiSpj5m4yuhW4Ly2/4fAV6rqJ1W1B/ga0KG7Ihju6TMMPNv2R4FlAO1Q0xGMO0QlSZp9AwVCkhU9D88Gnmj7zwAfStdhwCrgiap6Dnglyap2fmANcGfrcxdwYds/H3ignWeQJB1AiyZrkOQ24DRgSZJR4CrgrCQnAK8BTwMXteafBT4PPEb3UNDnq+rRVncx3SuWDgHuaxvADcDNSXbRXRlcMO1ZSZL2Wxbqh/FOp1MjIyNzPQxJWlCSbK+qTr86v6ksSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEnNpIGQ5MYke5I81lN2dZJHkzyS5P4kx/TUnZRka5LHk+xMcnArX9ke70pyXZK08oOS3N7KtyVZPgvzlCRNYiorhJuA1ePKrq2qk6rqZOBu4EqAJIuALwAXVdWJwGnAT1qf64F1wIq2jT3nWuDFqjoe2AhsGHAukqRpmDQQqupB4IVxZS/3PDwMqLZ/JvBoVe1o7X5QVT9NcjRweFVtraoCtgDntj7nAJvb/h3A6WOrB0nSgTPwOYQk1yTZDXyUtkIAfgWoJF9N8lCSy1r5UmC0p/toKxur2w1QVa8CLwGLBx2XJGkwAwdCVa2vqmXALcAlrXgR8EG6IfFB4PeSnA70+8Q/tqrYV92bJFmXZCTJyN69ewcduiSpj5m4yuhW4Ly2Pwr8e1U9X1X/C9wLnNLKh3v6DAPP9vRZBq+fgziCcYeoxlTVpqrqVFVnaGhoBoYuSRozUCAkWdHz8Gzgibb/VeCkJIe2f+6/CXyzqp4DXkmyqp0fWAPc2frcBVzY9s8HHmjnGSRJB9CiyRokuY3u1UJLkowCVwFnJTkBeA14GrgIoKpeTPI3wH/QPexzb1Xd057qYrpXLB0C3Nc2gBuAm5PsorsyuGBGZiZJ2i9ZqB/GO51OjYyMzPUwJGlBSbK9qjr96vymsiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAmYQiAkuTHJniSP9ZRdneTRJI8kuT/JMeP6HJvkh0ku7SlbmWRnkl1JrkuSVn5Qkttb+bYky2dwfpKkKZrKCuEmYPW4smur6qSqOhm4G7hyXP1G4L5xZdcD64AVbRt7zrXAi1V1fOu3YaqDlyTNnEkDoaoeBF4YV/Zyz8PDgBp7kORc4LvA4z1lRwOHV9XWqipgC3Buqz4H2Nz27wBOH1s9SJIOnIHPISS5Jslu4KO0FUKSw4C/AD41rvlSYLTn8WgrG6vbDVBVrwIvAYsneM11SUaSjOzdu3fQoUuS+hg4EKpqfVUtA24BLmnFnwI2VtUPxzXv94m/plA3/jU3VVWnqjpDQ0ODDFuSNIFFM/ActwL3AFcBvw6cn+TTwJHAa0n+D/gSMNzTZxh4tu2PAsuA0SSLgCMYd4hKkjT7BgqEJCuq6jvt4dnAEwBV9Rs9bf4S+GFV/V17/EqSVcA2YA3wt63pXcCFwFbgfOCBdp5BknQATRoISW4DTgOWJBmluxI4K8kJwGvA08BFU3iti+lesXQI3SuQxq5CugG4OckuuiuDC/ZvCpKkmZCF+mG80+nUyMjIXA9DkhaUJNurqtOvzm8qS5IAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSM2kgJLkxyZ4kj/WUXZ3k0SSPJLk/yTGt/Iwk25PsbH8/1NNnZSvfleS6JGnlByW5vZVvS7J8FuYpSZrEVFYINwGrx5VdW1UnVdXJwN3Ala38eeAjVfUB4ELg5p4+1wPrgBVtG3vOtcCLVXU8sBHYsP/TkCRN16SBUFUPAi+MK3u55+FhQLXyh6vq2Vb+OHBwWwEcDRxeVVurqoAtwLmt3TnA5rZ/B3D62OpBknTgLBq0Y5JrgDXAS8Bv9WlyHvBwVf0oyVJgtKduFFja9pcCuwGq6tUkLwGL6a42xr/mOrqrDI499thBhy5J6mPgk8pVtb6qlgG3AJf01iU5ke6hn4+NFfV7iinUjX/NTVXVqarO0NDQYAOXJPU1E1cZ3Up3NQBAkmHgy8CaqnqyFY8Cwz19hoFne+qWtb6LgCMYd4hKkjT7BgqEJCt6Hp4NPNHKjwTuAa6oqq+NNaiq54BXkqxq5wfWAHe26rvonoAGOB94oJ1nkCQdQJOeQ0hyG3AasCTJKHAVcFaSE4DXgKeBi1rzS4DjgU8m+WQrO7Oq9gAX071i6RDgvrYB3ADcnGQX3ZXBBdOfliRpf2WhfhjvdDo1MjIy18OQpAUlyfaq6vSr85vKkiRgAa8Qkuyle7hqoVlCn0tq3+LebnN+u80XnPNC8stV1fcyzQUbCAtVkpGJlmtvVW+3Ob/d5gvO+a3CQ0aSJMBAkCQ1BsKBt2muBzAH3m5zfrvNF5zzW4LnECRJgCsESVJjIEiSAANhxiV5d5J/TvKd9vcXJ2i3Osm3253iLu9Tf2mSSrJk9kc9PdOdc5JrkzzR7sL35fabWPPSFN63tDsC7mrzOWWqfeerQeecZFmSf0vyrSSPJ/n4gR/9YKbzPrf6dyR5OMndB27UM6Cq3GZwAz4NXN72Lwc29GnzDuBJ4L3Au4AdwPt76pcBX6X7xbslcz2n2Z4zcCawqO1v6Nd/PmyTvW+tzVl0f6crwCpg21T7zsdtmnM+Gjil7f8C8J9v9Tn31H+C7i9B3z3X89mfzRXCzOu9A9xm3rgzXK9TgV1V9d2q+jHwxdZvzEbgMia4L8Q8NK05V9X9VfVqa/d13vxT6fPJZO8b7fGW6vo6cGS7Y+BU+s5HA8+5qp6rqocAquoV4Fu8cWOs+Ww67/PYLQB+F/jcgRz0TDAQZt4vVffnvml/j+rT5vW7xDWv30EuydnA96pqx2wPdAZNa87j/DFv/BLufDOVOUzUZqrzn2+mM+fXJVkO/BqwbeaHOOOmO+fP0P1A99osjW/WDHwLzbezJP8CvKdP1fqpPkWfskpyaHuOMwcd22yZrTmPe431wKt078I3H03l7n4TtZnynQHnmenMuVuZ/DzwJeBP6833Y5+vBp5zkg8De6pqe5LTZnpgs81AGEBV/fZEdUn+e2y53JaQe/o0e/0ucc3YHeTeBxwH7OjeR4hh4KEkp1bV92dsAgOYxTmPPceFwIeB06sdhJ2H9jmHSdq8awp956PpzJkk76QbBrdU1T/N4jhn0nTmfD5wdpKzgIOBw5N8oar+aBbHO3Pm+iTGW20DruXNJ1g/3afNIuC7dP/5j520OrFPu6dYGCeVpzVnYDXwTWBorucyyTwnfd/oHjvuPdn4jf15z+fbNs05B9gCfGau53Gg5jyuzWkssJPKcz6At9oGLAb+FfhO+/vuVn4McG9Pu7PoXnXxJLB+gudaKIEwrTkDu+gej32kbf8w13Pax1x/Zg507xh4UdsP8NlWvxPo7M97Ph+3QecMfJDuoZZHe97bs+Z6PrP9Pvc8x4ILBH+6QpIEeJWRJKkxECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpOb/AYnOgaFL8Oe6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "record the last path to gazebo for showing up\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n",
      "torch.Size([12800, 48])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import knn_graph\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "from listofpathpoint import input_handler\n",
    "import yaml\n",
    "from torch.distributions.categorical import Categorical\n",
    "# visualization\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from tqdm import tqdm_notebook\n",
    "import torch.nn.functional as F\n",
    "####### my own import file ##########\n",
    "from listofpathpoint import input_handler\n",
    "import cnc_input\n",
    "import copy\n",
    "#from hybrid_models import HPN\n",
    "####### my own import file ##########\n",
    "'''\n",
    "so, the models we have are TransEncoderNet,\n",
    "                            Attention\n",
    "                            LSTM\n",
    "                            HPN\n",
    "each one have initial parameters and the forward part, \n",
    "once we have the forward part, the back propagation will \n",
    "finished automatically by pytorch  \n",
    "'''\n",
    "TOL = 1e-3\n",
    "TINY = 1e-15\n",
    "learning_rate = 0.005   #learning rate\n",
    "B = 128          #batch size\n",
    "B_valLoop = 1\n",
    "steps = 500\n",
    "n_epoch = 100       # epochs\n",
    "map_number = 0\n",
    "record_actor = []\n",
    "record_critic = []\n",
    "dimension = 4\n",
    "speed_of_nozzle = 30\n",
    "range_of_wait = 20\n",
    "scale_of_the_map = (800,500,speed_of_nozzle*range_of_wait)\n",
    "maplist = ['10&15data/25_chips/25_1.json'\n",
    "          ,'10&15data/25_chips/25_1.json','10&15data/25_chips/25_1.json'\\\n",
    "          ,'10&15data/25_chips/25_1.json','10&15data/25_chips/25_1.json'\\\n",
    "          ,'10&15data/25_chips/25_1.json'\n",
    "          ]\n",
    "print('======================')\n",
    "print('prepare to train')\n",
    "print('======================')\n",
    "print('Hyper parameters:')\n",
    "print('learning rate', learning_rate)\n",
    "print('batch size', B)\n",
    "print('steps', steps)\n",
    "print('epoch', n_epoch)\n",
    "print('======================')\n",
    "\n",
    "'''\n",
    "instantiate a training network and a baseline network\n",
    "'''\n",
    "temp = input_handler(maplist[map_number])\n",
    "x_gcn_temp, mask_list_num = temp.final_ver_points()\n",
    "\n",
    "try:\n",
    "    del Actor  # remove existing model\n",
    "    del Critic # remove existing model\n",
    "except:\n",
    "    pass\n",
    "Actor = Net(n_feature=4, n_hidden=48).to(device)\n",
    "Critic = Net(n_feature=4, n_hidden=48).to(device)\n",
    "optimizer = optim.Adam(Actor.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "# Putting Critic model on the eval mode\n",
    "Actor = Actor.to(device)\n",
    "Critic = Critic.to(device)\n",
    "Critic.eval()\n",
    "\n",
    "epoch_ckpt = 0\n",
    "tot_time_ckpt = 0\n",
    "\n",
    "val_mean = []\n",
    "val_std = []\n",
    "          \n",
    "plot_performance_train = []\n",
    "plot_performance_baseline = []\n",
    "# recording the result of the resent epoch makes it available for future\n",
    "#*********************# Uncomment these lines to load the previous check point\n",
    "\"\"\"\n",
    "checkpoint_file = \"checkpoint/mutimap_20.pkl\"\n",
    "checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "epoch_ckpt = checkpoint['epoch'] + 1\n",
    "tot_time_ckpt = checkpoint['tot_time']\n",
    "plot_performance_train = checkpoint['plot_performance_train']\n",
    "plot_performance_baseline = checkpoint['plot_performance_baseline']\n",
    "Critic.load_state_dict(checkpoint['model_baseline'])\n",
    "Actor.load_state_dict(checkpoint['model_train'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "print('Re-start training with saved checkpoint file={:s}\\n  Checkpoint at epoch= {:d} and time={:.3f}min\\n'.format(checkpoint_file,epoch_ckpt-1,tot_time_ckpt/60))\n",
    "\"\"\"\n",
    "\n",
    "#***********************# Uncomment these lines to load the previous check point\n",
    "\n",
    "# Main training loop\n",
    "# The core training concept mainly upon Sampling from the actor\n",
    "# then taking the greedy action from the critic\n",
    "\n",
    "start_training_time = time.time()\n",
    "time_stamp = datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\") # Load the time stamp\n",
    "\n",
    "C = 0       # baseline => the object which the actor can compare\n",
    "R = 0       # reward\n",
    "# load 100 points into the program \n",
    "x_gcn_temp = torch.Tensor(x_gcn_temp).type(torch.float)\n",
    "x_gcn_temp /= scale_of_the_map[0]\n",
    "X_temp, mask_list_num = temp.final_ver_points()\n",
    "print(x_gcn_temp)\n",
    "print(X_temp)\n",
    "print(mask_list_num)\n",
    "#change the waiting time to the distance that we can measure\n",
    "size = len(X_temp)\n",
    "zero_to_bsz = torch.arange(B, device = device) # a list contains 0 to (batch size -1)\n",
    "batch = torch.arange(B)\n",
    "batch = batch.repeat_interleave(size)\n",
    "for corner in X_temp:\n",
    "    corner[dimension -2] *= speed_of_nozzle\n",
    "size_rec = mask_list_num[-1]\n",
    "print(size_rec)\n",
    "\n",
    "X_temp = torch.FloatTensor(X_temp)\n",
    "visit_count_initial = X_temp[:,dimension-1]\n",
    "visit_count_rec = []\n",
    "for i in range(0,len(visit_count_initial),4):\n",
    "    visit_count_rec.append(int(visit_count_initial[i]))\n",
    "X = X_temp.repeat(B,1,1)\n",
    "if torch.cuda.is_available():\n",
    "    X = X.cuda()\n",
    "\n",
    "for epoch in range(0, n_epoch):\n",
    "    # re-start training with saved checkpoint\n",
    "    epoch += epoch_ckpt # adding the number of the former epochs\n",
    "    # Train the model for one epoch\n",
    "    start = time.time() # record the starting time\n",
    "    Actor.train() \n",
    "    path_gazebo = []\n",
    "    for i_all in range(1, steps+1): # 1 ~ 2500 steps\n",
    "        # mask some points that are not the first visited points\n",
    "        if torch.cuda.is_available():\n",
    "            R = torch.zeros(B).cuda()\n",
    "            reward_recorder = torch.zeros(B,size_rec).cuda()\n",
    "            idx_recorder = torch.zeros(B,size_rec).cuda()\n",
    "            logprobs = 0\n",
    "            reward = torch.zeros(B).cuda()\n",
    "            mask = torch.zeros(B,size).cuda() # use mask to make some points impossible to choose\n",
    "            X_gcn_original = x_gcn_temp.repeat(B,1,1).cuda()\n",
    "        else:\n",
    "            R = torch.zeros(B)\n",
    "            reward_recorder = torch.zeros(B,size_rec)\n",
    "            idx_recorder = torch.zeros(B,size_rec)\n",
    "            logprobs = 0\n",
    "            reward = torch.zeros(B)\n",
    "            mask = torch.zeros(B,size) # use mask to make some points impossible to choose\n",
    "            X_gcn_original = x_gcn_temp.repeat(B,1,1)\n",
    "        x = torch.zeros(B,dimension)# Y[:,0,:] #set the first point to x\n",
    "        h = None\n",
    "        c = None\n",
    "        GCNcontext = None\n",
    "        Y0 = None\n",
    "        choosen_idx = None\n",
    "        visit_count = visit_count_initial.repeat(B,1)\n",
    "        visit_time_count_initial = torch.zeros(len(visit_count_initial))\n",
    "        visit_time_count = visit_time_count_initial.repeat(B,1)\n",
    "        if torch.cuda.is_available():\n",
    "            visit_count = visit_count.cuda()\n",
    "            batch = batch.cuda()\n",
    "        # Actor Sampling phase\n",
    "        for k in range(size_rec):\n",
    "            if k ==0:\n",
    "                Y = X.view(B,size,dimension)\n",
    "            X_gcn = X_gcn_original.view(B*size,dimension)\n",
    "            data = Data(pos=X_gcn,batch=batch,mask=mask,B=B)\n",
    "            output, h, c, _ = Actor(data, x=x, h=h, c=c)\n",
    "            sampler = torch.distributions.Categorical(output)\n",
    "            idx = sampler.sample()\n",
    "            idx_recorder[:,k] = (idx/4).type(torch.long)\n",
    "            # prepare for the back propagation of pytorch\n",
    "            Y, reward, Y0, x, choosen_idx, X_gcn_original = rectangle_process(temp, idx,Y,Y0,mask,k,B,i_all,path_gazebo,\n",
    "                                                visit_count, visit_time_count, X_gcn_original, if_actor=True)\n",
    "\n",
    "            # change the input data X_gcn to match the current situation on map\n",
    "            R += reward\n",
    "            reward_recorder[:,k] = R\n",
    "            logprobs += torch.log(output[zero_to_bsz, idx.data] + TINY)\n",
    "            \n",
    "        # now it's time to check if any trajectory should be punished due to waiting on the same rectangle\n",
    "\n",
    "        trajec_count = 0\n",
    "        if i_all%100 ==0:\n",
    "            print(idx_recorder[0])\n",
    "        for path_time in zip(idx_recorder,reward_recorder):\n",
    "            idx_time = zip(path_time[0],path_time[1])\n",
    "            idx_time = sorted(idx_time, key=lambda x: x[0])\n",
    "            total_idx = 0\n",
    "            extra_waiting_time = 0\n",
    "            for item in visit_count_rec:\n",
    "                compare_list = []\n",
    "                if item>1:\n",
    "                    for i in range(int(item)):\n",
    "                        compare_list.append(idx_time[int(total_idx + i)][1])\n",
    "                    compare_list.sort(reverse=True)\n",
    "                    total_idx += item\n",
    "                    for i in range(len(compare_list)-1):\n",
    "                        dis_step = compare_list[i] - compare_list[i+1]\n",
    "                        dry_time = (range_of_wait/2)*speed_of_nozzle\n",
    "                        if (dis_step) < (dry_time):\n",
    "                            extra_waiting_time += dry_time - dis_step\n",
    "                else:\n",
    "                    total_idx += item\n",
    "            R[trajec_count] += extra_waiting_time\n",
    "            trajec_count+=1\n",
    "                    \n",
    "                \n",
    "        \n",
    "# # critic baseline phase, use the baseline to compute the actual reward of agent at that time\n",
    "        if torch.cuda.is_available():\n",
    "            C = torch.zeros(B).cuda()\n",
    "            reward_recorder = torch.zeros(B,size_rec).cuda()\n",
    "            idx_recorder = torch.zeros(B,size_rec).cuda()\n",
    "            baseline = torch.zeros(B).cuda()\n",
    "            mask = torch.zeros(B,size).cuda() # use mask to make some points impossible to choose\n",
    "            X_gcn_original = x_gcn_temp.repeat(B,1,1).cuda()\n",
    "        else:\n",
    "            C = torch.zeros(B)\n",
    "            reward_recorder = torch.zeros(B,size_rec)\n",
    "            idx_recorder = torch.zeros(B,size_rec)\n",
    "            baseline = torch.zeros(B)\n",
    "            mask = torch.zeros(B,size) # use mask to make some points impossible to choose\n",
    "            X_gcn_original = x_gcn_temp.repeat(B,1,1)\n",
    "        x = torch.zeros(B,dimension)#Y[:,0,:] #set the first point to x\n",
    "        h = None\n",
    "        c = None\n",
    "        context = None\n",
    "        Transcontext = None\n",
    "        GCNcontext = None\n",
    "        C0 = None\n",
    "        choosen_idx = None\n",
    "        visit_count = visit_count_initial.repeat(B,1)\n",
    "        visit_time_count_initial = torch.zeros(len(visit_count_initial))\n",
    "        visit_time_count = visit_time_count_initial.repeat(B,1)\n",
    "        if torch.cuda.is_available():\n",
    "            visit_count = visit_count.cuda()\n",
    "        # compute tours for baseline without grad \"Cause we want to fix the weights for the critic\"\n",
    "        with torch.no_grad():\n",
    "            for k in range(size_rec): \n",
    "                if k ==0:\n",
    "                    Y = X.view(B,size,dimension)\n",
    "                #check if all the points to be masked,if so, raise the total reward R, and check again\n",
    "                X_gcn = X_gcn_original.view(B*size,dimension)\n",
    "                data = Data(pos=X_gcn,batch=batch,mask=mask,B=B)\n",
    "                output, h, c, _ = Critic(data, x=x, h=h, c=c)\n",
    "                idx = torch.argmax(output, dim=1) # ----> greedy baseline critic\n",
    "                idx_recorder[:,k] = (idx/4).type(torch.long)\n",
    "                # prepare for the back propagation of pytorch\n",
    "                Y, baseline, C0, x, choosen_idx, X_gcn_original = rectangle_process(temp,idx,Y,C0, mask,k,B,i,path_gazebo,\n",
    "                                                   visit_count, visit_time_count, X_gcn_original, if_actor=False)\n",
    "                C += baseline\n",
    "                reward_recorder[:,k] = C\n",
    "                    #now is the time to check if any trajectory should be punished due to waiting on the same rectangle\n",
    "\n",
    "            trajec_count = 0\n",
    "            for path_time in zip(idx_recorder,reward_recorder):\n",
    "                idx_time = zip(path_time[0],path_time[1])\n",
    "                idx_time = sorted(idx_time, key=lambda x: x[0])\n",
    "                total_idx = 0\n",
    "                extra_waiting_time = 0\n",
    "                for item in visit_count_rec:\n",
    "                    compare_list = []\n",
    "                    if item>1:\n",
    "                        for i in range(int(item)):\n",
    "                            compare_list.append(idx_time[int(total_idx + i)][1])\n",
    "                        compare_list.sort(reverse=True)\n",
    "                        total_idx += item\n",
    "                        for i in range(len(compare_list)-1):\n",
    "                            dis_step = compare_list[i] - compare_list[i+1]\n",
    "                            dry_time = (range_of_wait/2)*speed_of_nozzle\n",
    "                            if (dis_step) < (dry_time):\n",
    "                                extra_waiting_time += dry_time - dis_step\n",
    "                    else:\n",
    "                        total_idx += item\n",
    "                C[trajec_count] += extra_waiting_time\n",
    "                trajec_count+=1\n",
    "        ###################\n",
    "        # Loss and backprop handling \n",
    "        ###################\n",
    "        loss = torch.mean((R - C) * logprobs)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i_all % 100 == 0:\n",
    "            print(\"epoch:{}, batch:{}/{}, reward:{}\".format(epoch, i_all, steps,R.mean().item()))\n",
    "            record_actor.append(R.mean().tolist())\n",
    "            record_critic.append(C.mean().tolist())\n",
    "            plt.plot(record_actor,'r:')\n",
    "            plt.plot(record_critic,'b:')\n",
    "            plt.show()\n",
    "        if i_all % 100 == 0:\n",
    "            print(\"record the last path to gazebo for showing up\")\n",
    "            #starting to show the path on simulated enviroment of cnc_machine \n",
    "            the_resent_path = temp.zig_zag_path(path_gazebo,mask_list_num)\n",
    "            data = {'path':the_resent_path}\n",
    "            data_1 = {'corners':path_gazebo}\n",
    "            pathpoints_dir = os.path.join(\"pathpoints\")\n",
    "            if not os.path.exists(pathpoints_dir):\n",
    "                os.makedirs(pathpoints_dir)\n",
    "            name = 'pathpoints/path_points '+str(i)+'.yaml'\n",
    "            with open(name, 'w') as file:\n",
    "                documents = yaml.dump(data,file)\n",
    "                documents = yaml.dump(data_1,file)\n",
    "            path_gazebo = []\n",
    "    time_one_epoch = time.time() - start #recording the work time of one epoch\n",
    "    time_tot = time.time() - start_training_time + tot_time_ckpt\n",
    "    ###################\n",
    "    # Evaluate train model and baseline \n",
    "    # in this phase we just solve random instances with the actor and the critic\n",
    "    # compare this soluation if we get any improvment we'll transfer the actor's\n",
    "    # weights into the critic\n",
    "    ###################\n",
    "    # putting the actor in the eval mode\n",
    "    Actor.eval()\n",
    "    \n",
    "    mean_tour_length_actor = 0\n",
    "    mean_tour_length_critic = 0\n",
    "\n",
    "    for step in range(0,B_valLoop):\n",
    "        \n",
    "        # compute tour for model and baseline\n",
    "        # mask some points that are not the first visited points\n",
    "        if torch.cuda.is_available():\n",
    "            R = torch.zeros(B).cuda()\n",
    "            reward_recorder = torch.zeros(B,size_rec).cuda()\n",
    "            idx_recorder = torch.zeros(B,size_rec).cuda()\n",
    "            reward = torch.zeros(B).cuda()\n",
    "            mask = torch.zeros(B,size).cuda() # use mask to make some points impossible to choose\n",
    "            X_gcn_original = x_gcn_temp.repeat(B,1,1).cuda()\n",
    "        else:\n",
    "            R = torch.zeros(B)\n",
    "            reward_recorder = torch.zeros(B,size_rec)\n",
    "            idx_recorder = torch.zeros(B,size_rec)\n",
    "            reward = torch.zeros(B)\n",
    "            mask = torch.zeros(B,size) # use mask to make some points impossible to choose\n",
    "            X_gcn_original = x_gcn_temp.repeat(B,1,1)\n",
    "        x = torch.zeros(B,dimension)# Y[:,0,:] #set the first point to x\n",
    "        h = None\n",
    "        c = None\n",
    "        context = None        # set Y_ini to the out corner\n",
    "        Transcontext = None\n",
    "        GCNcontext = None\n",
    "        Y0 = None\n",
    "        choosen_idx = None\n",
    "        visit_count = visit_count_initial.repeat(B,1)\n",
    "        visit_time_count_initial = torch.zeros(len(visit_count_initial))\n",
    "        visit_time_count = visit_time_count_initial.repeat(B,1)\n",
    "        if torch.cuda.is_available():\n",
    "            visit_count = visit_count.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for k in range(size_rec):\n",
    "                if k==0:\n",
    "                    Y = X.view(B,size,dimension)\n",
    "                X_gcn = X_gcn_original.view(B*size,dimension)\n",
    "                data = Data(pos=X_gcn,batch=batch,mask=mask,B=B)\n",
    "                output, h, c, _ = Actor(data, x=x, h=h, c=c)\n",
    "                idx = torch.argmax(output, dim=1)\n",
    "                idx_recorder[:,k] = (idx/4).type(torch.long)\n",
    "                #prepare for the back propagation of pytorch\n",
    "                Y, reward, Y0, x, choosen_idx, X_gcn_original = rectangle_process(temp, idx,Y,Y0,mask,k,B,i,path_gazebo,\n",
    "                                                    visit_count, visit_time_count, X_gcn_original, if_actor=False)\n",
    "                R += reward\n",
    "                reward_recorder[:,k] = R\n",
    "            #now is the time to check if any trajectory should be punished due to waiting on the same rectangle\n",
    "\n",
    "            trajec_count = 0\n",
    "            for path_time in zip(idx_recorder,reward_recorder):\n",
    "                idx_time = zip(path_time[0],path_time[1])\n",
    "                idx_time = sorted(idx_time, key=lambda x: x[0])\n",
    "                total_idx = 0\n",
    "                extra_waiting_time = 0\n",
    "                for item in visit_count_rec:\n",
    "                    compare_list = []\n",
    "                    if item>1:\n",
    "                        for i in range(int(item)):\n",
    "                            compare_list.append(idx_time[int(total_idx + i)][1])\n",
    "                        compare_list.sort(reverse=True)\n",
    "                        total_idx += item\n",
    "                        for i in range(len(compare_list)-1):\n",
    "                            dis_step = compare_list[i] - compare_list[i+1]\n",
    "                            dry_time = (range_of_wait/2)*speed_of_nozzle\n",
    "                            if (dis_step) < (dry_time):\n",
    "                                extra_waiting_time += dry_time - dis_step\n",
    "                    else:\n",
    "                        total_idx += item\n",
    "                R[trajec_count] += extra_waiting_time\n",
    "                trajec_count+=1\n",
    "            print('R_val = ',R[0])\n",
    "        if torch.cuda.is_available():\n",
    "            C = torch.zeros(B).cuda()\n",
    "            reward_recorder = torch.zeros(B,size_rec).cuda()\n",
    "            idx_recorder = torch.zeros(B,size_rec).cuda()\n",
    "            baseline = torch.zeros(B).cuda()\n",
    "            mask = torch.zeros(B,size).cuda() # use mask to make some points impossible to choose\n",
    "            X_gcn_original = x_gcn_temp.repeat(B,1,1).cuda()\n",
    "        else:\n",
    "            C = torch.zeros(B)\n",
    "            reward_recorder = torch.zeros(B,size_rec)\n",
    "            idx_recorder = torch.zeros(B,size_rec)\n",
    "            baseline = torch.zeros(B)\n",
    "            mask = torch.zeros(B,size) # use mask to make some points impossible to choose\n",
    "            X_gcn_original = x_gcn_temp.repeat(B,1,1)\n",
    "        x = torch.zeros(B,dimension)#Y[:,0,:] #set the first point to x\n",
    "        h = None\n",
    "        c = None\n",
    "        context = None\n",
    "        Transcontext = None\n",
    "        C0 = None\n",
    "        choosen_idx = None\n",
    "        visit_count = visit_count_initial.repeat(B,1)\n",
    "        visit_time_count_initial = torch.zeros(len(visit_count_initial))\n",
    "        visit_time_count = visit_time_count_initial.repeat(B,1)\n",
    "        if torch.cuda.is_available():\n",
    "            visit_count = visit_count.cuda()\n",
    "        # compute tours for baseline without grad \"Cause we want to fix the weights for the critic\"\n",
    "        with torch.no_grad():\n",
    "            for k in range(size_rec): \n",
    "                if k ==0:\n",
    "                    Y = X.view(B,size,dimension)\n",
    "                #check if all the points to be masked,if so, raise the total reward R, and check again\n",
    "                X_gcn = X_gcn_original.view(B*size,dimension)\n",
    "                data = Data(pos=X_gcn,batch=batch,mask=mask,B=B)\n",
    "                output, h, c, _ = Critic(data, x=x, h=h, c=c)\n",
    "                idx = torch.argmax(output, dim=1) # ----> greedy baseline critic\n",
    "                idx_recorder[:,k] = (idx/4).type(torch.long)\n",
    "                # prepare for the back propagation of pytorch\n",
    "                Y, baseline, C0, x, choosen_idx, X_gcn_original = rectangle_process(temp,idx,Y,C0, mask,k,B,i,path_gazebo,\n",
    "                                                   visit_count, visit_time_count, X_gcn_original, if_actor=False)\n",
    "                C += baseline\n",
    "                reward_recorder[:,k] = C\n",
    "                #now is the time to check if any trajectory should be punished due to waiting on the same rectangle\n",
    "\n",
    "            trajec_count = 0\n",
    "            for path_time in zip(idx_recorder,reward_recorder):\n",
    "                idx_time = zip(path_time[0],path_time[1])\n",
    "                idx_time = sorted(idx_time, key=lambda x: x[0])\n",
    "                total_idx = 0\n",
    "                extra_waiting_time = 0\n",
    "                for item in visit_count_rec:\n",
    "                    compare_list = []\n",
    "                    if item>1:\n",
    "                        for i in range(int(item)):\n",
    "                            compare_list.append(idx_time[int(total_idx + i)][1])\n",
    "                        compare_list.sort(reverse=True)\n",
    "                        total_idx += item\n",
    "                        for i in range(len(compare_list)-1):\n",
    "                            dis_step = compare_list[i] - compare_list[i+1]\n",
    "                            dry_time = (range_of_wait/2)*speed_of_nozzle\n",
    "                            if (dis_step) < (dry_time):\n",
    "                                extra_waiting_time += dry_time - dis_step\n",
    "                    else:\n",
    "                        total_idx += item\n",
    "                C[trajec_count] += extra_waiting_time\n",
    "                trajec_count+=1\n",
    "            print('C_val = ',C.mean().item())\n",
    "        mean_tour_length_actor  += R.mean().item()\n",
    "        mean_tour_length_critic += C.mean().item()\n",
    "\n",
    "    mean_tour_length_actor  =  mean_tour_length_actor  / B_valLoop\n",
    "    mean_tour_length_critic =  mean_tour_length_critic / B_valLoop\n",
    "    # evaluate train model and baseline and update if train model is better\n",
    "\n",
    "    update_baseline = mean_tour_length_actor + TOL < mean_tour_length_critic\n",
    "\n",
    "    print('Avg Actor {} --- Avg Critic {}'.format(mean_tour_length_actor,mean_tour_length_critic))\n",
    "\n",
    "    if update_baseline:\n",
    "        Critic.load_state_dict(Actor.state_dict())\n",
    "        print('My actor is going on the right road Hallelujah :) Updated')\n",
    "    ###################\n",
    "    # Valdiation train model and baseline on 1k random TSP instances\n",
    "    ###################\n",
    "    # erased by daniel due to the 1K tsp is not the scale I want to train  \n",
    "\n",
    "    # For checkpoint\n",
    "    plot_performance_train.append([(epoch+1), mean_tour_length_actor])\n",
    "    plot_performance_baseline.append([(epoch+1), mean_tour_length_critic])\n",
    "    # compute the optimally gap ==> this is interesting because there is no LKH or other optimal algorithms \n",
    "    # for the problem like this rectangle characterized map\n",
    "    mystring_min = 'Epoch: {:d}, epoch time: {:.3f}min, tot time: {:.3f}day, L_actor: {:.3f}, L_critic: {:.3f}, update: {}'.format(\n",
    "        epoch, time_one_epoch/60, time_tot/86400, mean_tour_length_actor, mean_tour_length_critic, update_baseline)\n",
    "\n",
    "    print(mystring_min)\n",
    "    print('Save Checkpoints')\n",
    "\n",
    "    # Saving checkpoint\n",
    "    checkpoint_dir = os.path.join(\"checkpoint\")\n",
    "\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "    \n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'time': time_one_epoch,\n",
    "        'tot_time': time_tot,\n",
    "        'loss': loss.item(),\n",
    "        'plot_performance_train': plot_performance_train,\n",
    "        'plot_performance_baseline': plot_performance_baseline,\n",
    "        'model_baseline': Critic.state_dict(),\n",
    "        'model_train': Actor.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        },'{}.pkl'.format(checkpoint_dir + \"/checkpoint_\" + time_stamp + \"-n{}\".format(size) + \"-gpu{}\".format(gpu_id)))\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "            \n",
    "                \n",
    "        \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f703da",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "from torch_geometric.nn import TopKPooling\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch_geometric.nn import GravNetConv\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = GravNetConv(-1, 128)\n",
    "        self.pool1 = TopKPooling(128, ratio=0.8)\n",
    "        self.conv2 = GravNetConv(128, 128)\n",
    "        self.pool2 = TopKPooling(128, ratio=0.8)\n",
    "        self.conv3 = GravNetConv(128, 128)\n",
    "        self.pool3 = TopKPooling(128, ratio=0.8)\n",
    "        self.lin1 = torch.nn.Linear(128, 128)\n",
    "        self.lin2 = torch.nn.Linear(128, 64)\n",
    "        self.lin3 = torch.nn.Linear(64, 1)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(128)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(64)\n",
    "        self.act1 = torch.nn.ReLU()\n",
    "        self.act2 = torch.nn.ReLU()        \n",
    "  \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        print(x.dtype)\n",
    "        print(edge_index.dtype)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        print(x.shape)\n",
    "        x = self.lin1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.act2(x)      \n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        x = torch.sigmoid(self.lin3(x)).squeeze(1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396d8771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import knn_graph\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "def train():\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    print(output)\n",
    "    label = data.y.to(device)\n",
    "    loss = crit(output, label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "x = torch.Tensor([[-1, -1], [-1, 1], [1, -1], [1, 1]])\n",
    "dataset = x.repeat(128,1)\n",
    "x = x.repeat(128,1,1)\n",
    "loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "edge_index = torch.tensor([])\n",
    "for x_seed in x:\n",
    "    edge_index_temp = knn_graph(x_seed, k=1, loop=False)\n",
    "    edge_index_temp = torch.unsqueeze(edge_index_temp, 0)\n",
    "    edge_index = torch.cat((edge_index, edge_index_temp),0)\n",
    "x = torch.Tensor(x).type(torch.float)\n",
    "edge_index = torch.Tensor(edge_index).type(torch.long)\n",
    "data = Data(x=x[0],edge_index=edge_index[0],batch=128)\n",
    "# device = torch.device('cuda')\n",
    "model = Net()#.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "crit = torch.nn.BCELoss()\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c1e1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import ModelNet\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MLP, DynamicEdgeConv, global_max_pool\n",
    "\n",
    "path = osp.join(osp.dirname(osp.realpath('only_for_test')), '..', 'data/ModelNet10')\n",
    "pre_transform, transform = T.NormalizeScale(), T.SamplePoints(1024)\n",
    "train_dataset = ModelNet(path, '10', True, transform, pre_transform)\n",
    "test_dataset = ModelNet(path, '10', False, transform, pre_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,\n",
    "                          num_workers=6)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False,\n",
    "                         num_workers=6)\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, out_channels, k=20, aggr='max'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = DynamicEdgeConv(MLP([2 * 3, 64, 64, 64]), k, aggr)\n",
    "        self.conv2 = DynamicEdgeConv(MLP([2 * 64, 128]), k, aggr)\n",
    "        self.lin1 = Linear(128 + 64, 1024)\n",
    "\n",
    "        self.mlp = MLP([1024, 512, 256, out_channels], dropout=0.5,\n",
    "                       batch_norm=False)\n",
    "\n",
    "    def forward(self, data):\n",
    "        pos, batch = data.pos, data.batch\n",
    "        print(pos.shape)\n",
    "        print(pos)\n",
    "        x1 = self.conv1(pos, batch)\n",
    "        print(x1.shape)\n",
    "        x2 = self.conv2(x1, batch)\n",
    "        print(x2.shape)\n",
    "        out = self.lin1(torch.cat([x1, x2], dim=1))\n",
    "        print(out.shape)\n",
    "        out = global_max_pool(out, batch)\n",
    "        out = self.mlp(out)\n",
    "        return F.log_softmax(out, dim=1)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net(train_dataset.num_classes, k=20).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    print(train_loader)\n",
    "    for data in train_loader:\n",
    "        print(data)\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out, data.y)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_dataset)\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(data).max(dim=1)[1]\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    test_acc = test(test_loader)\n",
    "    print(f'Epoch {epoch:03d}, Loss: {loss:.4f}, Test: {test_acc:.4f}')\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15da0af0",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e16a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Optional, Union\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.dense.linear import Linear\n",
    "from torch_geometric.typing import OptTensor, PairOptTensor, PairTensor\n",
    "from torch_geometric.utils import remove_self_loops\n",
    "try:\n",
    "    from torch_cluster import knn\n",
    "except ImportError:\n",
    "    knn = None\n",
    "\n",
    "\n",
    "class GravNetConv(MessagePassing):\n",
    "    \n",
    "    def __init__(self, in_channels: int, out_channels: int,\n",
    "                 space_dimensions: int, propagate_dimensions: int, k: int,\n",
    "                 num_workers: Optional[int] = None, **kwargs):\n",
    "        super().__init__(aggr='mean', flow='source_to_target',\n",
    "                         **kwargs)\n",
    "\n",
    "        if knn is None:\n",
    "            raise ImportError('`GravNetConv` requires `torch-cluster`.')\n",
    "\n",
    "        if num_workers is not None:\n",
    "            warnings.warn(\n",
    "                \"'num_workers' attribute in '{self.__class__.__name__}' is \"\n",
    "                \"deprecated and will be removed in a future release\")\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.k = k\n",
    "\n",
    "        self.lin_s = Linear(in_channels, space_dimensions)\n",
    "        self.lin_h = Linear(in_channels, propagate_dimensions)\n",
    "\n",
    "        self.lin_out1 = Linear(in_channels, out_channels, bias=False)\n",
    "        self.lin_out2 = Linear(2 * propagate_dimensions, out_channels)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin_s.reset_parameters()\n",
    "        self.lin_h.reset_parameters()\n",
    "        self.lin_out1.reset_parameters()\n",
    "        self.lin_out2.reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(\n",
    "            self, x: Union[Tensor, PairTensor],\n",
    "            batch: Union[OptTensor, Optional[PairTensor]] = None) -> Tensor:\n",
    "        # type: (Tensor, OptTensor) -> Tensor  # noqa\n",
    "        # type: (PairTensor, Optional[PairTensor]) -> Tensor  # noqa\n",
    "        \"\"\"\"\"\"\n",
    "\n",
    "        is_bipartite: bool = True\n",
    "        if isinstance(x, Tensor):\n",
    "            x: PairTensor = (x, x)\n",
    "            is_bipartite = False\n",
    "\n",
    "        if x[0].dim() != 2:\n",
    "            raise ValueError(\"Static graphs not supported in 'GravNetConv'\")\n",
    "\n",
    "        b: PairOptTensor = (None, None)\n",
    "        if isinstance(batch, Tensor):\n",
    "            b = (batch, batch)\n",
    "        elif isinstance(batch, tuple):\n",
    "            assert batch is not None\n",
    "            b = (batch[0], batch[1])\n",
    "\n",
    "        h_l: Tensor = self.lin_h(x[0])\n",
    "        s_l: Tensor = self.lin_s(x[0])\n",
    "        s_r: Tensor = s_l\n",
    "# x[0] = x[1], s_l = s_r \n",
    "        edge_index = knn(s_l, s_r, self.k+1, b[0], b[1]).flip([0])\n",
    "        temp_edge = remove_self_loops(edge_index)\n",
    "        edge_index = temp_edge[0]\n",
    "        edge_weight = (s_l[edge_index[0]] - s_r[edge_index[1]]).pow(2).sum(-1)\n",
    "        edge_weight = torch.exp(-20. * edge_weight)  # 10 gives a better spread\n",
    "        print(edge_weight)\n",
    "        # propagate_type: (x: OptPairTensor, edge_weight: OptTensor)\n",
    "        out = self.propagate(edge_index, x=(h_l, None),\n",
    "                             edge_weight=edge_weight,\n",
    "                             size=(s_l.size(0), s_r.size(0)))\n",
    "\n",
    "        return self.lin_out1(x[1]) + self.lin_out2(out)\n",
    "\n",
    "\n",
    "    def message(self, x_j: Tensor, edge_weight: Tensor) -> Tensor:\n",
    "        return x_j * edge_weight.unsqueeze(1)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.out_channels}, k={self.k})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f7516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MLP, DynamicEdgeConv, global_max_pool\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,space_dimensions=4, propagate_dimensions=22 ,k=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = GravNetConv(in_channels,64,space_dimensions, propagate_dimensions, k)\n",
    "        self.conv2 = GravNetConv(64,128,space_dimensions, propagate_dimensions, k)\n",
    "        self.lin1 = Linear(128 + 64, 1024)\n",
    "\n",
    "        self.mlp = MLP([1024, 512, 256, out_channels], dropout=0.5,\n",
    "                       batch_norm=False)\n",
    "\n",
    "    def forward(self, data):\n",
    "        pos, batch = data.pos, data.batch\n",
    "        x1 = self.conv1(pos, batch)\n",
    "        print(x1.shape)\n",
    "        x2 = self.conv2(x1, batch)\n",
    "        print(x2.shape)\n",
    "        out = self.lin1(torch.cat([x1, x2], dim=1))\n",
    "        print(out.shape)\n",
    "        out = global_max_pool(out, batch)\n",
    "        print(out.shape)\n",
    "        out = self.mlp(out)\n",
    "        print(out.shape)\n",
    "        out = out.repeat_interleave(4,dim=1)\n",
    "        out = 10 * torch.tanh(out)\n",
    "        return F.softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec69bcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import knn_graph\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "from listofpathpoint import input_handler\n",
    "batch_size = 128\n",
    "temp = input_handler('10&15data/30_chips/30_1.json')\n",
    "x, mask_list_num = temp.final_ver_points_no_visitcount()\n",
    "\n",
    "\n",
    "# load 100 points into the program \n",
    "x = torch.Tensor(x).type(torch.float)\n",
    "x /= 800\n",
    "X_original = x.repeat(128,1,1)\n",
    "print(X_original.shape)\n",
    "batch = torch.arange(batch_size)\n",
    "batch = batch.repeat_interleave(len(x))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net(in_channels=3, out_channels=(len(mask_list_num)-1)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "optimizer.zero_grad()\n",
    "size_rec = mask_list_num[-1]\n",
    "zero_to_bsz = torch.arange(128, device = device)\n",
    "add_time = torch.ones(128)\n",
    "# get the output probability of all the point, start to calculate the cost and transfer the input data\n",
    "for k in range(size_rec):\n",
    "    print(k)\n",
    "    X = X_original.view(12800,3)\n",
    "    data = Data(pos=X,batch=batch)\n",
    "    data = data.to(device)\n",
    "    model.eval()\n",
    "    output= model(data)\n",
    "    sampler = torch.distributions.Categorical(output)\n",
    "    idx = sampler.sample()\n",
    "    for i in range(128):\n",
    "        X_original[i][idx.data[i]][2] += 1\n",
    "    # prepare for the back propagation of pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428d7c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import knn_graph\n",
    "\n",
    "x = torch.Tensor([[-1, -1], [-1, 1], [1, -1], [1, 1]])\n",
    "batch = torch.tensor([0, 0, 0, 0])\n",
    "edge_index = knn_graph(x, k=2, batch=batch, loop=False)\n",
    "print(edge_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
