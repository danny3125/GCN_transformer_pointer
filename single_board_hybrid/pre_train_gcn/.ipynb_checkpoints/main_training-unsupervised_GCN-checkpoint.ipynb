{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "# visualization \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "device = torch.device(\"cpu\"); gpu_id = -1 # select CPU\n",
    "\n",
    "gpu_id = '0' # select a single GPU  \n",
    "#gpu_id = '2,3' # select multiple GPUs  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)  \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('GPU name: {:s}, gpu_id: {:s}'.format(torch.cuda.get_device_name(0),gpu_id))   \n",
    "    \n",
    "print(device)\n",
    "print('pytorch version = ',torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_scatter import scatter\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MLP, DynamicEdgeConv, global_max_pool\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.dense.linear import Linear\n",
    "from torch_geometric.typing import OptTensor, PairOptTensor, PairTensor\n",
    "from torch_geometric.utils import remove_self_loops\n",
    "try:\n",
    "    from torch_cluster import knn\n",
    "except ImportError:\n",
    "    knn = None\n",
    "from typing import Optional, Union\n",
    "class TransEncoderNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder network based on self-attention transformer\n",
    "    Inputs :  \n",
    "      h of size      (bsz, nb_nodes, dim_emb)    batch of input cities\n",
    "    Outputs :  \n",
    "      h of size      (bsz, nb_nodes, dim_emb)    batch of encoded cities\n",
    "      score of size  (bsz, nb_nodes, nb_nodes+1) batch of attention scores\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, nb_layers, dim_emb, nb_heads, dim_ff, batchnorm):\n",
    "        super(TransEncoderNet, self).__init__()\n",
    "        assert dim_emb == nb_heads* (dim_emb//nb_heads) # check if dim_emb is divisible by nb_heads\n",
    "        self.MHA_layers = nn.ModuleList( [nn.MultiheadAttention(dim_emb, nb_heads) for _ in range(nb_layers)] )\n",
    "        self.linear1_layers = nn.ModuleList( [nn.Linear(dim_emb, dim_ff) for _ in range(nb_layers)] )\n",
    "        self.linear2_layers = nn.ModuleList( [nn.Linear(dim_ff, dim_emb) for _ in range(nb_layers)] )   \n",
    "        if batchnorm:\n",
    "            self.norm1_layers = nn.ModuleList( [nn.BatchNorm1d(dim_emb) for _ in range(nb_layers)] )\n",
    "            self.norm2_layers = nn.ModuleList( [nn.BatchNorm1d(dim_emb) for _ in range(nb_layers)] )\n",
    "        else:\n",
    "            self.norm1_layers = nn.ModuleList( [nn.LayerNorm(dim_emb) for _ in range(nb_layers)] )\n",
    "            self.norm2_layers = nn.ModuleList( [nn.LayerNorm(dim_emb) for _ in range(nb_layers)] )\n",
    "        self.nb_layers = nb_layers\n",
    "        self.nb_heads = nb_heads\n",
    "        self.batchnorm = batchnorm\n",
    "        \n",
    "    def forward(self, h):      \n",
    "        # PyTorch nn.MultiheadAttention requires input size (seq_len, bsz, dim_emb) \n",
    "        h = h.transpose(0,1) # size(h)=(nb_nodes, bsz, dim_emb)  \n",
    "        # L layers\n",
    "        for i in range(self.nb_layers):\n",
    "            h_rc = h # residual connection, size(h_rc)=(nb_nodes, bsz, dim_emb)\n",
    "            h, score = self.MHA_layers[i](h, h, h) # size(h)=(nb_nodes, bsz, dim_emb), size(score)=(bsz, nb_nodes, nb_nodes)\n",
    "            # add residual connection\n",
    "            \n",
    "            h = h_rc + h # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            if self.batchnorm:\n",
    "                # Pytorch nn.BatchNorm1d requires input size (bsz, dim, seq_len)\n",
    "                h = h.permute(1,2,0).contiguous() # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                h = self.norm1_layers[i](h)       # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                h = h.permute(2,0,1).contiguous() # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            else:\n",
    "                h = self.norm1_layers[i](h)       # size(h)=(nb_nodes, bsz, dim_emb) \n",
    "            # feedforward\n",
    "            h_rc = h # residual connection\n",
    "            h = self.linear2_layers[i](torch.relu(self.linear1_layers[i](h)))\n",
    "            h = h_rc + h # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            if self.batchnorm:\n",
    "                h = h.permute(1,2,0).contiguous() # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                h = self.norm2_layers[i](h)       # size(h)=(bsz, dim_emb, nb_nodes)\n",
    "                h = h.permute(2,0,1).contiguous() # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "            else:\n",
    "                h = self.norm2_layers[i](h) # size(h)=(nb_nodes, bsz, dim_emb)\n",
    "        # Transpose h\n",
    "        h = h.transpose(0,1) # size(h)=(bsz, nb_nodes, dim_emb)\n",
    "        return h, score\n",
    "    \n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, n_hidden):\n",
    "        super(Attention, self).__init__()\n",
    "        self.size = 0\n",
    "        self.batch_size = 0\n",
    "        self.dim = n_hidden\n",
    "        \n",
    "        v  = torch.FloatTensor(n_hidden)\n",
    "        self.v  = nn.Parameter(v)\n",
    "        self.v.data.uniform_(-1/math.sqrt(n_hidden), 1/math.sqrt(n_hidden))\n",
    "        \n",
    "        # parameters for pointer attention\n",
    "        self.Wref = nn.Linear(n_hidden, n_hidden)\n",
    "        self.Wq = nn.Linear(n_hidden, n_hidden)\n",
    "    \n",
    "    \n",
    "    def forward(self, q, ref):       # query and reference\n",
    "        self.batch_size = q.size(0)\n",
    "        self.size = int(ref.size(0) / self.batch_size)\n",
    "        q = self.Wq(q)     # (B, dim)\n",
    "        ref = self.Wref(ref)\n",
    "        ref = ref.view(self.batch_size, self.size, self.dim)  # (B, size, dim)\n",
    "        \n",
    "        q_ex = q.unsqueeze(1).repeat(1, self.size, 1) # (B, size, dim)\n",
    "        # v_view: (B, dim, 1)\n",
    "        v_view = self.v.unsqueeze(0).expand(self.batch_size, self.dim).unsqueeze(2)\n",
    "        \n",
    "        # (B, size, dim) * (B, dim, 1)\n",
    "        u = torch.bmm(torch.tanh(q_ex + ref), v_view).squeeze(2)\n",
    "        \n",
    "        return u, ref\n",
    "    \n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, n_hidden):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        # parameters for input gate\n",
    "        self.Wxi = nn.Linear(n_hidden, n_hidden)    # W(xt)\n",
    "        self.Whi = nn.Linear(n_hidden, n_hidden)    # W(ht)\n",
    "        self.wci = nn.Linear(n_hidden, n_hidden)    # w(ct)\n",
    "        \n",
    "        # parameters for forget gate\n",
    "        self.Wxf = nn.Linear(n_hidden, n_hidden)    # W(xt)\n",
    "        self.Whf = nn.Linear(n_hidden, n_hidden)    # W(ht)\n",
    "        self.wcf = nn.Linear(n_hidden, n_hidden)    # w(ct)\n",
    "        \n",
    "        # parameters for cell gate\n",
    "        self.Wxc = nn.Linear(n_hidden, n_hidden)    # W(xt)\n",
    "        self.Whc = nn.Linear(n_hidden, n_hidden)    # W(ht)\n",
    "        \n",
    "        # parameters for forget gate\n",
    "        self.Wxo = nn.Linear(n_hidden, n_hidden)    # W(xt)\n",
    "        self.Who = nn.Linear(n_hidden, n_hidden)    # W(ht)\n",
    "        self.wco = nn.Linear(n_hidden, n_hidden)    # w(ct)\n",
    "    \n",
    "    \n",
    "    def forward(self, x, h, c):       # query and reference\n",
    "        \n",
    "        # input gate\n",
    "        i = torch.sigmoid(self.Wxi(x) + self.Whi(h) + self.wci(c))\n",
    "        # forget gate\n",
    "        f = torch.sigmoid(self.Wxf(x) + self.Whf(h) + self.wcf(c))\n",
    "        # cell gate\n",
    "        c = f * c + i * torch.tanh(self.Wxc(x) + self.Whc(h))\n",
    "        # output gate\n",
    "        o = torch.sigmoid(self.Wxo(x) + self.Who(h) + self.wco(c))\n",
    "        \n",
    "        h = o * torch.tanh(c)\n",
    "        \n",
    "        return h, c\n",
    "    \n",
    "class GravNetConv(MessagePassing):\n",
    "    r\"\"\"The GravNet operator from the `\"Learning Representations of Irregular\n",
    "    Particle-detector Geometry with Distance-weighted Graph\n",
    "    Networks\" <https://arxiv.org/abs/1902.07987>`_ paper, where the graph is\n",
    "    dynamically constructed using nearest neighbors.\n",
    "    The neighbors are constructed in a learnable low-dimensional projection of\n",
    "    the feature space.\n",
    "    A second projection of the input feature space is then propagated from the\n",
    "    neighbors to each vertex using distance weights that are derived by\n",
    "    applying a Gaussian function to the distances.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Size of each input sample, or :obj:`-1` to derive\n",
    "            the size from the first input(s) to the forward method.\n",
    "        out_channels (int): The number of output channels.\n",
    "        space_dimensions (int): The dimensionality of the space used to\n",
    "           construct the neighbors; referred to as :math:`S` in the paper.\n",
    "        propagate_dimensions (int): The number of features to be propagated\n",
    "           between the vertices; referred to as :math:`F_{\\textrm{LR}}` in the\n",
    "           paper.\n",
    "        k (int): The number of nearest neighbors.\n",
    "        num_workers (int): Number of workers to use for k-NN computation.\n",
    "            Has no effect in case :obj:`batch` is not :obj:`None`, or the input\n",
    "            lies on the GPU. (default: :obj:`1`)\n",
    "        **kwargs (optional): Additional arguments of\n",
    "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
    "\n",
    "    Shapes:\n",
    "        - **input:**\n",
    "          node features :math:`(|\\mathcal{V}|, F_{in})` or\n",
    "          :math:`((|\\mathcal{V_s}|, F_{in}), (|\\mathcal{V_t}|, F_{in}))`\n",
    "          if bipartite,\n",
    "          batch vector :math:`(|\\mathcal{V}|)` or\n",
    "          :math:`((|\\mathcal{V}_s|), (|\\mathcal{V}_t|))` if bipartite\n",
    "          *(optional)*\n",
    "        - **output:** node features :math:`(|\\mathcal{V}|, F_{out})` or\n",
    "          :math:`(|\\mathcal{V}_t|, F_{out})` if bipartite\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int,\n",
    "                 space_dimensions: int, propagate_dimensions: int, k: int,\n",
    "                 num_workers: int = 1, **kwargs):\n",
    "        super().__init__(flow='source_to_target', **kwargs)\n",
    "\n",
    "        if knn is None:\n",
    "            raise ImportError('`GravNetConv` requires `torch-cluster`.')\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.k = k\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self.lin_s = Linear(in_channels, space_dimensions)\n",
    "        self.lin_h = Linear(in_channels, propagate_dimensions)\n",
    "\n",
    "        self.lin_out1 = Linear(in_channels, out_channels, bias=False)\n",
    "        self.lin_out2 = Linear(2 * propagate_dimensions, out_channels)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin_s.reset_parameters()\n",
    "        self.lin_h.reset_parameters()\n",
    "        self.lin_out1.reset_parameters()\n",
    "        self.lin_out2.reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(\n",
    "            self, x: Union[Tensor, PairTensor],\n",
    "            batch: Union[OptTensor, Optional[PairTensor]] = None) -> Tensor:\n",
    "        # type: (Tensor, OptTensor) -> Tensor  # noqa\n",
    "        # type: (PairTensor, Optional[PairTensor]) -> Tensor  # noqa\n",
    "        \"\"\"\"\"\"\n",
    "\n",
    "        is_bipartite: bool = True\n",
    "        if isinstance(x, Tensor):\n",
    "            x: PairTensor = (x, x)\n",
    "            is_bipartite = False\n",
    "\n",
    "        if x[0].dim() != 2:\n",
    "            raise ValueError(\"Static graphs not supported in 'GravNetConv'\")\n",
    "\n",
    "        b: PairOptTensor = (None, None)\n",
    "        if isinstance(batch, Tensor):\n",
    "            b = (batch, batch)\n",
    "        elif isinstance(batch, tuple):\n",
    "            assert batch is not None\n",
    "            b = (batch[0], batch[1])\n",
    "\n",
    "        h_l: Tensor = self.lin_h(x[0])\n",
    "\n",
    "        s_l: Tensor = self.lin_s(x[0])\n",
    "        s_r: Tensor = self.lin_s(x[1]) if is_bipartite else s_l\n",
    "\n",
    "        edge_index = knn(s_l, s_r, self.k, b[0], b[1]).flip([0])\n",
    "\n",
    "        edge_weight = (s_l[edge_index[0]] - s_r[edge_index[1]]).pow(2).sum(-1)\n",
    "        edge_weight = torch.exp(-10. * edge_weight)  # 10 gives a better spread\n",
    "\n",
    "        # propagate_type: (x: OptPairTensor, edge_weight: OptTensor)\n",
    "        out = self.propagate(edge_index, x=(h_l, None),\n",
    "                             edge_weight=edge_weight,\n",
    "                             size=(s_l.size(0), s_r.size(0)))\n",
    "\n",
    "        return self.lin_out1(x[1]) + self.lin_out2(out)\n",
    "\n",
    "\n",
    "    def message(self, x_j: Tensor, edge_weight: Tensor) -> Tensor:\n",
    "        return x_j * edge_weight.unsqueeze(1)\n",
    "\n",
    "    def aggregate(self, inputs: Tensor, index: Tensor,\n",
    "                  dim_size: Optional[int] = None) -> Tensor:\n",
    "        out_mean = scatter(inputs, index, dim=self.node_dim, dim_size=dim_size,\n",
    "                           reduce='mean')\n",
    "        out_max = scatter(inputs, index, dim=self.node_dim, dim_size=dim_size,\n",
    "                          reduce='max')\n",
    "        return torch.cat([out_mean, out_max], dim=-1)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.out_channels}, k={self.k})')\n",
    "\n",
    "class HPN(nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden):\n",
    "\n",
    "        super(HPN, self).__init__()\n",
    "        self.city_size = 0\n",
    "        self.batch_size = 0\n",
    "        self.dim = n_hidden\n",
    "        \n",
    "        # lstm for first turn\n",
    "        #self.lstm0 = nn.LSTM(n_hidden, n_hidden)main_training - Jupyter Notebook\n",
    "        \n",
    "        # pointer layer\n",
    "        self.TransPointer = Attention(n_hidden)\n",
    "        self.Pointer = Attention(n_hidden)\n",
    "        self.conv1 = GravNetConv(n_feature, n_hidden, space_dimensions=4, propagate_dimensions=22, k=40)\n",
    "        self.conv2 = GravNetConv(n_hidden, n_hidden, space_dimensions=4, propagate_dimensions=22, k=40)\n",
    "        self.conv3 = GravNetConv(n_hidden, n_hidden, space_dimensions=4, propagate_dimensions=22, k=40)\n",
    "        # lstm encode2\n",
    "        self.encoder = LSTM(n_hidden)\n",
    "        \n",
    "        # trainable first hidden input\n",
    "        h0 = torch.FloatTensor(n_hidden)\n",
    "        c0 = torch.FloatTensor(n_hidden)\n",
    "        # trainable latent variable coefficient\n",
    "        print('here') \n",
    "        alpha = torch.ones(1)\n",
    "        self.h0 = nn.Parameter(h0)\n",
    "        self.c0 = nn.Parameter(c0)\n",
    "        \n",
    "        self.alpha = nn.Parameter(alpha)\n",
    "        self.h0.data.uniform_(-1/math.sqrt(n_hidden), 1/math.sqrt(n_hidden))\n",
    "        self.c0.data.uniform_(-1/math.sqrt(n_hidden), 1/math.sqrt(n_hidden))\n",
    "        \n",
    "        # embedding\n",
    "        self.embedding_x = nn.Linear(n_feature, n_hidden)\n",
    "        self.embedding_all = nn.Linear(n_feature, n_hidden)\n",
    "        self.denselayer1 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.denselayer2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.Transembedding_all = TransEncoderNet(6, 128, 8, 512, batchnorm=True)#6,128,8,512\n",
    "        \n",
    "        # vector to start decoding \n",
    "        self.start_placeholder = nn.Parameter(torch.randn(n_hidden))\n",
    "        self.outagg = nn.Linear(2, 1)\n",
    "    \n",
    "    def forward(self,GCNcontext,Transcontext, x, X_all, mask,choosen_idx,epoch, h=None, c=None, latent=None):\n",
    "        '''\n",
    "        Inputs (B: batch size, size: city size, dim: hidden dimension)\n",
    "        \n",
    "        x: current city coordinate (B, 2)\n",
    "        X_all: all cities' cooridnates (B, size, 2)\n",
    "        mask: mask visited cities\n",
    "        h: hidden variable (B, dim)\n",
    "        c: cell gate (B, dim)\n",
    "        latent: latent pointer vector from previous layer (B, size, dim)\n",
    "        \n",
    "        Outputs\n",
    "        \n",
    "        softmax: probability distribution of next city (B, size)\n",
    "        h: hidden variable (B, dim)\n",
    "        c: cell gate (B, dim)\n",
    "        latent_u: latent pointer vector for next layer\n",
    "        '''\n",
    "        self.batch_size = X_all.size(0)\n",
    "        self.city_size = X_all.size(1)\n",
    "        zero_to_bsz = torch.arange(self.batch_size, device=device)\n",
    "        batch = torch.arange(B)\n",
    "        batch = batch.repeat_interleave(self.city_size)\n",
    "        if torch.cuda.is_available():\n",
    "            batch=batch.cuda()\n",
    "        # Check if this the first iteration loop\n",
    "        if h is None or c is None:\n",
    "            x          = self.start_placeholder  \n",
    "            \n",
    "            #X_all = X_all.reshape(self.batch_size*self.city_size,dimension)\n",
    "            X_all_normal = X_all/800\n",
    "            context = self.embedding_all(X_all)\n",
    "#             X_all_normal = X_all_normal.reshape(self.batch_size*self.city_size,dimension)\n",
    "            Transcontext,_ = self.Transembedding_all(context)\n",
    "#             tempcontext = tempcontext.reshape(self.batch_size*self.city_size,self.dim)\n",
    "#             tempcontext = self.denselayer2(tempcontext)\n",
    "#             tempcontext = self.conv1(tempcontext, batch)\n",
    "#             tempcontext = self.denselayer1(tempcontext)\n",
    "#             Transcontext = self.conv2(tempcontext, batch)\n",
    "            \n",
    "            #context = context.reshape(self.batch_size,-1,self.dim)\n",
    "            \n",
    "            #(B, size, dim)\n",
    "            Transcontext = Transcontext.reshape(-1, self.dim)\n",
    "\n",
    "            h0 = self.h0.unsqueeze(0).expand(self.batch_size, self.dim)\n",
    "            c0 = self.c0.unsqueeze(0).expand(self.batch_size, self.dim)\n",
    "\n",
    "            h0 = h0.unsqueeze(0).contiguous()\n",
    "            c0 = c0.unsqueeze(0).contiguous()\n",
    "            \n",
    "            # let h0, c0 be the hidden variable of first turn\n",
    "            h = h0.squeeze(0)\n",
    "            c = c0.squeeze(0)\n",
    "        else:\n",
    "            x          = self.embedding_x(x)\n",
    "        # LSTM encoder1900/2500\n",
    "        h, c = self.encoder(x, h, c)\n",
    "        # query vector\n",
    "        q = h\n",
    "        # pointer\n",
    "        u2 ,_ = self.TransPointer(q, Transcontext)\n",
    "#         u1 ,_ = self.Pointer(q, GCNcontext)\n",
    "        # Avg Agg between the two attention vector\n",
    "        u = u2 #self.outagg(torch.cat((u1.unsqueeze(2),u2.unsqueeze(2)),dim = 2)).squeeze(2)\n",
    "        latent_u = u.clone()\n",
    "        u = 10 * torch.tanh(u)\n",
    "        u = u + mask\n",
    "        \n",
    "        return GCNcontext, Transcontext,F.softmax(u, dim=1), h, c, latent_u\n",
    "# params= list(HPN(n_feature = 2, n_hidden = 128).parameters())\n",
    "# print(len(params))\n",
    "# for name,parameters in HPN(n_feature = 2, n_hidden = 128).named_parameters():\n",
    "#     print(name,':',parameters.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test network \n",
    "Actor = HPN(n_feature = 2, n_hidden = 256)\n",
    "print(Actor)\n",
    "nb_param = 0\n",
    "for param in Actor.parameters():\n",
    "    nb_param += np.prod(list(param.data.size()))\n",
    "print('Number of parameters:', nb_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# daniel rectangle feature handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This part I designed the rectangle-characterized TSP, that means for every step the agent walk through a corner,\n",
    "then he travel through the whole rectangle using zig-zag, finally he ends up at one of the rest corners of \n",
    "the rextangle, so, it equals the agent walk through three points at one step, in practice, I add three points into \n",
    "mask to make them unselectable.\n",
    "'''\n",
    "def rectangle_process(temp,idx,Y,Y0,mask,k,B,i,path_gazebo, visit_count, visit_time_count, if_actor):\n",
    "    Y1 = Y[zero_to_bsz, idx.data].clone()\n",
    "    rectangle_inf = idx/4\n",
    "    feature_table = temp.outcorner_getout(rectangle_inf,B)\n",
    "    feature_table = torch.Tensor(feature_table).type(torch.long)\n",
    "    if torch.cuda.is_available():\n",
    "        feature_table = feature_table.cuda()\n",
    "    Y_corner = Y[zero_to_bsz, feature_table[:,0].data].clone()\n",
    "    add_time = visit_time_count[zero_to_bsz, feature_table[:,0].data]*((range_of_wait/2)*speed_of_nozzle)\n",
    "    if torch.cuda.is_available():\n",
    "        add_time = add_time.cuda()\n",
    "    Y_corner[:,dimension-2] = add_time\n",
    "    \n",
    "    if (i % 100 == 0)and(if_actor):\n",
    "        path_gazebo.append([idx.data[0].tolist(),feature_table[:,0].data[0].tolist()])\n",
    "    if k ==0:\n",
    "        if torch.cuda.is_available():\n",
    "            reward = torch.zeros(B).cuda()\n",
    "        else:\n",
    "            reward = torch.zeros(B)\n",
    "    if k > 0:\n",
    "        reward = torch.sum((Y1[:,(0,1)] - Y0[:,(0,1)])**2 , dim=1 )**0.5\n",
    "        reward += torch.sum((Y_corner[:,(0,1)] - Y1[:,(0,1)])**2 , dim=1 )**0.5\n",
    "        #dis = (Y1 - Y0)**2\n",
    "        #dis_1 = (Y_corner - Y1)**2\n",
    "        #reward = torch.maximum(dis[:,0],dis[:,1])**0.5\n",
    "        #reward += torch.maximum(dis_1[:,0],dis_1[:,1])**0.5  \n",
    "    visit_count[zero_to_bsz, idx.data] -= 1\n",
    "    visit_count[zero_to_bsz, feature_table[:,0].data] -= 1\n",
    "    visit_count[zero_to_bsz, feature_table[:,1].data] -= 1\n",
    "    visit_count[zero_to_bsz, feature_table[:,2].data] -= 1\n",
    "    visit_time_count[zero_to_bsz, idx.data] += 1\n",
    "    visit_time_count[zero_to_bsz, feature_table[:,0].data] += 1\n",
    "    visit_time_count[zero_to_bsz, feature_table[:,1].data] += 1\n",
    "    visit_time_count[zero_to_bsz, feature_table[:,2].data] += 1\n",
    "    if_revisited = visit_count[zero_to_bsz, idx.data]<=0\n",
    "    if_revisited = -np.inf*if_revisited\n",
    "    if_revisited[if_revisited!=if_revisited] = 0\n",
    "    mask[zero_to_bsz, idx.data] += if_revisited\n",
    "    mask[zero_to_bsz, feature_table[:,0].data] += if_revisited\n",
    "    mask[zero_to_bsz, feature_table[:,1].data ] += if_revisited  \n",
    "    mask[zero_to_bsz, feature_table[:,2].data ] += if_revisited\n",
    "    \n",
    "    \n",
    "    \n",
    "    return Y, reward, Y_corner, Y_corner,feature_table[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from listofpathpoint import input_handler\n",
    "import cnc_input\n",
    "import copy\n",
    "import json\n",
    "def produce_random_data(boundry_recs, randomseed):\n",
    "    for i in range(0,len(boundry_recs),4):\n",
    "        np.random.seed(randomseed)\n",
    "        width = boundry_recs[i+2][0] - boundry_recs[i][0]\n",
    "        length = boundry_recs[i+2][1] - boundry_recs[i][1]\n",
    "        original_x,original_y = boundry_recs[i][0].clone(), boundry_recs[i][1].clone()\n",
    "        points_x = np.random.choice(int(width),2,replace=False)\n",
    "        points_y = np.random.choice(int(length),2,replace=False)\n",
    "        points_x.sort()\n",
    "        points_y.sort()\n",
    "        boundry_recs[i][0],boundry_recs[i][1] = (original_x + points_x[0]), (original_y + points_y[0])\n",
    "        boundry_recs[i+1][0],boundry_recs[i+1][1] = (original_x + points_x[1]), (original_y + points_y[0])\n",
    "        boundry_recs[i+2][0],boundry_recs[i+2][1] = (original_x + points_x[1]), (original_y + points_y[1])\n",
    "        boundry_recs[i+3][0],boundry_recs[i+3][1] = (original_x + points_x[0]), (original_y + points_y[1])\n",
    "    return boundry_recs\n",
    "def random_data_generator(origin_recs, batch_size):\n",
    "    result_X = torch.Tensor([])\n",
    "    for seed in range(batch_size):\n",
    "        temp_recs = origin_recs.clone()\n",
    "        temp_x = produce_random_data(temp_recs,seed)\n",
    "        result_X = torch.cat((result_X, temp_x),0)\n",
    "    result_X = result_X.reshape(batch_size,-1,temp_x.size(1))\n",
    "    return result_X\n",
    "\n",
    "test = input_handler('10&15data/25_chips/25_general.json')\n",
    "X_temp, mask_list_num = test.final_ver_points()\n",
    "X_temp = torch.FloatTensor(X_temp)\n",
    "# result = produce_random_data(X_temp,2)\n",
    "# result_1 = produce_random_data(X_temp,2)\n",
    "# now we have the produce_random_data, to produce single random data, but we need a batch of data...\n",
    "X_result = random_data_generator(X_temp, 128)\n",
    "for map_num in range(128):\n",
    "    gluewidth =[[354.0,320.0],[354.0,331.0],[387.0,330.0],[387.0,320.0]]\n",
    "    d = {\n",
    "    \"version\": \"4.6.0\",\n",
    "    \"flags\": {},\n",
    "    \"shapes\": [{\"label\":\"gluewidth\",\"points\":gluewidth}]\n",
    "    }\n",
    "    for i in range(25):\n",
    "        dict = {}\n",
    "        dict[\"label\"] = str(i)\n",
    "        dict[\"points\"] = X_result[map_num][:,(0,1)][4*i:4*i+4].tolist()\n",
    "        d[\"shapes\"].append(dict)\n",
    "\n",
    "    with open('10&15data/25_chips/25_generate'+str(map_num)+'.json', 'w') as f:\n",
    "        json.dump(d, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([1,2,4,3])\n",
    "a.sort()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from torch.distributions.categorical import Categorical\n",
    "# visualization\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from tqdm import tqdm_notebook\n",
    "import torch.nn.functional as F\n",
    "####### my own import file ##########\n",
    "from listofpathpoint import input_handler\n",
    "import cnc_input\n",
    "import copy\n",
    "#from hybrid_models import HPN\n",
    "####### my own import file ##########\n",
    "'''\n",
    "so, the models we have are TransEncoderNet,\n",
    "                            Attention\n",
    "                            LSTM\n",
    "                            HPN\n",
    "each one have initial parameters and the forward part, \n",
    "once we have the forward part, the back propagation will \n",
    "finished automatically by pytorch  \n",
    "'''\n",
    "TOL = 1e-3\n",
    "TINY = 1e-15\n",
    "learning_rate = 1e-4   #learning rate\n",
    "B = 128          #batch size\n",
    "B_valLoop = 1\n",
    "steps = 100\n",
    "n_epoch = 500       # epochs\n",
    "map_number = 0\n",
    "record_actor = []\n",
    "record_critic = []\n",
    "dimension = 4\n",
    "speed_of_nozzle = 30\n",
    "range_of_wait = 20\n",
    "scale_of_the_map = (800,500,speed_of_nozzle*range_of_wait)\n",
    "generalization_setup = False\n",
    "\n",
    "print('======================')\n",
    "print('prepare to train')\n",
    "print('======================')\n",
    "print('Hyper parameters:')\n",
    "print('learning rate', learning_rate)\n",
    "print('batch size', B)\n",
    "print('steps', steps)\n",
    "print('epoch', n_epoch)\n",
    "print('======================')\n",
    "\n",
    "'''\n",
    "instantiate a training network and a baseline network\n",
    "'''\n",
    "\n",
    "\n",
    "try:\n",
    "    del Actor  # remove existing model\n",
    "    del Critic # remove existing model\n",
    "except:\n",
    "    pass\n",
    "Actor = HPN(n_feature = dimension, n_hidden = 128)\n",
    "Critic = HPN(n_feature = dimension, n_hidden = 128)\n",
    "optimizer = optim.Adam(Actor.parameters(), lr=learning_rate)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "# Putting Critic model on the eval mode\n",
    "Actor = Actor.to(device)\n",
    "Critic = Critic.to(device)\n",
    "Critic.eval()\n",
    "\n",
    "epoch_ckpt = 0\n",
    "tot_time_ckpt = 0\n",
    "\n",
    "val_mean = []\n",
    "val_std = []\n",
    "maplist = ['10&15data/25_chips/25_1.json'\n",
    "          ]\n",
    "          \n",
    "plot_performance_train = []\n",
    "plot_performance_baseline = []\n",
    "# recording the result of the resent epoch makes it available for future\n",
    "#*********************# Uncomment these lines to load the previous check point\n",
    "\"\"\"\n",
    "checkpoint_file = \"checkpoint/useful.pkl\"\n",
    "checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "epoch_ckpt = checkpoint['epoch'] + 1\n",
    "tot_time_ckpt = checkpoint['tot_time']\n",
    "plot_performance_train = checkpoint['plot_performance_train']\n",
    "plot_performance_baseline = checkpoint['plot_performance_baseline']\n",
    "Critic.load_state_dict(checkpoint['model_baseline'])\n",
    "Actor.load_state_dict(checkpoint['model_train'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "print('Re-start training with saved checkpoint file={:s}\\n  Checkpoint at epoch= {:d} and time={:.3f}min\\n'.format(checkpoint_file,epoch_ckpt-1,tot_time_ckpt/60))\n",
    "\n",
    "\"\"\"\n",
    "#***********************# Uncomment these lines to load the previous check point\n",
    "\n",
    "# Main training loop\n",
    "# The core training concept mainly upon Sampling from the actor\n",
    "# then taking the greedy action from the critic\n",
    "\n",
    "start_training_time = time.time()\n",
    "time_stamp = datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\") # Load the time stamp\n",
    "\n",
    "C = 0       # baseline => the object which the actor can compare\n",
    "R = 0       # reward\n",
    "\n",
    "    \n",
    "for epoch in range(0, n_epoch):\n",
    "    # re-start training with saved checkpoint\n",
    "    epoch += epoch_ckpt # adding the number of the former epochs\n",
    "    # Train the model for one epoch\n",
    "    start = time.time() # record the starting time\n",
    "    Actor.train() \n",
    "    path_gazebo = []\n",
    "    temp = input_handler('10&15data/25_chips/25_generate'+str((epoch%B)+1)+'.json')\n",
    "    X_temp, mask_list_num = temp.final_ver_points()\n",
    "    #change the waiting time to the distance that we can measure\n",
    "    size = len(X_temp)\n",
    "    zero_to_bsz = torch.arange(B, device = device) # a list contains 0 to (batch size -1)\n",
    "\n",
    "    for corner in X_temp:\n",
    "        corner[dimension -2] *= speed_of_nozzle\n",
    "    size_rec = mask_list_num[-1]\n",
    "\n",
    "    X_temp = torch.FloatTensor(X_temp)\n",
    "    visit_count_initial = X_temp[:,dimension-1]\n",
    "    visit_count_rec = []\n",
    "    for i in range(0,len(visit_count_initial),4):\n",
    "        visit_count_rec.append(int(visit_count_initial[i]))\n",
    "\n",
    "    # C_critic = torch.Tensor([12000]) #********\n",
    "    # if torch.cuda.is_available():#*******\n",
    "    #     C_critic = C_critic.cuda()#*******\n",
    "    # in this step, if we want to variance the outputs, load the generalize .json and run the following code\n",
    "    if generalization_setup == True:\n",
    "        X = random_data_generator(X_temp,B)\n",
    "    else:\n",
    "        X = X_temp.repeat(B,1,1)\n",
    "    if torch.cuda.is_available():\n",
    "        X = X.cuda()\n",
    "    for i_all in range(1, steps+1): # 1 ~ 2500 steps\n",
    "        # mask some points that are not the first visited points\n",
    "        if torch.cuda.is_available():\n",
    "            R = torch.zeros(B).cuda()\n",
    "            reward_recorder = torch.zeros(B,size_rec).cuda()\n",
    "            idx_recorder = torch.zeros(B,size_rec).cuda()\n",
    "            logprobs = 0\n",
    "            reward = torch.zeros(B).cuda()\n",
    "            mask = torch.zeros(B,size).cuda() # use mask to make some points impossible to choose\n",
    "        else:\n",
    "            R = torch.zeros(B)\n",
    "            reward_recorder = torch.zeros(B,size_rec)\n",
    "            idx_recorder = torch.zeros(B,size_rec)\n",
    "            logprobs = 0\n",
    "            reward = torch.zeros(B)\n",
    "            mask = torch.zeros(B,size) # use mask to make some points impossible to choose\n",
    "        x = torch.zeros(B,dimension)# Y[:,0,:] #set the first point to x\n",
    "        h = None\n",
    "        c = None\n",
    "        context = None        # set Y_ini to the out corner\n",
    "        Transcontext = None\n",
    "        Y0 = None\n",
    "        choosen_idx = None\n",
    "        visit_count = visit_count_initial.repeat(B,1)\n",
    "        visit_time_count_initial = torch.zeros(len(visit_count_initial))\n",
    "        visit_time_count = visit_time_count_initial.repeat(B,1)\n",
    "        if torch.cuda.is_available():\n",
    "            visit_count = visit_count.cuda()\n",
    "        # Actor Sampling phase\n",
    "        for k in range(size_rec):\n",
    "            if k ==0:\n",
    "                Y = X.view(B,size,dimension)\n",
    "            context, Transcontext, output, h, c, _ = Actor(context,Transcontext,x=x, X_all=X,h=h,\n",
    "                                                           c=c, mask=mask, choosen_idx=choosen_idx, \n",
    "                                                                       epoch=epoch+1)\n",
    "            sampler = torch.distributions.Categorical(output)\n",
    "            idx = sampler.sample()\n",
    "            idx_recorder[:,k] = (idx/4).type(torch.long)\n",
    "            #prepare for the back propagation of pytorch\n",
    "            Y, reward, Y0, x, choosen_idx = rectangle_process(temp, idx,Y,Y0,mask,k,B,i_all,path_gazebo,\n",
    "                                                visit_count, visit_time_count, if_actor=True)\n",
    "            R += reward\n",
    "            reward_recorder[:,k] = R\n",
    "            logprobs += torch.log(output[zero_to_bsz, idx.data] + TINY)\n",
    "            \n",
    "        #now is the time to check if any trajectory should be punished due to waiting on the same rectangle\n",
    "\n",
    "        trajec_count = 0\n",
    "        if i_all%100 ==0:\n",
    "            print(idx_recorder[0])\n",
    "        for path_time in zip(idx_recorder,reward_recorder):\n",
    "            idx_time = zip(path_time[0],path_time[1])\n",
    "            idx_time = sorted(idx_time, key=lambda x: x[0])\n",
    "            total_idx = 0\n",
    "            extra_waiting_time = 0\n",
    "            for item in visit_count_rec:\n",
    "                compare_list = []\n",
    "                if item>1:\n",
    "                    for i in range(int(item)):\n",
    "                        compare_list.append(idx_time[int(total_idx + i)][1])\n",
    "                    compare_list.sort(reverse=True)\n",
    "                    total_idx += item\n",
    "                    for i in range(len(compare_list)-1):\n",
    "                        dis_step = compare_list[i] - compare_list[i+1]\n",
    "                        dry_time = (range_of_wait/2)*speed_of_nozzle\n",
    "                        if (dis_step) < (dry_time):\n",
    "                            extra_waiting_time += dry_time - dis_step\n",
    "                else:\n",
    "                    total_idx += item\n",
    "            R[trajec_count] += extra_waiting_time\n",
    "            trajec_count+=1\n",
    "                    \n",
    "                \n",
    "        \n",
    " # critic baseline phase, use the baseline to compute the actual reward of agent at that time\n",
    "        if torch.cuda.is_available():\n",
    "            C = torch.zeros(B).cuda()\n",
    "            reward_recorder = torch.zeros(B,size_rec).cuda()\n",
    "            idx_recorder = torch.zeros(B,size_rec).cuda()\n",
    "            baseline = torch.zeros(B).cuda()\n",
    "            mask = torch.zeros(B,size).cuda() # use mask to make some points impossible to choose\n",
    "        else:\n",
    "            C = torch.zeros(B)\n",
    "            reward_recorder = torch.zeros(B,size_rec)\n",
    "            idx_recorder = torch.zeros(B,size_rec)\n",
    "            baseline = torch.zeros(B)\n",
    "            mask = torch.zeros(B,size) # use mask to make some points impossible to choose\n",
    "        x = torch.zeros(B,dimension)#Y[:,0,:] #set the first point to x\n",
    "        h = None\n",
    "        c = None\n",
    "        context = None\n",
    "        Transcontext = None\n",
    "        C0 = None\n",
    "        choosen_idx = None\n",
    "        visit_count = visit_count_initial.repeat(B,1)\n",
    "        visit_time_count_initial = torch.zeros(len(visit_count_initial))\n",
    "        visit_time_count = visit_time_count_initial.repeat(B,1)\n",
    "        if torch.cuda.is_available():\n",
    "            visit_count = visit_count.cuda()\n",
    "        # compute tours for baseline without grad \"Cause we want to fix the weights for the critic\"\n",
    "        with torch.no_grad():\n",
    "            for k in range(size_rec): \n",
    "                if k ==0:\n",
    "                    Y = X.view(B,size,dimension)\n",
    "                #check if all the points to be masked,if so, raise the total reward R, and check again\n",
    "                context, Transcontext, output, h, c, _ = Critic(context,Transcontext,x=x, X_all=X,h=h,\n",
    "                                                                c=c, mask=mask, choosen_idx=choosen_idx,epoch=epoch+1)\n",
    "                idx = torch.argmax(output, dim=1) # ----> greedy baseline critic\n",
    "                idx_recorder[:,k] = (idx/4).type(torch.long)\n",
    "                # prepare for the back propagation of pytorch\n",
    "                Y, baseline, C0, x, choosen_idx = rectangle_process(temp,idx,Y,C0, mask,k,B,i,path_gazebo,\n",
    "                                                   visit_count, visit_time_count, if_actor=False)\n",
    "                C += baseline\n",
    "                reward_recorder[:,k] = C\n",
    "                    #now is the time to check if any trajectory should be punished due to waiting on the same rectangle\n",
    "\n",
    "            trajec_count = 0\n",
    "            for path_time in zip(idx_recorder,reward_recorder):\n",
    "                idx_time = zip(path_time[0],path_time[1])\n",
    "                idx_time = sorted(idx_time, key=lambda x: x[0])\n",
    "                total_idx = 0\n",
    "                extra_waiting_time = 0\n",
    "                for item in visit_count_rec:\n",
    "                    compare_list = []\n",
    "                    if item>1:\n",
    "                        for i in range(int(item)):\n",
    "                            compare_list.append(idx_time[int(total_idx + i)][1])\n",
    "                        compare_list.sort(reverse=True)\n",
    "                        total_idx += item\n",
    "                        for i in range(len(compare_list)-1):\n",
    "                            dis_step = compare_list[i] - compare_list[i+1]\n",
    "                            dry_time = (range_of_wait/2)*speed_of_nozzle\n",
    "                            if (dis_step) < (dry_time):\n",
    "                                extra_waiting_time += dry_time - dis_step\n",
    "                    else:\n",
    "                        total_idx += item\n",
    "                C[trajec_count] += extra_waiting_time\n",
    "                trajec_count+=1\n",
    "        ###################\n",
    "        # Loss and backprop handling \n",
    "        ###################\n",
    "        loss = torch.mean((R - C) * logprobs) \n",
    "        #loss = torch.mean((R - C_critic[0]) * logprobs)********\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i_all % 100 == 0:\n",
    "            print(\"epoch:{}, batch:{}/{}, reward:{}\".format(epoch, i_all, steps,R.mean().item()))\n",
    "            record_actor.append(R.mean().tolist())\n",
    "            record_critic.append(C.mean().tolist())\n",
    "#             record_critic.append(C_critic[0].tolist())\n",
    "            plt.plot(record_actor,'r:')\n",
    "            plt.plot(record_critic,'b:')\n",
    "            plt.show()\n",
    "        if i_all % 100 == 0:\n",
    "            print(\"record the last path to gazebo for showing up\")\n",
    "            #starting to show the path on simulated enviroment of cnc_machine \n",
    "            the_resent_path = temp.zig_zag_path(path_gazebo,mask_list_num)\n",
    "            data = {'path':the_resent_path}\n",
    "            data_1 = {'corners':path_gazebo}\n",
    "            pathpoints_dir = os.path.join(\"pathpoints\")\n",
    "            if not os.path.exists(pathpoints_dir):\n",
    "                os.makedirs(pathpoints_dir)\n",
    "            name = 'pathpoints/path_points '+str(i)+'.yaml'\n",
    "            with open(name, 'w') as file:\n",
    "                documents = yaml.dump(data,file)\n",
    "                documents = yaml.dump(data_1,file)\n",
    "            path_gazebo = []\n",
    "    time_one_epoch = time.time() - start #recording the work time of one epoch\n",
    "    time_tot = time.time() - start_training_time + tot_time_ckpt\n",
    "    ###################\n",
    "    # Evaluate train model and baseline \n",
    "    # in this phase we just solve random instances with the actor and the critic\n",
    "    # compare this soluation if we get any improvment we'll transfer the actor's\n",
    "    # weights into the critic\n",
    "    ###################\n",
    "    # putting the actor in the eval mode\n",
    "    Actor.eval()\n",
    "    \n",
    "    mean_tour_length_actor = 0\n",
    "    mean_tour_length_critic = 0\n",
    "\n",
    "    for step in range(0,B_valLoop):\n",
    "        # compute tour for model and baseline\n",
    "        # mask some points that are not the first visited points\n",
    "        if torch.cuda.is_available():\n",
    "            R = torch.zeros(B).cuda()\n",
    "            reward_recorder = torch.zeros(B,size_rec).cuda()\n",
    "            idx_recorder = torch.zeros(B,size_rec).cuda()\n",
    "            reward = torch.zeros(B).cuda()\n",
    "            mask = torch.zeros(B,size).cuda() # use mask to make some points impossible to choose\n",
    "        else:\n",
    "            R = torch.zeros(B)\n",
    "            reward_recorder = torch.zeros(B,size_rec)\n",
    "            idx_recorder = torch.zeros(B,size_rec)\n",
    "            reward = torch.zeros(B)\n",
    "            mask = torch.zeros(B,size) # use mask to make some points impossible to choose\n",
    "        x = torch.zeros(B,dimension)# Y[:,0,:] #set the first point to x\n",
    "        h = None\n",
    "        c = None\n",
    "        context = None        # set Y_ini to the out corner\n",
    "        Transcontext = None\n",
    "        Y0 = None\n",
    "        choosen_idx = None\n",
    "        visit_count = visit_count_initial.repeat(B,1)\n",
    "        visit_time_count_initial = torch.zeros(len(visit_count_initial))\n",
    "        visit_time_count = visit_time_count_initial.repeat(B,1)\n",
    "        if torch.cuda.is_available():\n",
    "            visit_count = visit_count.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for k in range(size_rec):\n",
    "                if k==0:\n",
    "                    Y = X.view(B,size,dimension)\n",
    "                context, Transcontext, output, h, c, _ = Actor(context,Transcontext,x=x, X_all=X,h=h,\n",
    "                                                               c=c, mask=mask,choosen_idx=choosen_idx,epoch=epoch+1)\n",
    "                idx = torch.argmax(output, dim=1)\n",
    "                idx_recorder[:,k] = (idx/4).type(torch.long)\n",
    "                #prepare for the back propagation of pytorch\n",
    "                Y, reward, Y0, x, choosen_idx = rectangle_process(temp, idx,Y,Y0,mask,k,B,i,path_gazebo,\n",
    "                                                    visit_count, visit_time_count, if_actor=False)\n",
    "                R += reward\n",
    "                reward_recorder[:,k] = R\n",
    "            #now is the time to check if any trajectory should be punished due to waiting on the same rectangle\n",
    "\n",
    "            trajec_count = 0\n",
    "            for path_time in zip(idx_recorder,reward_recorder):\n",
    "                idx_time = zip(path_time[0],path_time[1])\n",
    "                idx_time = sorted(idx_time, key=lambda x: x[0])\n",
    "                total_idx = 0\n",
    "                extra_waiting_time = 0\n",
    "                for item in visit_count_rec:\n",
    "                    compare_list = []\n",
    "                    if item>1:\n",
    "                        for i in range(int(item)):\n",
    "                            compare_list.append(idx_time[int(total_idx + i)][1])\n",
    "                        compare_list.sort(reverse=True)\n",
    "                        total_idx += item\n",
    "                        for i in range(len(compare_list)-1):\n",
    "                            dis_step = compare_list[i] - compare_list[i+1]\n",
    "                            dry_time = (range_of_wait/2)*speed_of_nozzle\n",
    "                            if (dis_step) < (dry_time):\n",
    "                                extra_waiting_time += dry_time - dis_step\n",
    "                    else:\n",
    "                        total_idx += item\n",
    "                R[trajec_count] += extra_waiting_time\n",
    "                trajec_count+=1\n",
    "            print('R_val = ',R[0])\n",
    "        if torch.cuda.is_available():\n",
    "            C = torch.zeros(B).cuda()\n",
    "            reward_recorder = torch.zeros(B,size_rec).cuda()\n",
    "            idx_recorder = torch.zeros(B,size_rec).cuda()\n",
    "            baseline = torch.zeros(B).cuda()\n",
    "            mask = torch.zeros(B,size).cuda() # use mask to make some points impossible to choose\n",
    "        else:\n",
    "            C = torch.zeros(B)\n",
    "            reward_recorder = torch.zeros(B,size_rec)\n",
    "            idx_recorder = torch.zeros(B,size_rec)\n",
    "            baseline = torch.zeros(B)\n",
    "            mask = torch.zeros(B,size) # use mask to make some points impossible to choose\n",
    "        x = torch.zeros(B,dimension)#Y[:,0,:] #set the first point to x\n",
    "        h = None\n",
    "        c = None\n",
    "        context = None\n",
    "        Transcontext = None\n",
    "        C0 = None\n",
    "        choosen_idx = None\n",
    "        visit_count = visit_count_initial.repeat(B,1)\n",
    "        visit_time_count_initial = torch.zeros(len(visit_count_initial))\n",
    "        visit_time_count = visit_time_count_initial.repeat(B,1)\n",
    "        if torch.cuda.is_available():\n",
    "            visit_count = visit_count.cuda()\n",
    "        # compute tours for baseline without grad \"Cause we want to fix the weights for the critic\"\n",
    "        with torch.no_grad():\n",
    "            for k in range(size_rec): \n",
    "                if k ==0:\n",
    "                    Y = X.view(B,size,dimension)\n",
    "                #check if all the points to be masked,if so, raise the total reward R, and check again\n",
    "                context, Transcontext, output, h, c, _ = Critic(context,Transcontext,x=x, X_all=X,h=h,\n",
    "                                                                c=c, mask=mask, choosen_idx=choosen_idx,epoch=epoch+1)\n",
    "                idx = torch.argmax(output, dim=1) # ----> greedy baseline critic\n",
    "                idx_recorder[:,k] = (idx/4).type(torch.long)\n",
    "                # prepare for the back propagation of pytorch\n",
    "                Y, baseline, C0, x, choosen_idx = rectangle_process(temp,idx,Y,C0, mask,k,B,i,path_gazebo,\n",
    "                                                   visit_count, visit_time_count, if_actor=False)\n",
    "                C += baseline\n",
    "                reward_recorder[:,k] = C\n",
    "                    #now is the time to check if any trajectory should be punished due to waiting on the same rectangle\n",
    "\n",
    "            trajec_count = 0\n",
    "            for path_time in zip(idx_recorder,reward_recorder):\n",
    "                idx_time = zip(path_time[0],path_time[1])\n",
    "                idx_time = sorted(idx_time, key=lambda x: x[0])\n",
    "                total_idx = 0\n",
    "                extra_waiting_time = 0\n",
    "                for item in visit_count_rec:\n",
    "                    compare_list = []\n",
    "                    if item>1:\n",
    "                        for i in range(int(item)):\n",
    "                            compare_list.append(idx_time[int(total_idx + i)][1])\n",
    "                        compare_list.sort(reverse=True)\n",
    "                        total_idx += item\n",
    "                        for i in range(len(compare_list)-1):\n",
    "                            dis_step = compare_list[i] - compare_list[i+1]\n",
    "                            dry_time = (range_of_wait/2)*speed_of_nozzle\n",
    "                            if (dis_step) < (dry_time):\n",
    "                                extra_waiting_time += dry_time - dis_step\n",
    "                    else:\n",
    "                        total_idx += item\n",
    "                C[trajec_count] += extra_waiting_time\n",
    "                trajec_count+=1\n",
    "            print('C_val = ',C.mean().item())\n",
    "            #print('C_val = ',C[0])*********\n",
    "        mean_tour_length_actor  += R.mean().item()\n",
    "        mean_tour_length_critic += C.mean().item()\n",
    "\n",
    "    mean_tour_length_actor  =  mean_tour_length_actor  / B_valLoop\n",
    "    mean_tour_length_critic =  mean_tour_length_critic / B_valLoop\n",
    "    # evaluate train model and baseline and update if train model is better\n",
    "\n",
    "    update_baseline = mean_tour_length_actor + TOL < mean_tour_length_critic\n",
    "\n",
    "    print('Avg Actor {} --- Avg Critic {}'.format(mean_tour_length_actor,mean_tour_length_critic))\n",
    "\n",
    "    if update_baseline:\n",
    "        Critic.load_state_dict(Actor.state_dict())\n",
    "        #C_critic = [R[0]] #********\n",
    "        print('My actor is going on the right road Hallelujah :) Updated')\n",
    "    ###################\n",
    "    # Valdiation train model and baseline on 1k random TSP instances\n",
    "    ###################\n",
    "    # erased by daniel due to the 1K tsp is not the scale I want to train  \n",
    "\n",
    "    # For checkpoint\n",
    "    plot_performance_train.append([(epoch+1), mean_tour_length_actor])\n",
    "    plot_performance_baseline.append([(epoch+1), mean_tour_length_critic])\n",
    "    # compute the optimally gap ==> this is interesting because there is no LKH or other optimal algorithms \n",
    "    # for the problem like this rectangle characterized map\n",
    "    mystring_min = 'Epoch: {:d}, epoch time: {:.3f}min, tot time: {:.3f}day, L_actor: {:.3f}, L_critic: {:.3f}, update: {}'.format(\n",
    "        epoch, time_one_epoch/60, time_tot/86400, mean_tour_length_actor, mean_tour_length_critic, update_baseline)\n",
    "\n",
    "    print(mystring_min)\n",
    "    print('Save Checkpoints')\n",
    "\n",
    "    # Saving checkpoint\n",
    "    checkpoint_dir = os.path.join(\"checkpoint\")\n",
    "\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "    \n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'time': time_one_epoch,\n",
    "        'tot_time': time_tot,\n",
    "        'loss': loss.item(),\n",
    "        'plot_performance_train': plot_performance_train,\n",
    "        'plot_performance_baseline': plot_performance_baseline,\n",
    "        'model_baseline': Critic.state_dict(),\n",
    "        'model_train': Actor.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        },'{}.pkl'.format(checkpoint_dir + \"/checkpoint_\" + time_stamp + \"-n{}\".format(size) + \"-gpu{}\".format(gpu_id)))\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "            \n",
    "                \n",
    "        \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "index = int(9.34)\n",
    "table = [[1,2],[3,4]]\n",
    "table_1 = [[3,44],[5,6]]\n",
    "table = torch.as_tensor(table)\n",
    "table_1 = torch.as_tensor(table_1)\n",
    "result = torch.maximum(table_1[:,0],table_1[:,1])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "t = torch.ones(10,2,2,2)\n",
    "x = torch.ones(10,2,2)\n",
    "k = x.unsqueeze(1)*2\n",
    "x = x.unsqueeze(2)\n",
    "print(x.shape)\n",
    "print(k.shape)\n",
    "print(t.shape)\n",
    "X = t+x+k\n",
    "print(X)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
